{"version":3,"sources":["src/js/convnet.js"],"names":["convnetjs","REVISION","global","return_v","v_val","gaussRandom","u","Math","random","v","r","c","sqrt","log","randf","a","b","randi","floor","randn","mu","std","zeros","n","isNaN","ArrayBuffer","arr","Array","i","Float64Array","arrContains","elt","length","arrUnique","push","maxmin","w","maxv","minv","maxi","mini","dv","randperm","j","temp","array","q","weightedSample","lst","probs","p","cumprob","k","getopt","opt","field_name","default_value","ret","f","assert","condition","message","Error","Vol","sx","sy","depth","Object","prototype","toString","call","dw","scale","get","x","y","d","ix","set","add","get_grad","set_grad","add_grad","cloneAndZero","clone","V","addFrom","addFromScaled","setConst","toJSON","json","fromJSON","augment","crop","dx","dy","fliplr","W","W2","img_to_vol","img","convert_grayscale","canvas","document","createElement","width","height","ctx","getContext","drawImage","e","name","img_data","getImageData","data","H","pv","x1","ConvLayer","out_depth","filters","in_depth","in_sx","in_sy","stride","pad","l1_decay_mul","l2_decay_mul","out_sx","out_sy","layer_type","bias","bias_pref","biases","forward","is_training","in_act","A","V_sx","V_sy","xy_stride","ay","ax","fy","oy","fx","ox","fd","out_act","backward","chain_grad","ix1","ix2","getParamsAndGrads","response","params","grads","FullyConnLayer","num_neurons","num_inputs","Vw","wi","tfi","PoolLayer","switchx","switchy","winx","winy","InputLayer","SoftmaxLayer","as","amax","es","esum","exp","indicator","mul","RegressionLayer","loss","dim","yi","val","SVMLayer","yscore","margin","ydiff","ReluLayer","V2","N","V2w","SigmoidLayer","v2wi","MaxoutLayer","group_size","switches","ai","a2","tanh","TanhLayer","DropoutLayer","drop_prob","dropped","LocalResponseNormalizationLayer","alpha","beta","console","S_cache_","n2","den","max","min","aa","pow","S","SB","SB2","aj","g","Net","options","layers","makeLayers","defs","type","desugar","new_defs","def","num_classes","activation","gs","prev","act","getCostLoss","layer_reponse","getPrediction","Lj","t","L","Trainer","net","learning_rate","l1_decay","l2_decay","batch_size","method","momentum","ro","eps","gsum","xsum","train","start","Date","getTime","end","fwd_time","cost_loss","l2_decay_loss","l1_decay_loss","bwd_time","pglist","pg","plen","abs","l1grad","l2grad","gij","gsumi","xsumi","softmax_loss","SGDTrainer","MagicNet","labels","train_ratio","num_folds","num_candidates","num_epochs","ensemble_size","batch_size_min","batch_size_max","l2_decay_min","l2_decay_max","learning_rate_min","learning_rate_max","momentum_min","momentum_max","neurons_min","neurons_max","folds","candidates","evaluated_candidates","unique_labels","iter","foldix","finish_fold_callback","finish_batch_callback","sampleFolds","sampleCandidates","num_train","train_ix","slice","test_ix","sampleCandidate","input_depth","layer_defs","nl","ni","dp","bs","l2","lr","mom","tp","trainer_def","trainer","cand","acc","accv","step","fold","dataix","l","lastiter","val_acc","evalValErrors","sort","vals","yhat","predict_soft","eval_candidates","nv","xout","predict","stats","predicted_label","nets","dummy_candidate","onFinishFold","onFinishBatch","lib","module","exports","window","jsfeat"],"mappings":";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAAA,IAAIA,SAAS,GAAGA,SAAS,IAAI;AAAEC,EAAAA,QAAQ,EAAE;AAAZ,CAA7B;;AACA,CAAC,UAASC,MAAT,EAAiB;AAChB,eADgB,CAGhB;;AACA,MAAIC,QAAQ,GAAG,KAAf;AACA,MAAIC,KAAK,GAAG,GAAZ;;AACA,MAAIC,WAAW,GAAG,YAAW;AAC3B,QAAGF,QAAH,EAAa;AACXA,MAAAA,QAAQ,GAAG,KAAX;AACA,aAAOC,KAAP;AACD;;AACD,QAAIE,CAAC,GAAG,IAAEC,IAAI,CAACC,MAAL,EAAF,GAAgB,CAAxB;AACA,QAAIC,CAAC,GAAG,IAAEF,IAAI,CAACC,MAAL,EAAF,GAAgB,CAAxB;AACA,QAAIE,CAAC,GAAGJ,CAAC,GAACA,CAAF,GAAMG,CAAC,GAACA,CAAhB;AACA,QAAGC,CAAC,IAAI,CAAL,IAAUA,CAAC,GAAG,CAAjB,EAAoB,OAAOL,WAAW,EAAlB;AACpB,QAAIM,CAAC,GAAGJ,IAAI,CAACK,IAAL,CAAU,CAAC,CAAD,GAAGL,IAAI,CAACM,GAAL,CAASH,CAAT,CAAH,GAAeA,CAAzB,CAAR;AACAN,IAAAA,KAAK,GAAGK,CAAC,GAACE,CAAV,CAV2B,CAUd;;AACbR,IAAAA,QAAQ,GAAG,IAAX;AACA,WAAOG,CAAC,GAACK,CAAT;AACD,GAbD;;AAcA,MAAIG,KAAK,GAAG,UAASC,CAAT,EAAYC,CAAZ,EAAe;AAAE,WAAOT,IAAI,CAACC,MAAL,MAAeQ,CAAC,GAACD,CAAjB,IAAoBA,CAA3B;AAA+B,GAA5D;;AACA,MAAIE,KAAK,GAAG,UAASF,CAAT,EAAYC,CAAZ,EAAe;AAAE,WAAOT,IAAI,CAACW,KAAL,CAAWX,IAAI,CAACC,MAAL,MAAeQ,CAAC,GAACD,CAAjB,IAAoBA,CAA/B,CAAP;AAA2C,GAAxE;;AACA,MAAII,KAAK,GAAG,UAASC,EAAT,EAAaC,GAAb,EAAiB;AAAE,WAAOD,EAAE,GAACf,WAAW,KAAGgB,GAAxB;AAA8B,GAA7D,CAtBgB,CAwBhB;;;AACA,MAAIC,KAAK,GAAG,UAASC,CAAT,EAAY;AACtB,QAAG,OAAOA,CAAP,KAAY,WAAZ,IAA2BC,KAAK,CAACD,CAAD,CAAnC,EAAwC;AAAE,aAAO,EAAP;AAAY;;AACtD,QAAG,OAAOE,WAAP,KAAuB,WAA1B,EAAuC;AACrC;AACA,UAAIC,GAAG,GAAG,IAAIC,KAAJ,CAAUJ,CAAV,CAAV;;AACA,WAAI,IAAIK,CAAC,GAAC,CAAV,EAAYA,CAAC,GAACL,CAAd,EAAgBK,CAAC,EAAjB,EAAqB;AAAEF,QAAAA,GAAG,CAACE,CAAD,CAAH,GAAQ,CAAR;AAAY;;AACnC,aAAOF,GAAP;AACD,KALD,MAKO;AACL,aAAO,IAAIG,YAAJ,CAAiBN,CAAjB,CAAP;AACD;AACF,GAVD;;AAYA,MAAIO,WAAW,GAAG,UAASJ,GAAT,EAAcK,GAAd,EAAmB;AACnC,SAAI,IAAIH,CAAC,GAAC,CAAN,EAAQL,CAAC,GAACG,GAAG,CAACM,MAAlB,EAAyBJ,CAAC,GAACL,CAA3B,EAA6BK,CAAC,EAA9B,EAAkC;AAChC,UAAGF,GAAG,CAACE,CAAD,CAAH,KAASG,GAAZ,EAAiB,OAAO,IAAP;AAClB;;AACD,WAAO,KAAP;AACD,GALD;;AAOA,MAAIE,SAAS,GAAG,UAASP,GAAT,EAAc;AAC5B,QAAIV,CAAC,GAAG,EAAR;;AACA,SAAI,IAAIY,CAAC,GAAC,CAAN,EAAQL,CAAC,GAACG,GAAG,CAACM,MAAlB,EAAyBJ,CAAC,GAACL,CAA3B,EAA6BK,CAAC,EAA9B,EAAkC;AAChC,UAAG,CAACE,WAAW,CAACd,CAAD,EAAIU,GAAG,CAACE,CAAD,CAAP,CAAf,EAA4B;AAC1BZ,QAAAA,CAAC,CAACkB,IAAF,CAAOR,GAAG,CAACE,CAAD,CAAV;AACD;AACF;;AACD,WAAOZ,CAAP;AACD,GARD,CA5CgB,CAsDhB;;;AACA,MAAImB,MAAM,GAAG,UAASC,CAAT,EAAY;AACvB,QAAGA,CAAC,CAACJ,MAAF,KAAa,CAAhB,EAAmB;AAAE,aAAO,EAAP;AAAY,KADV,CACW;;;AAClC,QAAIK,IAAI,GAAGD,CAAC,CAAC,CAAD,CAAZ;AACA,QAAIE,IAAI,GAAGF,CAAC,CAAC,CAAD,CAAZ;AACA,QAAIG,IAAI,GAAG,CAAX;AACA,QAAIC,IAAI,GAAG,CAAX;AACA,QAAIjB,CAAC,GAAGa,CAAC,CAACJ,MAAV;;AACA,SAAI,IAAIJ,CAAC,GAAC,CAAV,EAAYA,CAAC,GAACL,CAAd,EAAgBK,CAAC,EAAjB,EAAqB;AACnB,UAAGQ,CAAC,CAACR,CAAD,CAAD,GAAOS,IAAV,EAAgB;AAAEA,QAAAA,IAAI,GAAGD,CAAC,CAACR,CAAD,CAAR;AAAaW,QAAAA,IAAI,GAAGX,CAAP;AAAW;;AAC1C,UAAGQ,CAAC,CAACR,CAAD,CAAD,GAAOU,IAAV,EAAgB;AAAEA,QAAAA,IAAI,GAAGF,CAAC,CAACR,CAAD,CAAR;AAAaY,QAAAA,IAAI,GAAGZ,CAAP;AAAW;AAC3C;;AACD,WAAO;AAACW,MAAAA,IAAI,EAAEA,IAAP;AAAaF,MAAAA,IAAI,EAAEA,IAAnB;AAAyBG,MAAAA,IAAI,EAAEA,IAA/B;AAAqCF,MAAAA,IAAI,EAAEA,IAA3C;AAAiDG,MAAAA,EAAE,EAACJ,IAAI,GAACC;AAAzD,KAAP;AACD,GAZD,CAvDgB,CAqEhB;;;AACA,MAAII,QAAQ,GAAG,UAASnB,CAAT,EAAY;AACzB,QAAIK,CAAC,GAAGL,CAAR;AAAA,QACIoB,CAAC,GAAG,CADR;AAAA,QAEIC,IAFJ;AAGA,QAAIC,KAAK,GAAG,EAAZ;;AACA,SAAI,IAAIC,CAAC,GAAC,CAAV,EAAYA,CAAC,GAACvB,CAAd,EAAgBuB,CAAC,EAAjB,EAAoBD,KAAK,CAACC,CAAD,CAAL,GAASA,CAAT;;AACpB,WAAOlB,CAAC,EAAR,EAAY;AACRe,MAAAA,CAAC,GAAGpC,IAAI,CAACW,KAAL,CAAWX,IAAI,CAACC,MAAL,MAAiBoB,CAAC,GAAC,CAAnB,CAAX,CAAJ;AACAgB,MAAAA,IAAI,GAAGC,KAAK,CAACjB,CAAD,CAAZ;AACAiB,MAAAA,KAAK,CAACjB,CAAD,CAAL,GAAWiB,KAAK,CAACF,CAAD,CAAhB;AACAE,MAAAA,KAAK,CAACF,CAAD,CAAL,GAAWC,IAAX;AACH;;AACD,WAAOC,KAAP;AACD,GAbD,CAtEgB,CAqFhB;AACA;;;AACA,MAAIE,cAAc,GAAG,UAASC,GAAT,EAAcC,KAAd,EAAqB;AACxC,QAAIC,CAAC,GAAGpC,KAAK,CAAC,CAAD,EAAI,GAAJ,CAAb;AACA,QAAIqC,OAAO,GAAG,GAAd;;AACA,SAAI,IAAIC,CAAC,GAAC,CAAN,EAAQ7B,CAAC,GAACyB,GAAG,CAAChB,MAAlB,EAAyBoB,CAAC,GAAC7B,CAA3B,EAA6B6B,CAAC,EAA9B,EAAkC;AAChCD,MAAAA,OAAO,IAAIF,KAAK,CAACG,CAAD,CAAhB;;AACA,UAAGF,CAAC,GAAGC,OAAP,EAAgB;AAAE,eAAOH,GAAG,CAACI,CAAD,CAAV;AAAgB;AACnC;AACF,GAPD,CAvFgB,CAgGhB;;;AACA,MAAIC,MAAM,GAAG,UAASC,GAAT,EAAcC,UAAd,EAA0BC,aAA1B,EAAyC;AACpD,QAAG,OAAOD,UAAP,KAAsB,QAAzB,EAAmC;AACjC;AACA,aAAQ,OAAOD,GAAG,CAACC,UAAD,CAAV,KAA2B,WAA5B,GAA2CD,GAAG,CAACC,UAAD,CAA9C,GAA6DC,aAApE;AACD,KAHD,MAGO;AACL;AACA,UAAIC,GAAG,GAAGD,aAAV;;AACA,WAAI,IAAI5B,CAAC,GAAC,CAAV,EAAYA,CAAC,GAAC2B,UAAU,CAACvB,MAAzB,EAAgCJ,CAAC,EAAjC,EAAqC;AACnC,YAAI8B,CAAC,GAAGH,UAAU,CAAC3B,CAAD,CAAlB;;AACA,YAAI,OAAO0B,GAAG,CAACI,CAAD,CAAV,KAAkB,WAAtB,EAAmC;AACjCD,UAAAA,GAAG,GAAGH,GAAG,CAACI,CAAD,CAAT,CADiC,CACnB;AACf;AACF;;AACD,aAAOD,GAAP;AACD;AACF,GAfD;;AAiBA,WAASE,MAAT,CAAgBC,SAAhB,EAA2BC,OAA3B,EAAoC;AAClC,QAAI,CAACD,SAAL,EAAgB;AACdC,MAAAA,OAAO,GAAGA,OAAO,IAAI,kBAArB;;AACA,UAAI,OAAOC,KAAP,KAAiB,WAArB,EAAkC;AAChC,cAAM,IAAIA,KAAJ,CAAUD,OAAV,CAAN;AACD;;AACD,YAAMA,OAAN,CALc,CAKC;AAChB;AACF;;AAED3D,EAAAA,MAAM,CAACY,KAAP,GAAeA,KAAf;AACAZ,EAAAA,MAAM,CAACe,KAAP,GAAeA,KAAf;AACAf,EAAAA,MAAM,CAACiB,KAAP,GAAeA,KAAf;AACAjB,EAAAA,MAAM,CAACoB,KAAP,GAAeA,KAAf;AACApB,EAAAA,MAAM,CAACiC,MAAP,GAAgBA,MAAhB;AACAjC,EAAAA,MAAM,CAACwC,QAAP,GAAkBA,QAAlB;AACAxC,EAAAA,MAAM,CAAC6C,cAAP,GAAwBA,cAAxB;AACA7C,EAAAA,MAAM,CAAC+B,SAAP,GAAmBA,SAAnB;AACA/B,EAAAA,MAAM,CAAC4B,WAAP,GAAqBA,WAArB;AACA5B,EAAAA,MAAM,CAACmD,MAAP,GAAgBA,MAAhB;AACAnD,EAAAA,MAAM,CAACyD,MAAP,GAAgBA,MAAhB;AAED,CAxID,EAwIG3D,SAxIH;;AAyIA,CAAC,UAASE,MAAT,EAAiB;AAChB,eADgB,CAGhB;AACA;AACA;AACA;AACA;AACA;AACA;;AACA,MAAI6D,GAAG,GAAG,UAASC,EAAT,EAAaC,EAAb,EAAiBC,KAAjB,EAAwBvD,CAAxB,EAA2B;AACnC;AACA,QAAGwD,MAAM,CAACC,SAAP,CAAiBC,QAAjB,CAA0BC,IAA1B,CAA+BN,EAA/B,MAAuC,gBAA1C,EAA4D;AAC1D;AACA,WAAKA,EAAL,GAAU,CAAV;AACA,WAAKC,EAAL,GAAU,CAAV;AACA,WAAKC,KAAL,GAAaF,EAAE,CAAChC,MAAhB,CAJ0D,CAK1D;AACA;;AACA,WAAKI,CAAL,GAASlC,MAAM,CAACoB,KAAP,CAAa,KAAK4C,KAAlB,CAAT;AACA,WAAKK,EAAL,GAAUrE,MAAM,CAACoB,KAAP,CAAa,KAAK4C,KAAlB,CAAV;;AACA,WAAI,IAAItC,CAAC,GAAC,CAAV,EAAYA,CAAC,GAAC,KAAKsC,KAAnB,EAAyBtC,CAAC,EAA1B,EAA8B;AAC5B,aAAKQ,CAAL,CAAOR,CAAP,IAAYoC,EAAE,CAACpC,CAAD,CAAd;AACD;AACF,KAZD,MAYO;AACL;AACA,WAAKoC,EAAL,GAAUA,EAAV;AACA,WAAKC,EAAL,GAAUA,EAAV;AACA,WAAKC,KAAL,GAAaA,KAAb;AACA,UAAI3C,CAAC,GAAGyC,EAAE,GAACC,EAAH,GAAMC,KAAd;AACA,WAAK9B,CAAL,GAASlC,MAAM,CAACoB,KAAP,CAAaC,CAAb,CAAT;AACA,WAAKgD,EAAL,GAAUrE,MAAM,CAACoB,KAAP,CAAaC,CAAb,CAAV;;AACA,UAAG,OAAOZ,CAAP,KAAa,WAAhB,EAA6B;AAC3B;AACA;AACA;AACA,YAAI6D,KAAK,GAAGjE,IAAI,CAACK,IAAL,CAAU,OAAKoD,EAAE,GAACC,EAAH,GAAMC,KAAX,CAAV,CAAZ;;AACA,aAAI,IAAItC,CAAC,GAAC,CAAV,EAAYA,CAAC,GAACL,CAAd,EAAgBK,CAAC,EAAjB,EAAqB;AACnB,eAAKQ,CAAL,CAAOR,CAAP,IAAY1B,MAAM,CAACiB,KAAP,CAAa,GAAb,EAAkBqD,KAAlB,CAAZ;AACD;AACF,OARD,MAQO;AACL,aAAI,IAAI5C,CAAC,GAAC,CAAV,EAAYA,CAAC,GAACL,CAAd,EAAgBK,CAAC,EAAjB,EAAqB;AACnB,eAAKQ,CAAL,CAAOR,CAAP,IAAYjB,CAAZ;AACD;AACF;AACF;AACF,GApCD;;AAsCAoD,EAAAA,GAAG,CAACK,SAAJ,GAAgB;AACdK,IAAAA,GAAG,EAAE,UAASC,CAAT,EAAYC,CAAZ,EAAeC,CAAf,EAAkB;AACrB,UAAIC,EAAE,GAAC,CAAE,KAAKb,EAAL,GAAUW,CAAX,GAAcD,CAAf,IAAkB,KAAKR,KAAvB,GAA6BU,CAApC;AACA,aAAO,KAAKxC,CAAL,CAAOyC,EAAP,CAAP;AACD,KAJa;AAKdC,IAAAA,GAAG,EAAE,UAASJ,CAAT,EAAYC,CAAZ,EAAeC,CAAf,EAAkBnE,CAAlB,EAAqB;AACxB,UAAIoE,EAAE,GAAC,CAAE,KAAKb,EAAL,GAAUW,CAAX,GAAcD,CAAf,IAAkB,KAAKR,KAAvB,GAA6BU,CAApC;AACA,WAAKxC,CAAL,CAAOyC,EAAP,IAAapE,CAAb;AACD,KARa;AASdsE,IAAAA,GAAG,EAAE,UAASL,CAAT,EAAYC,CAAZ,EAAeC,CAAf,EAAkBnE,CAAlB,EAAqB;AACxB,UAAIoE,EAAE,GAAC,CAAE,KAAKb,EAAL,GAAUW,CAAX,GAAcD,CAAf,IAAkB,KAAKR,KAAvB,GAA6BU,CAApC;AACA,WAAKxC,CAAL,CAAOyC,EAAP,KAAcpE,CAAd;AACD,KAZa;AAaduE,IAAAA,QAAQ,EAAE,UAASN,CAAT,EAAYC,CAAZ,EAAeC,CAAf,EAAkB;AAC1B,UAAIC,EAAE,GAAG,CAAE,KAAKb,EAAL,GAAUW,CAAX,GAAcD,CAAf,IAAkB,KAAKR,KAAvB,GAA6BU,CAAtC;AACA,aAAO,KAAKL,EAAL,CAAQM,EAAR,CAAP;AACD,KAhBa;AAiBdI,IAAAA,QAAQ,EAAE,UAASP,CAAT,EAAYC,CAAZ,EAAeC,CAAf,EAAkBnE,CAAlB,EAAqB;AAC7B,UAAIoE,EAAE,GAAG,CAAE,KAAKb,EAAL,GAAUW,CAAX,GAAcD,CAAf,IAAkB,KAAKR,KAAvB,GAA6BU,CAAtC;AACA,WAAKL,EAAL,CAAQM,EAAR,IAAcpE,CAAd;AACD,KApBa;AAqBdyE,IAAAA,QAAQ,EAAE,UAASR,CAAT,EAAYC,CAAZ,EAAeC,CAAf,EAAkBnE,CAAlB,EAAqB;AAC7B,UAAIoE,EAAE,GAAG,CAAE,KAAKb,EAAL,GAAUW,CAAX,GAAcD,CAAf,IAAkB,KAAKR,KAAvB,GAA6BU,CAAtC;AACA,WAAKL,EAAL,CAAQM,EAAR,KAAepE,CAAf;AACD,KAxBa;AAyBd0E,IAAAA,YAAY,EAAE,YAAW;AAAE,aAAO,IAAIpB,GAAJ,CAAQ,KAAKC,EAAb,EAAiB,KAAKC,EAAtB,EAA0B,KAAKC,KAA/B,EAAsC,GAAtC,CAAP;AAAkD,KAzB/D;AA0BdkB,IAAAA,KAAK,EAAE,YAAW;AAChB,UAAIC,CAAC,GAAG,IAAItB,GAAJ,CAAQ,KAAKC,EAAb,EAAiB,KAAKC,EAAtB,EAA0B,KAAKC,KAA/B,EAAsC,GAAtC,CAAR;AACA,UAAI3C,CAAC,GAAG,KAAKa,CAAL,CAAOJ,MAAf;;AACA,WAAI,IAAIJ,CAAC,GAAC,CAAV,EAAYA,CAAC,GAACL,CAAd,EAAgBK,CAAC,EAAjB,EAAqB;AAAEyD,QAAAA,CAAC,CAACjD,CAAF,CAAIR,CAAJ,IAAS,KAAKQ,CAAL,CAAOR,CAAP,CAAT;AAAqB;;AAC5C,aAAOyD,CAAP;AACD,KA/Ba;AAgCdC,IAAAA,OAAO,EAAE,UAASD,CAAT,EAAY;AAAE,WAAI,IAAIjC,CAAC,GAAC,CAAV,EAAYA,CAAC,GAAC,KAAKhB,CAAL,CAAOJ,MAArB,EAA4BoB,CAAC,EAA7B,EAAiC;AAAE,aAAKhB,CAAL,CAAOgB,CAAP,KAAaiC,CAAC,CAACjD,CAAF,CAAIgB,CAAJ,CAAb;AAAsB;AAAC,KAhCnE;AAiCdmC,IAAAA,aAAa,EAAE,UAASF,CAAT,EAAYtE,CAAZ,EAAe;AAAE,WAAI,IAAIqC,CAAC,GAAC,CAAV,EAAYA,CAAC,GAAC,KAAKhB,CAAL,CAAOJ,MAArB,EAA4BoB,CAAC,EAA7B,EAAiC;AAAE,aAAKhB,CAAL,CAAOgB,CAAP,KAAarC,CAAC,GAACsE,CAAC,CAACjD,CAAF,CAAIgB,CAAJ,CAAf;AAAwB;AAAC,KAjC9E;AAkCdoC,IAAAA,QAAQ,EAAE,UAASzE,CAAT,EAAY;AAAE,WAAI,IAAIqC,CAAC,GAAC,CAAV,EAAYA,CAAC,GAAC,KAAKhB,CAAL,CAAOJ,MAArB,EAA4BoB,CAAC,EAA7B,EAAiC;AAAE,aAAKhB,CAAL,CAAOgB,CAAP,IAAYrC,CAAZ;AAAgB;AAAC,KAlC9D;AAoCd0E,IAAAA,MAAM,EAAE,YAAW;AACjB;AACA,UAAIC,IAAI,GAAG,EAAX;AACAA,MAAAA,IAAI,CAAC1B,EAAL,GAAU,KAAKA,EAAf;AACA0B,MAAAA,IAAI,CAACzB,EAAL,GAAU,KAAKA,EAAf;AACAyB,MAAAA,IAAI,CAACxB,KAAL,GAAa,KAAKA,KAAlB;AACAwB,MAAAA,IAAI,CAACtD,CAAL,GAAS,KAAKA,CAAd;AACA,aAAOsD,IAAP,CAPiB,CAQjB;AACD,KA7Ca;AA8CdC,IAAAA,QAAQ,EAAE,UAASD,IAAT,EAAe;AACvB,WAAK1B,EAAL,GAAU0B,IAAI,CAAC1B,EAAf;AACA,WAAKC,EAAL,GAAUyB,IAAI,CAACzB,EAAf;AACA,WAAKC,KAAL,GAAawB,IAAI,CAACxB,KAAlB;AAEA,UAAI3C,CAAC,GAAG,KAAKyC,EAAL,GAAQ,KAAKC,EAAb,GAAgB,KAAKC,KAA7B;AACA,WAAK9B,CAAL,GAASlC,MAAM,CAACoB,KAAP,CAAaC,CAAb,CAAT;AACA,WAAKgD,EAAL,GAAUrE,MAAM,CAACoB,KAAP,CAAaC,CAAb,CAAV,CAPuB,CAQvB;;AACA,WAAI,IAAIK,CAAC,GAAC,CAAV,EAAYA,CAAC,GAACL,CAAd,EAAgBK,CAAC,EAAjB,EAAqB;AACnB,aAAKQ,CAAL,CAAOR,CAAP,IAAY8D,IAAI,CAACtD,CAAL,CAAOR,CAAP,CAAZ;AACD;AACF;AA1Da,GAAhB;AA6DA1B,EAAAA,MAAM,CAAC6D,GAAP,GAAaA,GAAb;AACD,CA9GD,EA8GG/D,SA9GH;;AA+GA,CAAC,UAASE,MAAT,EAAiB;AAChB;;AACA,MAAI6D,GAAG,GAAG7D,MAAM,CAAC6D,GAAjB,CAFgB,CAEM;AAEtB;AACA;AACA;AACA;AACA;;AACA,MAAI6B,OAAO,GAAG,UAASP,CAAT,EAAYQ,IAAZ,EAAkBC,EAAlB,EAAsBC,EAAtB,EAA0BC,MAA1B,EAAkC;AAC9C;AACA,QAAG,OAAOA,MAAP,KAAiB,WAApB,EAAiC,IAAIA,MAAM,GAAG,KAAb;AACjC,QAAG,OAAOF,EAAP,KAAa,WAAhB,EAA6B,IAAIA,EAAE,GAAG5F,MAAM,CAACe,KAAP,CAAa,CAAb,EAAgBoE,CAAC,CAACrB,EAAF,GAAO6B,IAAvB,CAAT;AAC7B,QAAG,OAAOE,EAAP,KAAa,WAAhB,EAA6B,IAAIA,EAAE,GAAG7F,MAAM,CAACe,KAAP,CAAa,CAAb,EAAgBoE,CAAC,CAACpB,EAAF,GAAO4B,IAAvB,CAAT,CAJiB,CAM9C;;AACA,QAAII,CAAJ;;AACA,QAAGJ,IAAI,KAAKR,CAAC,CAACrB,EAAX,IAAiB8B,EAAE,KAAG,CAAtB,IAA2BC,EAAE,KAAG,CAAnC,EAAsC;AACpCE,MAAAA,CAAC,GAAG,IAAIlC,GAAJ,CAAQ8B,IAAR,EAAcA,IAAd,EAAoBR,CAAC,CAACnB,KAAtB,EAA6B,GAA7B,CAAJ;;AACA,WAAI,IAAIQ,CAAC,GAAC,CAAV,EAAYA,CAAC,GAACmB,IAAd,EAAmBnB,CAAC,EAApB,EAAwB;AACtB,aAAI,IAAIC,CAAC,GAAC,CAAV,EAAYA,CAAC,GAACkB,IAAd,EAAmBlB,CAAC,EAApB,EAAwB;AACtB,cAAGD,CAAC,GAACoB,EAAF,GAAK,CAAL,IAAUpB,CAAC,GAACoB,EAAF,IAAMT,CAAC,CAACrB,EAAlB,IAAwBW,CAAC,GAACoB,EAAF,GAAK,CAA7B,IAAkCpB,CAAC,GAACoB,EAAF,IAAMV,CAAC,CAACpB,EAA7C,EAAiD,SAD3B,CACqC;;AAC3D,eAAI,IAAIW,CAAC,GAAC,CAAV,EAAYA,CAAC,GAACS,CAAC,CAACnB,KAAhB,EAAsBU,CAAC,EAAvB,EAA2B;AAC1BqB,YAAAA,CAAC,CAACnB,GAAF,CAAMJ,CAAN,EAAQC,CAAR,EAAUC,CAAV,EAAYS,CAAC,CAACZ,GAAF,CAAMC,CAAC,GAACoB,EAAR,EAAWnB,CAAC,GAACoB,EAAb,EAAgBnB,CAAhB,CAAZ,EAD0B,CACO;AACjC;AACF;AACF;AACF,KAVD,MAUO;AACLqB,MAAAA,CAAC,GAAGZ,CAAJ;AACD;;AAED,QAAGW,MAAH,EAAW;AACT;AACA,UAAIE,EAAE,GAAGD,CAAC,CAACd,YAAF,EAAT;;AACA,WAAI,IAAIT,CAAC,GAAC,CAAV,EAAYA,CAAC,GAACuB,CAAC,CAACjC,EAAhB,EAAmBU,CAAC,EAApB,EAAwB;AACtB,aAAI,IAAIC,CAAC,GAAC,CAAV,EAAYA,CAAC,GAACsB,CAAC,CAAChC,EAAhB,EAAmBU,CAAC,EAApB,EAAwB;AACtB,eAAI,IAAIC,CAAC,GAAC,CAAV,EAAYA,CAAC,GAACqB,CAAC,CAAC/B,KAAhB,EAAsBU,CAAC,EAAvB,EAA2B;AAC1BsB,YAAAA,EAAE,CAACpB,GAAH,CAAOJ,CAAP,EAASC,CAAT,EAAWC,CAAX,EAAaqB,CAAC,CAACxB,GAAF,CAAMwB,CAAC,CAACjC,EAAF,GAAOU,CAAP,GAAW,CAAjB,EAAmBC,CAAnB,EAAqBC,CAArB,CAAb,EAD0B,CACa;AACvC;AACF;AACF;;AACDqB,MAAAA,CAAC,GAAGC,EAAJ,CAVS,CAUD;AACT;;AACD,WAAOD,CAAP;AACD,GAnCD,CATgB,CA8ChB;AACA;;;AACA,MAAIE,UAAU,GAAG,UAASC,GAAT,EAAcC,iBAAd,EAAiC;AAEhD,QAAG,OAAOA,iBAAP,KAA4B,WAA/B,EAA4C,IAAIA,iBAAiB,GAAG,KAAxB;AAE5C,QAAIC,MAAM,GAAGC,QAAQ,CAACC,aAAT,CAAuB,QAAvB,CAAb;AACAF,IAAAA,MAAM,CAACG,KAAP,GAAeL,GAAG,CAACK,KAAnB;AACAH,IAAAA,MAAM,CAACI,MAAP,GAAgBN,GAAG,CAACM,MAApB;AACA,QAAIC,GAAG,GAAGL,MAAM,CAACM,UAAP,CAAkB,IAAlB,CAAV,CAPgD,CAShD;;AACA,QAAI;AACFD,MAAAA,GAAG,CAACE,SAAJ,CAAcT,GAAd,EAAmB,CAAnB,EAAsB,CAAtB;AACD,KAFD,CAEE,OAAOU,CAAP,EAAU;AACV,UAAIA,CAAC,CAACC,IAAF,KAAW,wBAAf,EAAyC;AACvC;AACA,eAAO,KAAP;AACD,OAHD,MAGO;AACL,cAAMD,CAAN;AACD;AACF;;AAED,QAAI;AACF,UAAIE,QAAQ,GAAGL,GAAG,CAACM,YAAJ,CAAiB,CAAjB,EAAoB,CAApB,EAAuBX,MAAM,CAACG,KAA9B,EAAqCH,MAAM,CAACI,MAA5C,CAAf;AACD,KAFD,CAEE,OAAOI,CAAP,EAAU;AACV,UAAGA,CAAC,CAACC,IAAF,KAAW,gBAAd,EAAgC;AAC9B,eAAO,KAAP,CAD8B,CAChB;AACf,OAFD,MAEO;AACL,cAAMD,CAAN;AACD;AACF,KA7B+C,CA+BhD;;;AACA,QAAI5D,CAAC,GAAG8D,QAAQ,CAACE,IAAjB;AACA,QAAIjB,CAAC,GAAGG,GAAG,CAACK,KAAZ;AACA,QAAIU,CAAC,GAAGf,GAAG,CAACM,MAAZ;AACA,QAAIU,EAAE,GAAG,EAAT;;AACA,SAAI,IAAIxF,CAAC,GAAC,CAAV,EAAYA,CAAC,GAACsB,CAAC,CAAClB,MAAhB,EAAuBJ,CAAC,EAAxB,EAA4B;AAC1BwF,MAAAA,EAAE,CAAClF,IAAH,CAAQgB,CAAC,CAACtB,CAAD,CAAD,GAAK,KAAL,GAAW,GAAnB,EAD0B,CACD;AAC1B;;AACD,QAAI8C,CAAC,GAAG,IAAIX,GAAJ,CAAQkC,CAAR,EAAWkB,CAAX,EAAc,CAAd,EAAiB,GAAjB,CAAR,CAvCgD,CAuCjB;;AAC/BzC,IAAAA,CAAC,CAACtC,CAAF,GAAMgF,EAAN;;AAEA,QAAGf,iBAAH,EAAsB;AACpB;AACA,UAAIgB,EAAE,GAAG,IAAItD,GAAJ,CAAQkC,CAAR,EAAWkB,CAAX,EAAc,CAAd,EAAiB,GAAjB,CAAT;;AACA,WAAI,IAAIvF,CAAC,GAAC,CAAV,EAAYA,CAAC,GAACqE,CAAd,EAAgBrE,CAAC,EAAjB,EAAqB;AACnB,aAAI,IAAIe,CAAC,GAAC,CAAV,EAAYA,CAAC,GAACwE,CAAd,EAAgBxE,CAAC,EAAjB,EAAqB;AACnB0E,UAAAA,EAAE,CAACvC,GAAH,CAAOlD,CAAP,EAASe,CAAT,EAAW,CAAX,EAAa+B,CAAC,CAACD,GAAF,CAAM7C,CAAN,EAAQe,CAAR,EAAU,CAAV,CAAb;AACD;AACF;;AACD+B,MAAAA,CAAC,GAAG2C,EAAJ;AACD;;AAED,WAAO3C,CAAP;AACD,GAtDD;;AAwDAxE,EAAAA,MAAM,CAAC0F,OAAP,GAAiBA,OAAjB;AACA1F,EAAAA,MAAM,CAACiG,UAAP,GAAoBA,UAApB;AAED,CA3GD,EA2GGnG,SA3GH;;AA4GA,CAAC,UAASE,MAAT,EAAiB;AAChB;;AACA,MAAI6D,GAAG,GAAG7D,MAAM,CAAC6D,GAAjB,CAFgB,CAEM;AAEtB;AACA;AACA;AACA;AACA;AACA;;AACA,MAAIuD,SAAS,GAAG,UAAShE,GAAT,EAAc;AAC5B,QAAIA,GAAG,GAAGA,GAAG,IAAI,EAAjB,CAD4B,CAG5B;;AACA,SAAKiE,SAAL,GAAiBjE,GAAG,CAACkE,OAArB;AACA,SAAKxD,EAAL,GAAUV,GAAG,CAACU,EAAd,CAL4B,CAKV;;AAClB,SAAKyD,QAAL,GAAgBnE,GAAG,CAACmE,QAApB;AACA,SAAKC,KAAL,GAAapE,GAAG,CAACoE,KAAjB;AACA,SAAKC,KAAL,GAAarE,GAAG,CAACqE,KAAjB,CAR4B,CAU5B;;AACA,SAAK1D,EAAL,GAAU,OAAOX,GAAG,CAACW,EAAX,KAAkB,WAAlB,GAAgCX,GAAG,CAACW,EAApC,GAAyC,KAAKD,EAAxD;AACA,SAAK4D,MAAL,GAAc,OAAOtE,GAAG,CAACsE,MAAX,KAAsB,WAAtB,GAAoCtE,GAAG,CAACsE,MAAxC,GAAiD,CAA/D,CAZ4B,CAYsC;;AAClE,SAAKC,GAAL,GAAW,OAAOvE,GAAG,CAACuE,GAAX,KAAmB,WAAnB,GAAiCvE,GAAG,CAACuE,GAArC,GAA2C,CAAtD,CAb4B,CAa6B;;AACzD,SAAKC,YAAL,GAAoB,OAAOxE,GAAG,CAACwE,YAAX,KAA4B,WAA5B,GAA0CxE,GAAG,CAACwE,YAA9C,GAA6D,GAAjF;AACA,SAAKC,YAAL,GAAoB,OAAOzE,GAAG,CAACyE,YAAX,KAA4B,WAA5B,GAA0CzE,GAAG,CAACyE,YAA9C,GAA6D,GAAjF,CAf4B,CAiB5B;AACA;AACA;AACA;;AACA,SAAKC,MAAL,GAAczH,IAAI,CAACW,KAAL,CAAW,CAAC,KAAKwG,KAAL,GAAa,KAAKG,GAAL,GAAW,CAAxB,GAA4B,KAAK7D,EAAlC,IAAwC,KAAK4D,MAA7C,GAAsD,CAAjE,CAAd;AACA,SAAKK,MAAL,GAAc1H,IAAI,CAACW,KAAL,CAAW,CAAC,KAAKyG,KAAL,GAAa,KAAKE,GAAL,GAAW,CAAxB,GAA4B,KAAK5D,EAAlC,IAAwC,KAAK2D,MAA7C,GAAsD,CAAjE,CAAd;AACA,SAAKM,UAAL,GAAkB,MAAlB,CAvB4B,CAyB5B;;AACA,QAAIC,IAAI,GAAG,OAAO7E,GAAG,CAAC8E,SAAX,KAAyB,WAAzB,GAAuC9E,GAAG,CAAC8E,SAA3C,GAAuD,GAAlE;AACA,SAAKZ,OAAL,GAAe,EAAf;;AACA,SAAI,IAAI5F,CAAC,GAAC,CAAV,EAAYA,CAAC,GAAC,KAAK2F,SAAnB,EAA6B3F,CAAC,EAA9B,EAAkC;AAAE,WAAK4F,OAAL,CAAatF,IAAb,CAAkB,IAAI6B,GAAJ,CAAQ,KAAKC,EAAb,EAAiB,KAAKC,EAAtB,EAA0B,KAAKwD,QAA/B,CAAlB;AAA8D;;AAClG,SAAKY,MAAL,GAAc,IAAItE,GAAJ,CAAQ,CAAR,EAAW,CAAX,EAAc,KAAKwD,SAAnB,EAA8BY,IAA9B,CAAd;AACD,GA9BD;;AA+BAb,EAAAA,SAAS,CAAClD,SAAV,GAAsB;AACpBkE,IAAAA,OAAO,EAAE,UAASjD,CAAT,EAAYkD,WAAZ,EAAyB;AAChC;AAEA,WAAKC,MAAL,GAAcnD,CAAd;AACA,UAAIoD,CAAC,GAAG,IAAI1E,GAAJ,CAAQ,KAAKiE,MAAL,GAAa,CAArB,EAAwB,KAAKC,MAAL,GAAa,CAArC,EAAwC,KAAKV,SAAL,GAAgB,CAAxD,EAA2D,GAA3D,CAAR;AAEA,UAAImB,IAAI,GAAGrD,CAAC,CAACrB,EAAF,GAAM,CAAjB;AACA,UAAI2E,IAAI,GAAGtD,CAAC,CAACpB,EAAF,GAAM,CAAjB;AACA,UAAI2E,SAAS,GAAG,KAAKhB,MAAL,GAAa,CAA7B;;AAEA,WAAI,IAAIhD,CAAC,GAAC,CAAV,EAAYA,CAAC,GAAC,KAAK2C,SAAnB,EAA6B3C,CAAC,EAA9B,EAAkC;AAChC,YAAIlB,CAAC,GAAG,KAAK8D,OAAL,CAAa5C,CAAb,CAAR;AACA,YAAIF,CAAC,GAAG,CAAC,KAAKmD,GAAN,GAAW,CAAnB;AACA,YAAIlD,CAAC,GAAG,CAAC,KAAKkD,GAAN,GAAW,CAAnB;;AACA,aAAI,IAAIgB,EAAE,GAAC,CAAX,EAAcA,EAAE,GAAC,KAAKZ,MAAtB,EAA8BtD,CAAC,IAAEiE,SAAH,EAAaC,EAAE,EAA7C,EAAiD;AAAG;AAClDnE,UAAAA,CAAC,GAAG,CAAC,KAAKmD,GAAN,GAAW,CAAf;;AACA,eAAI,IAAIiB,EAAE,GAAC,CAAX,EAAcA,EAAE,GAAC,KAAKd,MAAtB,EAA8BtD,CAAC,IAAEkE,SAAH,EAAaE,EAAE,EAA7C,EAAiD;AAAG;AAElD;AACA,gBAAI/H,CAAC,GAAG,GAAR;;AACA,iBAAI,IAAIgI,EAAE,GAAC,CAAX,EAAaA,EAAE,GAACrF,CAAC,CAACO,EAAlB,EAAqB8E,EAAE,EAAvB,EAA2B;AACzB,kBAAIC,EAAE,GAAGrE,CAAC,GAACoE,EAAX,CADyB,CACV;;AACf,mBAAI,IAAIE,EAAE,GAAC,CAAX,EAAaA,EAAE,GAACvF,CAAC,CAACM,EAAlB,EAAqBiF,EAAE,EAAvB,EAA2B;AACzB,oBAAIC,EAAE,GAAGxE,CAAC,GAACuE,EAAX;;AACA,oBAAGD,EAAE,IAAE,CAAJ,IAASA,EAAE,GAACL,IAAZ,IAAoBO,EAAE,IAAE,CAAxB,IAA6BA,EAAE,GAACR,IAAnC,EAAyC;AACvC,uBAAI,IAAIS,EAAE,GAAC,CAAX,EAAaA,EAAE,GAACzF,CAAC,CAACQ,KAAlB,EAAwBiF,EAAE,EAA1B,EAA8B;AAC5B;AACApI,oBAAAA,CAAC,IAAI2C,CAAC,CAACtB,CAAF,CAAI,CAAEsB,CAAC,CAACM,EAAF,GAAO+E,EAAR,GAAYE,EAAb,IAAiBvF,CAAC,CAACQ,KAAnB,GAAyBiF,EAA7B,IAAmC9D,CAAC,CAACjD,CAAF,CAAI,CAAEsG,IAAI,GAAGM,EAAR,GAAYE,EAAb,IAAiB7D,CAAC,CAACnB,KAAnB,GAAyBiF,EAA7B,CAAxC;AACD;AACF;AACF;AACF;;AACDpI,YAAAA,CAAC,IAAI,KAAKsH,MAAL,CAAYjG,CAAZ,CAAcwC,CAAd,CAAL;AACA6D,YAAAA,CAAC,CAAC3D,GAAF,CAAMgE,EAAN,EAAUD,EAAV,EAAcjE,CAAd,EAAiB7D,CAAjB;AACD;AACF;AACF;;AACD,WAAKqI,OAAL,GAAeX,CAAf;AACA,aAAO,KAAKW,OAAZ;AACD,KAxCmB;AAyCpBC,IAAAA,QAAQ,EAAE,YAAW;AAEnB,UAAIhE,CAAC,GAAG,KAAKmD,MAAb;AACAnD,MAAAA,CAAC,CAACd,EAAF,GAAOrE,MAAM,CAACoB,KAAP,CAAa+D,CAAC,CAACjD,CAAF,CAAIJ,MAAjB,CAAP,CAHmB,CAGc;;AAEjC,UAAI0G,IAAI,GAAGrD,CAAC,CAACrB,EAAF,GAAM,CAAjB;AACA,UAAI2E,IAAI,GAAGtD,CAAC,CAACpB,EAAF,GAAM,CAAjB;AACA,UAAI2E,SAAS,GAAG,KAAKhB,MAAL,GAAa,CAA7B;;AAEA,WAAI,IAAIhD,CAAC,GAAC,CAAV,EAAYA,CAAC,GAAC,KAAK2C,SAAnB,EAA6B3C,CAAC,EAA9B,EAAkC;AAChC,YAAIlB,CAAC,GAAG,KAAK8D,OAAL,CAAa5C,CAAb,CAAR;AACA,YAAIF,CAAC,GAAG,CAAC,KAAKmD,GAAN,GAAW,CAAnB;AACA,YAAIlD,CAAC,GAAG,CAAC,KAAKkD,GAAN,GAAW,CAAnB;;AACA,aAAI,IAAIgB,EAAE,GAAC,CAAX,EAAcA,EAAE,GAAC,KAAKZ,MAAtB,EAA8BtD,CAAC,IAAEiE,SAAH,EAAaC,EAAE,EAA7C,EAAiD;AAAG;AAClDnE,UAAAA,CAAC,GAAG,CAAC,KAAKmD,GAAN,GAAW,CAAf;;AACA,eAAI,IAAIiB,EAAE,GAAC,CAAX,EAAcA,EAAE,GAAC,KAAKd,MAAtB,EAA8BtD,CAAC,IAAEkE,SAAH,EAAaE,EAAE,EAA7C,EAAiD;AAAG;AAElD;AACA,gBAAIQ,UAAU,GAAG,KAAKF,OAAL,CAAapE,QAAb,CAAsB8D,EAAtB,EAAyBD,EAAzB,EAA4BjE,CAA5B,CAAjB,CAH+C,CAGE;;AACjD,iBAAI,IAAImE,EAAE,GAAC,CAAX,EAAaA,EAAE,GAACrF,CAAC,CAACO,EAAlB,EAAqB8E,EAAE,EAAvB,EAA2B;AACzB,kBAAIC,EAAE,GAAGrE,CAAC,GAACoE,EAAX,CADyB,CACV;;AACf,mBAAI,IAAIE,EAAE,GAAC,CAAX,EAAaA,EAAE,GAACvF,CAAC,CAACM,EAAlB,EAAqBiF,EAAE,EAAvB,EAA2B;AACzB,oBAAIC,EAAE,GAAGxE,CAAC,GAACuE,EAAX;;AACA,oBAAGD,EAAE,IAAE,CAAJ,IAASA,EAAE,GAACL,IAAZ,IAAoBO,EAAE,IAAE,CAAxB,IAA6BA,EAAE,GAACR,IAAnC,EAAyC;AACvC,uBAAI,IAAIS,EAAE,GAAC,CAAX,EAAaA,EAAE,GAACzF,CAAC,CAACQ,KAAlB,EAAwBiF,EAAE,EAA1B,EAA8B;AAC5B;AACA,wBAAII,GAAG,GAAG,CAAEb,IAAI,GAAGM,EAAR,GAAYE,EAAb,IAAiB7D,CAAC,CAACnB,KAAnB,GAAyBiF,EAAnC;AACA,wBAAIK,GAAG,GAAG,CAAE9F,CAAC,CAACM,EAAF,GAAO+E,EAAR,GAAYE,EAAb,IAAiBvF,CAAC,CAACQ,KAAnB,GAAyBiF,EAAnC;AACAzF,oBAAAA,CAAC,CAACa,EAAF,CAAKiF,GAAL,KAAanE,CAAC,CAACjD,CAAF,CAAImH,GAAJ,IAASD,UAAtB;AACAjE,oBAAAA,CAAC,CAACd,EAAF,CAAKgF,GAAL,KAAa7F,CAAC,CAACtB,CAAF,CAAIoH,GAAJ,IAASF,UAAtB;AACD;AACF;AACF;AACF;;AACD,iBAAKjB,MAAL,CAAY9D,EAAZ,CAAeK,CAAf,KAAqB0E,UAArB;AACD;AACF;AACF;AACF,KA/EmB;AAgFpBG,IAAAA,iBAAiB,EAAE,YAAW;AAC5B,UAAIC,QAAQ,GAAG,EAAf;;AACA,WAAI,IAAI9H,CAAC,GAAC,CAAV,EAAYA,CAAC,GAAC,KAAK2F,SAAnB,EAA6B3F,CAAC,EAA9B,EAAkC;AAChC8H,QAAAA,QAAQ,CAACxH,IAAT,CAAc;AAACyH,UAAAA,MAAM,EAAE,KAAKnC,OAAL,CAAa5F,CAAb,EAAgBQ,CAAzB;AAA4BwH,UAAAA,KAAK,EAAE,KAAKpC,OAAL,CAAa5F,CAAb,EAAgB2C,EAAnD;AAAuDwD,UAAAA,YAAY,EAAE,KAAKA,YAA1E;AAAwFD,UAAAA,YAAY,EAAE,KAAKA;AAA3G,SAAd;AACD;;AACD4B,MAAAA,QAAQ,CAACxH,IAAT,CAAc;AAACyH,QAAAA,MAAM,EAAE,KAAKtB,MAAL,CAAYjG,CAArB;AAAwBwH,QAAAA,KAAK,EAAE,KAAKvB,MAAL,CAAY9D,EAA3C;AAA+CuD,QAAAA,YAAY,EAAE,GAA7D;AAAkEC,QAAAA,YAAY,EAAE;AAAhF,OAAd;AACA,aAAO2B,QAAP;AACD,KAvFmB;AAwFpBjE,IAAAA,MAAM,EAAE,YAAW;AACjB,UAAIC,IAAI,GAAG,EAAX;AACAA,MAAAA,IAAI,CAAC1B,EAAL,GAAU,KAAKA,EAAf,CAFiB,CAEE;;AACnB0B,MAAAA,IAAI,CAACzB,EAAL,GAAU,KAAKA,EAAf;AACAyB,MAAAA,IAAI,CAACkC,MAAL,GAAc,KAAKA,MAAnB;AACAlC,MAAAA,IAAI,CAAC+B,QAAL,GAAgB,KAAKA,QAArB;AACA/B,MAAAA,IAAI,CAAC6B,SAAL,GAAiB,KAAKA,SAAtB;AACA7B,MAAAA,IAAI,CAACsC,MAAL,GAAc,KAAKA,MAAnB;AACAtC,MAAAA,IAAI,CAACuC,MAAL,GAAc,KAAKA,MAAnB;AACAvC,MAAAA,IAAI,CAACwC,UAAL,GAAkB,KAAKA,UAAvB;AACAxC,MAAAA,IAAI,CAACoC,YAAL,GAAoB,KAAKA,YAAzB;AACApC,MAAAA,IAAI,CAACqC,YAAL,GAAoB,KAAKA,YAAzB;AACArC,MAAAA,IAAI,CAACmC,GAAL,GAAW,KAAKA,GAAhB;AACAnC,MAAAA,IAAI,CAAC8B,OAAL,GAAe,EAAf;;AACA,WAAI,IAAI5F,CAAC,GAAC,CAAV,EAAYA,CAAC,GAAC,KAAK4F,OAAL,CAAaxF,MAA3B,EAAkCJ,CAAC,EAAnC,EAAuC;AACrC8D,QAAAA,IAAI,CAAC8B,OAAL,CAAatF,IAAb,CAAkB,KAAKsF,OAAL,CAAa5F,CAAb,EAAgB6D,MAAhB,EAAlB;AACD;;AACDC,MAAAA,IAAI,CAAC2C,MAAL,GAAc,KAAKA,MAAL,CAAY5C,MAAZ,EAAd;AACA,aAAOC,IAAP;AACD,KA3GmB;AA4GpBC,IAAAA,QAAQ,EAAE,UAASD,IAAT,EAAe;AACvB,WAAK6B,SAAL,GAAiB7B,IAAI,CAAC6B,SAAtB;AACA,WAAKS,MAAL,GAActC,IAAI,CAACsC,MAAnB;AACA,WAAKC,MAAL,GAAcvC,IAAI,CAACuC,MAAnB;AACA,WAAKC,UAAL,GAAkBxC,IAAI,CAACwC,UAAvB;AACA,WAAKlE,EAAL,GAAU0B,IAAI,CAAC1B,EAAf,CALuB,CAKJ;;AACnB,WAAKC,EAAL,GAAUyB,IAAI,CAACzB,EAAf;AACA,WAAK2D,MAAL,GAAclC,IAAI,CAACkC,MAAnB;AACA,WAAKH,QAAL,GAAgB/B,IAAI,CAAC+B,QAArB,CARuB,CAQQ;;AAC/B,WAAKD,OAAL,GAAe,EAAf;AACA,WAAKM,YAAL,GAAoB,OAAOpC,IAAI,CAACoC,YAAZ,KAA6B,WAA7B,GAA2CpC,IAAI,CAACoC,YAAhD,GAA+D,GAAnF;AACA,WAAKC,YAAL,GAAoB,OAAOrC,IAAI,CAACqC,YAAZ,KAA6B,WAA7B,GAA2CrC,IAAI,CAACqC,YAAhD,GAA+D,GAAnF;AACA,WAAKF,GAAL,GAAW,OAAOnC,IAAI,CAACmC,GAAZ,KAAoB,WAApB,GAAkCnC,IAAI,CAACmC,GAAvC,GAA6C,CAAxD;;AACA,WAAI,IAAIjG,CAAC,GAAC,CAAV,EAAYA,CAAC,GAAC8D,IAAI,CAAC8B,OAAL,CAAaxF,MAA3B,EAAkCJ,CAAC,EAAnC,EAAuC;AACrC,YAAInB,CAAC,GAAG,IAAIsD,GAAJ,CAAQ,CAAR,EAAU,CAAV,EAAY,CAAZ,EAAc,CAAd,CAAR;AACAtD,QAAAA,CAAC,CAACkF,QAAF,CAAWD,IAAI,CAAC8B,OAAL,CAAa5F,CAAb,CAAX;AACA,aAAK4F,OAAL,CAAatF,IAAb,CAAkBzB,CAAlB;AACD;;AACD,WAAK4H,MAAL,GAAc,IAAItE,GAAJ,CAAQ,CAAR,EAAU,CAAV,EAAY,CAAZ,EAAc,CAAd,CAAd;AACA,WAAKsE,MAAL,CAAY1C,QAAZ,CAAqBD,IAAI,CAAC2C,MAA1B;AACD;AAhImB,GAAtB;;AAmIA,MAAIwB,cAAc,GAAG,UAASvG,GAAT,EAAc;AACjC,QAAIA,GAAG,GAAGA,GAAG,IAAI,EAAjB,CADiC,CAGjC;AACA;;AACA,SAAKiE,SAAL,GAAiB,OAAOjE,GAAG,CAACwG,WAAX,KAA2B,WAA3B,GAAyCxG,GAAG,CAACwG,WAA7C,GAA2DxG,GAAG,CAACkE,OAAhF,CALiC,CAOjC;;AACA,SAAKM,YAAL,GAAoB,OAAOxE,GAAG,CAACwE,YAAX,KAA4B,WAA5B,GAA0CxE,GAAG,CAACwE,YAA9C,GAA6D,GAAjF;AACA,SAAKC,YAAL,GAAoB,OAAOzE,GAAG,CAACyE,YAAX,KAA4B,WAA5B,GAA0CzE,GAAG,CAACyE,YAA9C,GAA6D,GAAjF,CATiC,CAWjC;;AACA,SAAKgC,UAAL,GAAkBzG,GAAG,CAACoE,KAAJ,GAAYpE,GAAG,CAACqE,KAAhB,GAAwBrE,GAAG,CAACmE,QAA9C;AACA,SAAKO,MAAL,GAAc,CAAd;AACA,SAAKC,MAAL,GAAc,CAAd;AACA,SAAKC,UAAL,GAAkB,IAAlB,CAfiC,CAiBjC;;AACA,QAAIC,IAAI,GAAG,OAAO7E,GAAG,CAAC8E,SAAX,KAAyB,WAAzB,GAAuC9E,GAAG,CAAC8E,SAA3C,GAAuD,GAAlE;AACA,SAAKZ,OAAL,GAAe,EAAf;;AACA,SAAI,IAAI5F,CAAC,GAAC,CAAV,EAAYA,CAAC,GAAC,KAAK2F,SAAnB,EAA8B3F,CAAC,EAA/B,EAAmC;AAAE,WAAK4F,OAAL,CAAatF,IAAb,CAAkB,IAAI6B,GAAJ,CAAQ,CAAR,EAAW,CAAX,EAAc,KAAKgG,UAAnB,CAAlB;AAAoD;;AACzF,SAAK1B,MAAL,GAAc,IAAItE,GAAJ,CAAQ,CAAR,EAAW,CAAX,EAAc,KAAKwD,SAAnB,EAA8BY,IAA9B,CAAd;AACD,GAtBD;;AAwBA0B,EAAAA,cAAc,CAACzF,SAAf,GAA2B;AACzBkE,IAAAA,OAAO,EAAE,UAASjD,CAAT,EAAYkD,WAAZ,EAAyB;AAChC,WAAKC,MAAL,GAAcnD,CAAd;AACA,UAAIoD,CAAC,GAAG,IAAI1E,GAAJ,CAAQ,CAAR,EAAW,CAAX,EAAc,KAAKwD,SAAnB,EAA8B,GAA9B,CAAR;AACA,UAAIyC,EAAE,GAAG3E,CAAC,CAACjD,CAAX;;AACA,WAAI,IAAIR,CAAC,GAAC,CAAV,EAAYA,CAAC,GAAC,KAAK2F,SAAnB,EAA6B3F,CAAC,EAA9B,EAAkC;AAChC,YAAIb,CAAC,GAAG,GAAR;AACA,YAAIkJ,EAAE,GAAG,KAAKzC,OAAL,CAAa5F,CAAb,EAAgBQ,CAAzB;;AACA,aAAI,IAAIwC,CAAC,GAAC,CAAV,EAAYA,CAAC,GAAC,KAAKmF,UAAnB,EAA8BnF,CAAC,EAA/B,EAAmC;AACjC7D,UAAAA,CAAC,IAAIiJ,EAAE,CAACpF,CAAD,CAAF,GAAQqF,EAAE,CAACrF,CAAD,CAAf,CADiC,CACb;AACrB;;AACD7D,QAAAA,CAAC,IAAI,KAAKsH,MAAL,CAAYjG,CAAZ,CAAcR,CAAd,CAAL;AACA6G,QAAAA,CAAC,CAACrG,CAAF,CAAIR,CAAJ,IAASb,CAAT;AACD;;AACD,WAAKqI,OAAL,GAAeX,CAAf;AACA,aAAO,KAAKW,OAAZ;AACD,KAhBwB;AAiBzBC,IAAAA,QAAQ,EAAE,YAAW;AACnB,UAAIhE,CAAC,GAAG,KAAKmD,MAAb;AACAnD,MAAAA,CAAC,CAACd,EAAF,GAAOrE,MAAM,CAACoB,KAAP,CAAa+D,CAAC,CAACjD,CAAF,CAAIJ,MAAjB,CAAP,CAFmB,CAEc;AAEjC;;AACA,WAAI,IAAIJ,CAAC,GAAC,CAAV,EAAYA,CAAC,GAAC,KAAK2F,SAAnB,EAA6B3F,CAAC,EAA9B,EAAkC;AAChC,YAAIsI,GAAG,GAAG,KAAK1C,OAAL,CAAa5F,CAAb,CAAV;AACA,YAAI0H,UAAU,GAAG,KAAKF,OAAL,CAAa7E,EAAb,CAAgB3C,CAAhB,CAAjB;;AACA,aAAI,IAAIgD,CAAC,GAAC,CAAV,EAAYA,CAAC,GAAC,KAAKmF,UAAnB,EAA8BnF,CAAC,EAA/B,EAAmC;AACjCS,UAAAA,CAAC,CAACd,EAAF,CAAKK,CAAL,KAAWsF,GAAG,CAAC9H,CAAJ,CAAMwC,CAAN,IAAS0E,UAApB,CADiC,CACD;;AAChCY,UAAAA,GAAG,CAAC3F,EAAJ,CAAOK,CAAP,KAAaS,CAAC,CAACjD,CAAF,CAAIwC,CAAJ,IAAO0E,UAApB,CAFiC,CAED;AACjC;;AACD,aAAKjB,MAAL,CAAY9D,EAAZ,CAAe3C,CAAf,KAAqB0H,UAArB;AACD;AACF,KA/BwB;AAgCzBG,IAAAA,iBAAiB,EAAE,YAAW;AAC5B,UAAIC,QAAQ,GAAG,EAAf;;AACA,WAAI,IAAI9H,CAAC,GAAC,CAAV,EAAYA,CAAC,GAAC,KAAK2F,SAAnB,EAA6B3F,CAAC,EAA9B,EAAkC;AAChC8H,QAAAA,QAAQ,CAACxH,IAAT,CAAc;AAACyH,UAAAA,MAAM,EAAE,KAAKnC,OAAL,CAAa5F,CAAb,EAAgBQ,CAAzB;AAA4BwH,UAAAA,KAAK,EAAE,KAAKpC,OAAL,CAAa5F,CAAb,EAAgB2C,EAAnD;AAAuDuD,UAAAA,YAAY,EAAE,KAAKA,YAA1E;AAAwFC,UAAAA,YAAY,EAAE,KAAKA;AAA3G,SAAd;AACD;;AACD2B,MAAAA,QAAQ,CAACxH,IAAT,CAAc;AAACyH,QAAAA,MAAM,EAAE,KAAKtB,MAAL,CAAYjG,CAArB;AAAwBwH,QAAAA,KAAK,EAAE,KAAKvB,MAAL,CAAY9D,EAA3C;AAA+CuD,QAAAA,YAAY,EAAE,GAA7D;AAAkEC,QAAAA,YAAY,EAAE;AAAhF,OAAd;AACA,aAAO2B,QAAP;AACD,KAvCwB;AAwCzBjE,IAAAA,MAAM,EAAE,YAAW;AACjB,UAAIC,IAAI,GAAG,EAAX;AACAA,MAAAA,IAAI,CAAC6B,SAAL,GAAiB,KAAKA,SAAtB;AACA7B,MAAAA,IAAI,CAACsC,MAAL,GAAc,KAAKA,MAAnB;AACAtC,MAAAA,IAAI,CAACuC,MAAL,GAAc,KAAKA,MAAnB;AACAvC,MAAAA,IAAI,CAACwC,UAAL,GAAkB,KAAKA,UAAvB;AACAxC,MAAAA,IAAI,CAACqE,UAAL,GAAkB,KAAKA,UAAvB;AACArE,MAAAA,IAAI,CAACoC,YAAL,GAAoB,KAAKA,YAAzB;AACApC,MAAAA,IAAI,CAACqC,YAAL,GAAoB,KAAKA,YAAzB;AACArC,MAAAA,IAAI,CAAC8B,OAAL,GAAe,EAAf;;AACA,WAAI,IAAI5F,CAAC,GAAC,CAAV,EAAYA,CAAC,GAAC,KAAK4F,OAAL,CAAaxF,MAA3B,EAAkCJ,CAAC,EAAnC,EAAuC;AACrC8D,QAAAA,IAAI,CAAC8B,OAAL,CAAatF,IAAb,CAAkB,KAAKsF,OAAL,CAAa5F,CAAb,EAAgB6D,MAAhB,EAAlB;AACD;;AACDC,MAAAA,IAAI,CAAC2C,MAAL,GAAc,KAAKA,MAAL,CAAY5C,MAAZ,EAAd;AACA,aAAOC,IAAP;AACD,KAvDwB;AAwDzBC,IAAAA,QAAQ,EAAE,UAASD,IAAT,EAAe;AACvB,WAAK6B,SAAL,GAAiB7B,IAAI,CAAC6B,SAAtB;AACA,WAAKS,MAAL,GAActC,IAAI,CAACsC,MAAnB;AACA,WAAKC,MAAL,GAAcvC,IAAI,CAACuC,MAAnB;AACA,WAAKC,UAAL,GAAkBxC,IAAI,CAACwC,UAAvB;AACA,WAAK6B,UAAL,GAAkBrE,IAAI,CAACqE,UAAvB;AACA,WAAKjC,YAAL,GAAoB,OAAOpC,IAAI,CAACoC,YAAZ,KAA6B,WAA7B,GAA2CpC,IAAI,CAACoC,YAAhD,GAA+D,GAAnF;AACA,WAAKC,YAAL,GAAoB,OAAOrC,IAAI,CAACqC,YAAZ,KAA6B,WAA7B,GAA2CrC,IAAI,CAACqC,YAAhD,GAA+D,GAAnF;AACA,WAAKP,OAAL,GAAe,EAAf;;AACA,WAAI,IAAI5F,CAAC,GAAC,CAAV,EAAYA,CAAC,GAAC8D,IAAI,CAAC8B,OAAL,CAAaxF,MAA3B,EAAkCJ,CAAC,EAAnC,EAAuC;AACrC,YAAInB,CAAC,GAAG,IAAIsD,GAAJ,CAAQ,CAAR,EAAU,CAAV,EAAY,CAAZ,EAAc,CAAd,CAAR;AACAtD,QAAAA,CAAC,CAACkF,QAAF,CAAWD,IAAI,CAAC8B,OAAL,CAAa5F,CAAb,CAAX;AACA,aAAK4F,OAAL,CAAatF,IAAb,CAAkBzB,CAAlB;AACD;;AACD,WAAK4H,MAAL,GAAc,IAAItE,GAAJ,CAAQ,CAAR,EAAU,CAAV,EAAY,CAAZ,EAAc,CAAd,CAAd;AACA,WAAKsE,MAAL,CAAY1C,QAAZ,CAAqBD,IAAI,CAAC2C,MAA1B;AACD;AAxEwB,GAA3B;AA2EAnI,EAAAA,MAAM,CAACoH,SAAP,GAAmBA,SAAnB;AACApH,EAAAA,MAAM,CAAC2J,cAAP,GAAwBA,cAAxB;AAED,CAlRD,EAkRG7J,SAlRH;;AAmRA,CAAC,UAASE,MAAT,EAAiB;AAChB;;AACA,MAAI6D,GAAG,GAAG7D,MAAM,CAAC6D,GAAjB,CAFgB,CAEM;;AAEtB,MAAIoG,SAAS,GAAG,UAAS7G,GAAT,EAAc;AAE5B,QAAIA,GAAG,GAAGA,GAAG,IAAI,EAAjB,CAF4B,CAI5B;;AACA,SAAKU,EAAL,GAAUV,GAAG,CAACU,EAAd,CAL4B,CAKV;;AAClB,SAAKyD,QAAL,GAAgBnE,GAAG,CAACmE,QAApB;AACA,SAAKC,KAAL,GAAapE,GAAG,CAACoE,KAAjB;AACA,SAAKC,KAAL,GAAarE,GAAG,CAACqE,KAAjB,CAR4B,CAU5B;;AACA,SAAK1D,EAAL,GAAU,OAAOX,GAAG,CAACW,EAAX,KAAkB,WAAlB,GAAgCX,GAAG,CAACW,EAApC,GAAyC,KAAKD,EAAxD;AACA,SAAK4D,MAAL,GAAc,OAAOtE,GAAG,CAACsE,MAAX,KAAsB,WAAtB,GAAoCtE,GAAG,CAACsE,MAAxC,GAAiD,CAA/D;AACA,SAAKC,GAAL,GAAW,OAAOvE,GAAG,CAACuE,GAAX,KAAmB,WAAnB,GAAiCvE,GAAG,CAACuE,GAArC,GAA2C,CAAtD,CAb4B,CAa6B;AAEzD;;AACA,SAAKN,SAAL,GAAiB,KAAKE,QAAtB;AACA,SAAKO,MAAL,GAAczH,IAAI,CAACW,KAAL,CAAW,CAAC,KAAKwG,KAAL,GAAa,KAAKG,GAAL,GAAW,CAAxB,GAA4B,KAAK7D,EAAlC,IAAwC,KAAK4D,MAA7C,GAAsD,CAAjE,CAAd;AACA,SAAKK,MAAL,GAAc1H,IAAI,CAACW,KAAL,CAAW,CAAC,KAAKyG,KAAL,GAAa,KAAKE,GAAL,GAAW,CAAxB,GAA4B,KAAK5D,EAAlC,IAAwC,KAAK2D,MAA7C,GAAsD,CAAjE,CAAd;AACA,SAAKM,UAAL,GAAkB,MAAlB,CAnB4B,CAoB5B;;AACA,SAAKkC,OAAL,GAAelK,MAAM,CAACoB,KAAP,CAAa,KAAK0G,MAAL,GAAY,KAAKC,MAAjB,GAAwB,KAAKV,SAA1C,CAAf;AACA,SAAK8C,OAAL,GAAenK,MAAM,CAACoB,KAAP,CAAa,KAAK0G,MAAL,GAAY,KAAKC,MAAjB,GAAwB,KAAKV,SAA1C,CAAf;AACD,GAvBD;;AAyBA4C,EAAAA,SAAS,CAAC/F,SAAV,GAAsB;AACpBkE,IAAAA,OAAO,EAAE,UAASjD,CAAT,EAAYkD,WAAZ,EAAyB;AAChC,WAAKC,MAAL,GAAcnD,CAAd;AAEA,UAAIoD,CAAC,GAAG,IAAI1E,GAAJ,CAAQ,KAAKiE,MAAb,EAAqB,KAAKC,MAA1B,EAAkC,KAAKV,SAAvC,EAAkD,GAAlD,CAAR;AAEA,UAAIhG,CAAC,GAAC,CAAN,CALgC,CAKvB;;AACT,WAAI,IAAIqD,CAAC,GAAC,CAAV,EAAYA,CAAC,GAAC,KAAK2C,SAAnB,EAA6B3C,CAAC,EAA9B,EAAkC;AAChC,YAAIF,CAAC,GAAG,CAAC,KAAKmD,GAAd;AACA,YAAIlD,CAAC,GAAG,CAAC,KAAKkD,GAAd;;AACA,aAAI,IAAIiB,EAAE,GAAC,CAAX,EAAcA,EAAE,GAAC,KAAKd,MAAtB,EAA8BtD,CAAC,IAAE,KAAKkD,MAAR,EAAekB,EAAE,EAA/C,EAAmD;AACjDnE,UAAAA,CAAC,GAAG,CAAC,KAAKkD,GAAV;;AACA,eAAI,IAAIgB,EAAE,GAAC,CAAX,EAAcA,EAAE,GAAC,KAAKZ,MAAtB,EAA8BtD,CAAC,IAAE,KAAKiD,MAAR,EAAeiB,EAAE,EAA/C,EAAmD;AAEjD;AACA,gBAAI9H,CAAC,GAAG,CAAC,KAAT,CAHiD,CAGjC;;AAChB,gBAAIuJ,IAAI,GAAC,CAAC,CAAV;AAAA,gBAAYC,IAAI,GAAC,CAAC,CAAlB;;AACA,iBAAI,IAAItB,EAAE,GAAC,CAAX,EAAaA,EAAE,GAAC,KAAKjF,EAArB,EAAwBiF,EAAE,EAA1B,EAA8B;AAC5B,mBAAI,IAAIF,EAAE,GAAC,CAAX,EAAaA,EAAE,GAAC,KAAK9E,EAArB,EAAwB8E,EAAE,EAA1B,EAA8B;AAC5B,oBAAIC,EAAE,GAAGrE,CAAC,GAACoE,EAAX;AACA,oBAAIG,EAAE,GAAGxE,CAAC,GAACuE,EAAX;;AACA,oBAAGD,EAAE,IAAE,CAAJ,IAASA,EAAE,GAAC3D,CAAC,CAACpB,EAAd,IAAoBiF,EAAE,IAAE,CAAxB,IAA6BA,EAAE,GAAC7D,CAAC,CAACrB,EAArC,EAAyC;AACvC,sBAAIvD,CAAC,GAAG4E,CAAC,CAACZ,GAAF,CAAMyE,EAAN,EAAUF,EAAV,EAAcpE,CAAd,CAAR,CADuC,CAEvC;AACA;AACA;;AACA,sBAAGnE,CAAC,GAAGM,CAAP,EAAU;AAAEA,oBAAAA,CAAC,GAAGN,CAAJ;AAAO6J,oBAAAA,IAAI,GAACpB,EAAL;AAASqB,oBAAAA,IAAI,GAACvB,EAAL;AAAS;AACtC;AACF;AACF;;AACD,iBAAKoB,OAAL,CAAa7I,CAAb,IAAkB+I,IAAlB;AACA,iBAAKD,OAAL,CAAa9I,CAAb,IAAkBgJ,IAAlB;AACAhJ,YAAAA,CAAC;AACDkH,YAAAA,CAAC,CAAC3D,GAAF,CAAMgE,EAAN,EAAUD,EAAV,EAAcjE,CAAd,EAAiB7D,CAAjB;AACD;AACF;AACF;;AACD,WAAKqI,OAAL,GAAeX,CAAf;AACA,aAAO,KAAKW,OAAZ;AACD,KAvCmB;AAwCpBC,IAAAA,QAAQ,EAAE,YAAW;AACnB;AACA;AACA,UAAIhE,CAAC,GAAG,KAAKmD,MAAb;AACAnD,MAAAA,CAAC,CAACd,EAAF,GAAOrE,MAAM,CAACoB,KAAP,CAAa+D,CAAC,CAACjD,CAAF,CAAIJ,MAAjB,CAAP,CAJmB,CAIc;;AACjC,UAAIyG,CAAC,GAAG,KAAKW,OAAb,CALmB,CAKG;;AAEtB,UAAI7H,CAAC,GAAG,CAAR;;AACA,WAAI,IAAIqD,CAAC,GAAC,CAAV,EAAYA,CAAC,GAAC,KAAK2C,SAAnB,EAA6B3C,CAAC,EAA9B,EAAkC;AAChC,YAAIF,CAAC,GAAG,CAAC,KAAKmD,GAAd;AACA,YAAIlD,CAAC,GAAG,CAAC,KAAKkD,GAAd;;AACA,aAAI,IAAIiB,EAAE,GAAC,CAAX,EAAcA,EAAE,GAAC,KAAKd,MAAtB,EAA8BtD,CAAC,IAAE,KAAKkD,MAAR,EAAekB,EAAE,EAA/C,EAAmD;AACjDnE,UAAAA,CAAC,GAAG,CAAC,KAAKkD,GAAV;;AACA,eAAI,IAAIgB,EAAE,GAAC,CAAX,EAAcA,EAAE,GAAC,KAAKZ,MAAtB,EAA8BtD,CAAC,IAAE,KAAKiD,MAAR,EAAeiB,EAAE,EAA/C,EAAmD;AAEjD,gBAAIS,UAAU,GAAG,KAAKF,OAAL,CAAapE,QAAb,CAAsB8D,EAAtB,EAAyBD,EAAzB,EAA4BjE,CAA5B,CAAjB;AACAS,YAAAA,CAAC,CAACH,QAAF,CAAW,KAAKkF,OAAL,CAAa7I,CAAb,CAAX,EAA4B,KAAK8I,OAAL,CAAa9I,CAAb,CAA5B,EAA6CqD,CAA7C,EAAgD0E,UAAhD;AACA/H,YAAAA,CAAC;AAEF;AACF;AACF;AACF,KA9DmB;AA+DpBkI,IAAAA,iBAAiB,EAAE,YAAW;AAC5B,aAAO,EAAP;AACD,KAjEmB;AAkEpBhE,IAAAA,MAAM,EAAE,YAAW;AACjB,UAAIC,IAAI,GAAG,EAAX;AACAA,MAAAA,IAAI,CAAC1B,EAAL,GAAU,KAAKA,EAAf;AACA0B,MAAAA,IAAI,CAACzB,EAAL,GAAU,KAAKA,EAAf;AACAyB,MAAAA,IAAI,CAACkC,MAAL,GAAc,KAAKA,MAAnB;AACAlC,MAAAA,IAAI,CAAC+B,QAAL,GAAgB,KAAKA,QAArB;AACA/B,MAAAA,IAAI,CAAC6B,SAAL,GAAiB,KAAKA,SAAtB;AACA7B,MAAAA,IAAI,CAACsC,MAAL,GAAc,KAAKA,MAAnB;AACAtC,MAAAA,IAAI,CAACuC,MAAL,GAAc,KAAKA,MAAnB;AACAvC,MAAAA,IAAI,CAACwC,UAAL,GAAkB,KAAKA,UAAvB;AACAxC,MAAAA,IAAI,CAACmC,GAAL,GAAW,KAAKA,GAAhB;AACA,aAAOnC,IAAP;AACD,KA9EmB;AA+EpBC,IAAAA,QAAQ,EAAE,UAASD,IAAT,EAAe;AACvB,WAAK6B,SAAL,GAAiB7B,IAAI,CAAC6B,SAAtB;AACA,WAAKS,MAAL,GAActC,IAAI,CAACsC,MAAnB;AACA,WAAKC,MAAL,GAAcvC,IAAI,CAACuC,MAAnB;AACA,WAAKC,UAAL,GAAkBxC,IAAI,CAACwC,UAAvB;AACA,WAAKlE,EAAL,GAAU0B,IAAI,CAAC1B,EAAf;AACA,WAAKC,EAAL,GAAUyB,IAAI,CAACzB,EAAf;AACA,WAAK2D,MAAL,GAAclC,IAAI,CAACkC,MAAnB;AACA,WAAKH,QAAL,GAAgB/B,IAAI,CAAC+B,QAArB;AACA,WAAKI,GAAL,GAAW,OAAOnC,IAAI,CAACmC,GAAZ,KAAoB,WAApB,GAAkCnC,IAAI,CAACmC,GAAvC,GAA6C,CAAxD,CATuB,CASoC;;AAC3D,WAAKuC,OAAL,GAAelK,MAAM,CAACoB,KAAP,CAAa,KAAK0G,MAAL,GAAY,KAAKC,MAAjB,GAAwB,KAAKV,SAA1C,CAAf,CAVuB,CAU8C;;AACrE,WAAK8C,OAAL,GAAenK,MAAM,CAACoB,KAAP,CAAa,KAAK0G,MAAL,GAAY,KAAKC,MAAjB,GAAwB,KAAKV,SAA1C,CAAf;AACD;AA3FmB,GAAtB;AA8FArH,EAAAA,MAAM,CAACiK,SAAP,GAAmBA,SAAnB;AAED,CA7HD,EA6HGnK,SA7HH;;AA+HA,CAAC,UAASE,MAAT,EAAiB;AAChB;;AACA,MAAI6D,GAAG,GAAG7D,MAAM,CAAC6D,GAAjB,CAFgB,CAEM;;AACtB,MAAIV,MAAM,GAAGnD,MAAM,CAACmD,MAApB;;AAEA,MAAImH,UAAU,GAAG,UAASlH,GAAT,EAAc;AAC7B,QAAIA,GAAG,GAAGA,GAAG,IAAI,EAAjB,CAD6B,CAG7B;;AACA,SAAKiE,SAAL,GAAiBlE,MAAM,CAACC,GAAD,EAAM,CAAC,WAAD,EAAc,OAAd,CAAN,EAA8B,CAA9B,CAAvB,CAJ6B,CAM7B;;AACA,SAAK0E,MAAL,GAAc3E,MAAM,CAACC,GAAD,EAAM,CAAC,QAAD,EAAW,IAAX,EAAiB,OAAjB,CAAN,EAAiC,CAAjC,CAApB;AACA,SAAK2E,MAAL,GAAc5E,MAAM,CAACC,GAAD,EAAM,CAAC,QAAD,EAAW,IAAX,EAAiB,QAAjB,CAAN,EAAkC,CAAlC,CAApB,CAR6B,CAU7B;;AACA,SAAK4E,UAAL,GAAkB,OAAlB;AACD,GAZD;;AAaAsC,EAAAA,UAAU,CAACpG,SAAX,GAAuB;AACrBkE,IAAAA,OAAO,EAAE,UAASjD,CAAT,EAAYkD,WAAZ,EAAyB;AAChC,WAAKC,MAAL,GAAcnD,CAAd;AACA,WAAK+D,OAAL,GAAe/D,CAAf;AACA,aAAO,KAAK+D,OAAZ,CAHgC,CAGX;AACtB,KALoB;AAMrBC,IAAAA,QAAQ,EAAE,YAAW,CAAG,CANH;AAOrBI,IAAAA,iBAAiB,EAAE,YAAW;AAC5B,aAAO,EAAP;AACD,KAToB;AAUrBhE,IAAAA,MAAM,EAAE,YAAW;AACjB,UAAIC,IAAI,GAAG,EAAX;AACAA,MAAAA,IAAI,CAAC6B,SAAL,GAAiB,KAAKA,SAAtB;AACA7B,MAAAA,IAAI,CAACsC,MAAL,GAAc,KAAKA,MAAnB;AACAtC,MAAAA,IAAI,CAACuC,MAAL,GAAc,KAAKA,MAAnB;AACAvC,MAAAA,IAAI,CAACwC,UAAL,GAAkB,KAAKA,UAAvB;AACA,aAAOxC,IAAP;AACD,KAjBoB;AAkBrBC,IAAAA,QAAQ,EAAE,UAASD,IAAT,EAAe;AACvB,WAAK6B,SAAL,GAAiB7B,IAAI,CAAC6B,SAAtB;AACA,WAAKS,MAAL,GAActC,IAAI,CAACsC,MAAnB;AACA,WAAKC,MAAL,GAAcvC,IAAI,CAACuC,MAAnB;AACA,WAAKC,UAAL,GAAkBxC,IAAI,CAACwC,UAAvB;AACD;AAvBoB,GAAvB;AA0BAhI,EAAAA,MAAM,CAACsK,UAAP,GAAoBA,UAApB;AACD,CA7CD,EA6CGxK,SA7CH;;AA8CA,CAAC,UAASE,MAAT,EAAiB;AAChB;;AACA,MAAI6D,GAAG,GAAG7D,MAAM,CAAC6D,GAAjB,CAFgB,CAEM;AAEtB;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;;AACA,MAAI0G,YAAY,GAAG,UAASnH,GAAT,EAAc;AAC/B,QAAIA,GAAG,GAAGA,GAAG,IAAI,EAAjB,CAD+B,CAG/B;;AACA,SAAKyG,UAAL,GAAkBzG,GAAG,CAACoE,KAAJ,GAAYpE,GAAG,CAACqE,KAAhB,GAAwBrE,GAAG,CAACmE,QAA9C;AACA,SAAKF,SAAL,GAAiB,KAAKwC,UAAtB;AACA,SAAK/B,MAAL,GAAc,CAAd;AACA,SAAKC,MAAL,GAAc,CAAd;AACA,SAAKC,UAAL,GAAkB,SAAlB;AACD,GATD;;AAWAuC,EAAAA,YAAY,CAACrG,SAAb,GAAyB;AACvBkE,IAAAA,OAAO,EAAE,UAASjD,CAAT,EAAYkD,WAAZ,EAAyB;AAChC,WAAKC,MAAL,GAAcnD,CAAd;AAEA,UAAIoD,CAAC,GAAG,IAAI1E,GAAJ,CAAQ,CAAR,EAAW,CAAX,EAAc,KAAKwD,SAAnB,EAA8B,GAA9B,CAAR,CAHgC,CAKhC;;AACA,UAAImD,EAAE,GAAGrF,CAAC,CAACjD,CAAX;AACA,UAAIuI,IAAI,GAAGtF,CAAC,CAACjD,CAAF,CAAI,CAAJ,CAAX;;AACA,WAAI,IAAIR,CAAC,GAAC,CAAV,EAAYA,CAAC,GAAC,KAAK2F,SAAnB,EAA6B3F,CAAC,EAA9B,EAAkC;AAChC,YAAG8I,EAAE,CAAC9I,CAAD,CAAF,GAAQ+I,IAAX,EAAiBA,IAAI,GAAGD,EAAE,CAAC9I,CAAD,CAAT;AAClB,OAV+B,CAYhC;;;AACA,UAAIgJ,EAAE,GAAG1K,MAAM,CAACoB,KAAP,CAAa,KAAKiG,SAAlB,CAAT;AACA,UAAIsD,IAAI,GAAG,GAAX;;AACA,WAAI,IAAIjJ,CAAC,GAAC,CAAV,EAAYA,CAAC,GAAC,KAAK2F,SAAnB,EAA6B3F,CAAC,EAA9B,EAAkC;AAChC,YAAIkF,CAAC,GAAGvG,IAAI,CAACuK,GAAL,CAASJ,EAAE,CAAC9I,CAAD,CAAF,GAAQ+I,IAAjB,CAAR;AACAE,QAAAA,IAAI,IAAI/D,CAAR;AACA8D,QAAAA,EAAE,CAAChJ,CAAD,CAAF,GAAQkF,CAAR;AACD,OAnB+B,CAqBhC;;;AACA,WAAI,IAAIlF,CAAC,GAAC,CAAV,EAAYA,CAAC,GAAC,KAAK2F,SAAnB,EAA6B3F,CAAC,EAA9B,EAAkC;AAChCgJ,QAAAA,EAAE,CAAChJ,CAAD,CAAF,IAASiJ,IAAT;AACApC,QAAAA,CAAC,CAACrG,CAAF,CAAIR,CAAJ,IAASgJ,EAAE,CAAChJ,CAAD,CAAX;AACD;;AAED,WAAKgJ,EAAL,GAAUA,EAAV,CA3BgC,CA2BlB;;AACd,WAAKxB,OAAL,GAAeX,CAAf;AACA,aAAO,KAAKW,OAAZ;AACD,KA/BsB;AAgCvBC,IAAAA,QAAQ,EAAE,UAAS1E,CAAT,EAAY;AAEpB;AACA,UAAID,CAAC,GAAG,KAAK8D,MAAb;AACA9D,MAAAA,CAAC,CAACH,EAAF,GAAOrE,MAAM,CAACoB,KAAP,CAAaoD,CAAC,CAACtC,CAAF,CAAIJ,MAAjB,CAAP,CAJoB,CAIa;;AAEjC,WAAI,IAAIJ,CAAC,GAAC,CAAV,EAAYA,CAAC,GAAC,KAAK2F,SAAnB,EAA6B3F,CAAC,EAA9B,EAAkC;AAChC,YAAImJ,SAAS,GAAGnJ,CAAC,KAAK+C,CAAN,GAAU,GAAV,GAAgB,GAAhC;AACA,YAAIqG,GAAG,GAAG,EAAED,SAAS,GAAG,KAAKH,EAAL,CAAQhJ,CAAR,CAAd,CAAV;AACA8C,QAAAA,CAAC,CAACH,EAAF,CAAK3C,CAAL,IAAUoJ,GAAV;AACD,OAVmB,CAYpB;;;AACA,aAAO,CAACzK,IAAI,CAACM,GAAL,CAAS,KAAK+J,EAAL,CAAQjG,CAAR,CAAT,CAAR;AACD,KA9CsB;AA+CvB8E,IAAAA,iBAAiB,EAAE,YAAW;AAC5B,aAAO,EAAP;AACD,KAjDsB;AAkDvBhE,IAAAA,MAAM,EAAE,YAAW;AACjB,UAAIC,IAAI,GAAG,EAAX;AACAA,MAAAA,IAAI,CAAC6B,SAAL,GAAiB,KAAKA,SAAtB;AACA7B,MAAAA,IAAI,CAACsC,MAAL,GAAc,KAAKA,MAAnB;AACAtC,MAAAA,IAAI,CAACuC,MAAL,GAAc,KAAKA,MAAnB;AACAvC,MAAAA,IAAI,CAACwC,UAAL,GAAkB,KAAKA,UAAvB;AACAxC,MAAAA,IAAI,CAACqE,UAAL,GAAkB,KAAKA,UAAvB;AACA,aAAOrE,IAAP;AACD,KA1DsB;AA2DvBC,IAAAA,QAAQ,EAAE,UAASD,IAAT,EAAe;AACvB,WAAK6B,SAAL,GAAiB7B,IAAI,CAAC6B,SAAtB;AACA,WAAKS,MAAL,GAActC,IAAI,CAACsC,MAAnB;AACA,WAAKC,MAAL,GAAcvC,IAAI,CAACuC,MAAnB;AACA,WAAKC,UAAL,GAAkBxC,IAAI,CAACwC,UAAvB;AACA,WAAK6B,UAAL,GAAkBrE,IAAI,CAACqE,UAAvB;AACD,KAjEsB,CAoEzB;AACA;AACA;;AAtEyB,GAAzB;;AAuEA,MAAIkB,eAAe,GAAG,UAAS3H,GAAT,EAAc;AAClC,QAAIA,GAAG,GAAGA,GAAG,IAAI,EAAjB,CADkC,CAGlC;;AACA,SAAKyG,UAAL,GAAkBzG,GAAG,CAACoE,KAAJ,GAAYpE,GAAG,CAACqE,KAAhB,GAAwBrE,GAAG,CAACmE,QAA9C;AACA,SAAKF,SAAL,GAAiB,KAAKwC,UAAtB;AACA,SAAK/B,MAAL,GAAc,CAAd;AACA,SAAKC,MAAL,GAAc,CAAd;AACA,SAAKC,UAAL,GAAkB,YAAlB;AACD,GATD;;AAWA+C,EAAAA,eAAe,CAAC7G,SAAhB,GAA4B;AAC1BkE,IAAAA,OAAO,EAAE,UAASjD,CAAT,EAAYkD,WAAZ,EAAyB;AAChC,WAAKC,MAAL,GAAcnD,CAAd;AACA,WAAK+D,OAAL,GAAe/D,CAAf;AACA,aAAOA,CAAP,CAHgC,CAGtB;AACX,KALyB;AAM1B;AACA;AACA;AACA;AACAgE,IAAAA,QAAQ,EAAE,UAAS1E,CAAT,EAAY;AAEpB;AACA,UAAID,CAAC,GAAG,KAAK8D,MAAb;AACA9D,MAAAA,CAAC,CAACH,EAAF,GAAOrE,MAAM,CAACoB,KAAP,CAAaoD,CAAC,CAACtC,CAAF,CAAIJ,MAAjB,CAAP,CAJoB,CAIa;;AACjC,UAAIkJ,IAAI,GAAG,GAAX;;AACA,UAAGvG,CAAC,YAAYhD,KAAb,IAAsBgD,CAAC,YAAY9C,YAAtC,EAAoD;AAClD,aAAI,IAAID,CAAC,GAAC,CAAV,EAAYA,CAAC,GAAC,KAAK2F,SAAnB,EAA6B3F,CAAC,EAA9B,EAAkC;AAChC,cAAImE,EAAE,GAAGrB,CAAC,CAACtC,CAAF,CAAIR,CAAJ,IAAS+C,CAAC,CAAC/C,CAAD,CAAnB;AACA8C,UAAAA,CAAC,CAACH,EAAF,CAAK3C,CAAL,IAAUmE,EAAV;AACAmF,UAAAA,IAAI,IAAI,MAAInF,EAAJ,GAAOA,EAAf;AACD;AACF,OAND,MAMO,IAAG,OAAOpB,CAAP,KAAa,QAAhB,EAA0B;AAC/B;AACA,YAAIoB,EAAE,GAAGrB,CAAC,CAACtC,CAAF,CAAI,CAAJ,IAASuC,CAAlB;AACAD,QAAAA,CAAC,CAACH,EAAF,CAAK,CAAL,IAAUwB,EAAV;AACAmF,QAAAA,IAAI,IAAI,MAAInF,EAAJ,GAAOA,EAAf;AACD,OALM,MAKA;AACL;AACA;AACA,YAAInE,CAAC,GAAG+C,CAAC,CAACwG,GAAV;AACA,YAAIC,EAAE,GAAGzG,CAAC,CAAC0G,GAAX;AACA,YAAItF,EAAE,GAAGrB,CAAC,CAACtC,CAAF,CAAIR,CAAJ,IAASwJ,EAAlB;AACA1G,QAAAA,CAAC,CAACH,EAAF,CAAK3C,CAAL,IAAUmE,EAAV;AACAmF,QAAAA,IAAI,IAAI,MAAInF,EAAJ,GAAOA,EAAf;AACD;;AACD,aAAOmF,IAAP;AACD,KArCyB;AAsC1BzB,IAAAA,iBAAiB,EAAE,YAAW;AAC5B,aAAO,EAAP;AACD,KAxCyB;AAyC1BhE,IAAAA,MAAM,EAAE,YAAW;AACjB,UAAIC,IAAI,GAAG,EAAX;AACAA,MAAAA,IAAI,CAAC6B,SAAL,GAAiB,KAAKA,SAAtB;AACA7B,MAAAA,IAAI,CAACsC,MAAL,GAAc,KAAKA,MAAnB;AACAtC,MAAAA,IAAI,CAACuC,MAAL,GAAc,KAAKA,MAAnB;AACAvC,MAAAA,IAAI,CAACwC,UAAL,GAAkB,KAAKA,UAAvB;AACAxC,MAAAA,IAAI,CAACqE,UAAL,GAAkB,KAAKA,UAAvB;AACA,aAAOrE,IAAP;AACD,KAjDyB;AAkD1BC,IAAAA,QAAQ,EAAE,UAASD,IAAT,EAAe;AACvB,WAAK6B,SAAL,GAAiB7B,IAAI,CAAC6B,SAAtB;AACA,WAAKS,MAAL,GAActC,IAAI,CAACsC,MAAnB;AACA,WAAKC,MAAL,GAAcvC,IAAI,CAACuC,MAAnB;AACA,WAAKC,UAAL,GAAkBxC,IAAI,CAACwC,UAAvB;AACA,WAAK6B,UAAL,GAAkBrE,IAAI,CAACqE,UAAvB;AACD;AAxDyB,GAA5B;;AA2DA,MAAIuB,QAAQ,GAAG,UAAShI,GAAT,EAAc;AAC3B,QAAIA,GAAG,GAAGA,GAAG,IAAI,EAAjB,CAD2B,CAG3B;;AACA,SAAKyG,UAAL,GAAkBzG,GAAG,CAACoE,KAAJ,GAAYpE,GAAG,CAACqE,KAAhB,GAAwBrE,GAAG,CAACmE,QAA9C;AACA,SAAKF,SAAL,GAAiB,KAAKwC,UAAtB;AACA,SAAK/B,MAAL,GAAc,CAAd;AACA,SAAKC,MAAL,GAAc,CAAd;AACA,SAAKC,UAAL,GAAkB,KAAlB;AACD,GATD;;AAWAoD,EAAAA,QAAQ,CAAClH,SAAT,GAAqB;AACnBkE,IAAAA,OAAO,EAAE,UAASjD,CAAT,EAAYkD,WAAZ,EAAyB;AAChC,WAAKC,MAAL,GAAcnD,CAAd;AACA,WAAK+D,OAAL,GAAe/D,CAAf,CAFgC,CAEd;;AAClB,aAAOA,CAAP;AACD,KALkB;AAMnBgE,IAAAA,QAAQ,EAAE,UAAS1E,CAAT,EAAY;AAEpB;AACA,UAAID,CAAC,GAAG,KAAK8D,MAAb;AACA9D,MAAAA,CAAC,CAACH,EAAF,GAAOrE,MAAM,CAACoB,KAAP,CAAaoD,CAAC,CAACtC,CAAF,CAAIJ,MAAjB,CAAP,CAJoB,CAIa;AAEjC;AACA;AACA;;AACA,UAAIuJ,MAAM,GAAG7G,CAAC,CAACtC,CAAF,CAAIuC,CAAJ,CAAb,CAToB,CASC;;AACrB,UAAI6G,MAAM,GAAG,GAAb;AACA,UAAIN,IAAI,GAAG,GAAX;;AACA,WAAI,IAAItJ,CAAC,GAAC,CAAV,EAAYA,CAAC,GAAC,KAAK2F,SAAnB,EAA6B3F,CAAC,EAA9B,EAAkC;AAChC,YAAG+C,CAAC,KAAK/C,CAAT,EAAY;AAAE;AAAW;;AACzB,YAAI6J,KAAK,GAAG,CAACF,MAAD,GAAU7G,CAAC,CAACtC,CAAF,CAAIR,CAAJ,CAAV,GAAmB4J,MAA/B;;AACA,YAAGC,KAAK,GAAG,CAAX,EAAc;AACZ;AACA/G,UAAAA,CAAC,CAACH,EAAF,CAAK3C,CAAL,KAAW,CAAX;AACA8C,UAAAA,CAAC,CAACH,EAAF,CAAKI,CAAL,KAAW,CAAX;AACAuG,UAAAA,IAAI,IAAIO,KAAR;AACD;AACF;;AAED,aAAOP,IAAP;AACD,KA9BkB;AA+BnBzB,IAAAA,iBAAiB,EAAE,YAAW;AAC5B,aAAO,EAAP;AACD,KAjCkB;AAkCnBhE,IAAAA,MAAM,EAAE,YAAW;AACjB,UAAIC,IAAI,GAAG,EAAX;AACAA,MAAAA,IAAI,CAAC6B,SAAL,GAAiB,KAAKA,SAAtB;AACA7B,MAAAA,IAAI,CAACsC,MAAL,GAAc,KAAKA,MAAnB;AACAtC,MAAAA,IAAI,CAACuC,MAAL,GAAc,KAAKA,MAAnB;AACAvC,MAAAA,IAAI,CAACwC,UAAL,GAAkB,KAAKA,UAAvB;AACAxC,MAAAA,IAAI,CAACqE,UAAL,GAAkB,KAAKA,UAAvB;AACA,aAAOrE,IAAP;AACD,KA1CkB;AA2CnBC,IAAAA,QAAQ,EAAE,UAASD,IAAT,EAAe;AACvB,WAAK6B,SAAL,GAAiB7B,IAAI,CAAC6B,SAAtB;AACA,WAAKS,MAAL,GAActC,IAAI,CAACsC,MAAnB;AACA,WAAKC,MAAL,GAAcvC,IAAI,CAACuC,MAAnB;AACA,WAAKC,UAAL,GAAkBxC,IAAI,CAACwC,UAAvB;AACA,WAAK6B,UAAL,GAAkBrE,IAAI,CAACqE,UAAvB;AACD;AAjDkB,GAArB;AAoDA7J,EAAAA,MAAM,CAAC+K,eAAP,GAAyBA,eAAzB;AACA/K,EAAAA,MAAM,CAACuK,YAAP,GAAsBA,YAAtB;AACAvK,EAAAA,MAAM,CAACoL,QAAP,GAAkBA,QAAlB;AAED,CAxOD,EAwOGtL,SAxOH;;AA0OA,CAAC,UAASE,MAAT,EAAiB;AAChB;;AACA,MAAI6D,GAAG,GAAG7D,MAAM,CAAC6D,GAAjB,CAFgB,CAEM;AAEtB;AACA;AACA;;AACA,MAAI2H,SAAS,GAAG,UAASpI,GAAT,EAAc;AAC5B,QAAIA,GAAG,GAAGA,GAAG,IAAI,EAAjB,CAD4B,CAG5B;;AACA,SAAK0E,MAAL,GAAc1E,GAAG,CAACoE,KAAlB;AACA,SAAKO,MAAL,GAAc3E,GAAG,CAACqE,KAAlB;AACA,SAAKJ,SAAL,GAAiBjE,GAAG,CAACmE,QAArB;AACA,SAAKS,UAAL,GAAkB,MAAlB;AACD,GARD;;AASAwD,EAAAA,SAAS,CAACtH,SAAV,GAAsB;AACpBkE,IAAAA,OAAO,EAAE,UAASjD,CAAT,EAAYkD,WAAZ,EAAyB;AAChC,WAAKC,MAAL,GAAcnD,CAAd;AACA,UAAIsG,EAAE,GAAGtG,CAAC,CAACD,KAAF,EAAT;AACA,UAAIwG,CAAC,GAAGvG,CAAC,CAACjD,CAAF,CAAIJ,MAAZ;AACA,UAAI6J,GAAG,GAAGF,EAAE,CAACvJ,CAAb;;AACA,WAAI,IAAIR,CAAC,GAAC,CAAV,EAAYA,CAAC,GAACgK,CAAd,EAAgBhK,CAAC,EAAjB,EAAqB;AACnB,YAAGiK,GAAG,CAACjK,CAAD,CAAH,GAAS,CAAZ,EAAeiK,GAAG,CAACjK,CAAD,CAAH,GAAS,CAAT,CADI,CACQ;AAC5B;;AACD,WAAKwH,OAAL,GAAeuC,EAAf;AACA,aAAO,KAAKvC,OAAZ;AACD,KAXmB;AAYpBC,IAAAA,QAAQ,EAAE,YAAW;AACnB,UAAIhE,CAAC,GAAG,KAAKmD,MAAb,CADmB,CACE;;AACrB,UAAImD,EAAE,GAAG,KAAKvC,OAAd;AACA,UAAIwC,CAAC,GAAGvG,CAAC,CAACjD,CAAF,CAAIJ,MAAZ;AACAqD,MAAAA,CAAC,CAACd,EAAF,GAAOrE,MAAM,CAACoB,KAAP,CAAasK,CAAb,CAAP,CAJmB,CAIK;;AACxB,WAAI,IAAIhK,CAAC,GAAC,CAAV,EAAYA,CAAC,GAACgK,CAAd,EAAgBhK,CAAC,EAAjB,EAAqB;AACnB,YAAG+J,EAAE,CAACvJ,CAAH,CAAKR,CAAL,KAAW,CAAd,EAAiByD,CAAC,CAACd,EAAF,CAAK3C,CAAL,IAAU,CAAV,CAAjB,CAA8B;AAA9B,aACKyD,CAAC,CAACd,EAAF,CAAK3C,CAAL,IAAU+J,EAAE,CAACpH,EAAH,CAAM3C,CAAN,CAAV;AACN;AACF,KArBmB;AAsBpB6H,IAAAA,iBAAiB,EAAE,YAAW;AAC5B,aAAO,EAAP;AACD,KAxBmB;AAyBpBhE,IAAAA,MAAM,EAAE,YAAW;AACjB,UAAIC,IAAI,GAAG,EAAX;AACAA,MAAAA,IAAI,CAAC6B,SAAL,GAAiB,KAAKA,SAAtB;AACA7B,MAAAA,IAAI,CAACsC,MAAL,GAAc,KAAKA,MAAnB;AACAtC,MAAAA,IAAI,CAACuC,MAAL,GAAc,KAAKA,MAAnB;AACAvC,MAAAA,IAAI,CAACwC,UAAL,GAAkB,KAAKA,UAAvB;AACA,aAAOxC,IAAP;AACD,KAhCmB;AAiCpBC,IAAAA,QAAQ,EAAE,UAASD,IAAT,EAAe;AACvB,WAAK6B,SAAL,GAAiB7B,IAAI,CAAC6B,SAAtB;AACA,WAAKS,MAAL,GAActC,IAAI,CAACsC,MAAnB;AACA,WAAKC,MAAL,GAAcvC,IAAI,CAACuC,MAAnB;AACA,WAAKC,UAAL,GAAkBxC,IAAI,CAACwC,UAAvB;AACD,KAtCmB,CAyCtB;AACA;AACA;;AA3CsB,GAAtB;;AA4CA,MAAI4D,YAAY,GAAG,UAASxI,GAAT,EAAc;AAC/B,QAAIA,GAAG,GAAGA,GAAG,IAAI,EAAjB,CAD+B,CAG/B;;AACA,SAAK0E,MAAL,GAAc1E,GAAG,CAACoE,KAAlB;AACA,SAAKO,MAAL,GAAc3E,GAAG,CAACqE,KAAlB;AACA,SAAKJ,SAAL,GAAiBjE,GAAG,CAACmE,QAArB;AACA,SAAKS,UAAL,GAAkB,SAAlB;AACD,GARD;;AASA4D,EAAAA,YAAY,CAAC1H,SAAb,GAAyB;AACvBkE,IAAAA,OAAO,EAAE,UAASjD,CAAT,EAAYkD,WAAZ,EAAyB;AAChC,WAAKC,MAAL,GAAcnD,CAAd;AACA,UAAIsG,EAAE,GAAGtG,CAAC,CAACF,YAAF,EAAT;AACA,UAAIyG,CAAC,GAAGvG,CAAC,CAACjD,CAAF,CAAIJ,MAAZ;AACA,UAAI6J,GAAG,GAAGF,EAAE,CAACvJ,CAAb;AACA,UAAI4H,EAAE,GAAG3E,CAAC,CAACjD,CAAX;;AACA,WAAI,IAAIR,CAAC,GAAC,CAAV,EAAYA,CAAC,GAACgK,CAAd,EAAgBhK,CAAC,EAAjB,EAAqB;AACnBiK,QAAAA,GAAG,CAACjK,CAAD,CAAH,GAAS,OAAK,MAAIrB,IAAI,CAACuK,GAAL,CAAS,CAACd,EAAE,CAACpI,CAAD,CAAZ,CAAT,CAAT;AACD;;AACD,WAAKwH,OAAL,GAAeuC,EAAf;AACA,aAAO,KAAKvC,OAAZ;AACD,KAZsB;AAavBC,IAAAA,QAAQ,EAAE,YAAW;AACnB,UAAIhE,CAAC,GAAG,KAAKmD,MAAb,CADmB,CACE;;AACrB,UAAImD,EAAE,GAAG,KAAKvC,OAAd;AACA,UAAIwC,CAAC,GAAGvG,CAAC,CAACjD,CAAF,CAAIJ,MAAZ;AACAqD,MAAAA,CAAC,CAACd,EAAF,GAAOrE,MAAM,CAACoB,KAAP,CAAasK,CAAb,CAAP,CAJmB,CAIK;;AACxB,WAAI,IAAIhK,CAAC,GAAC,CAAV,EAAYA,CAAC,GAACgK,CAAd,EAAgBhK,CAAC,EAAjB,EAAqB;AACnB,YAAImK,IAAI,GAAGJ,EAAE,CAACvJ,CAAH,CAAKR,CAAL,CAAX;AACAyD,QAAAA,CAAC,CAACd,EAAF,CAAK3C,CAAL,IAAWmK,IAAI,IAAI,MAAMA,IAAV,CAAJ,GAAsBJ,EAAE,CAACpH,EAAH,CAAM3C,CAAN,CAAjC;AACD;AACF,KAtBsB;AAuBvB6H,IAAAA,iBAAiB,EAAE,YAAW;AAC5B,aAAO,EAAP;AACD,KAzBsB;AA0BvBhE,IAAAA,MAAM,EAAE,YAAW;AACjB,UAAIC,IAAI,GAAG,EAAX;AACAA,MAAAA,IAAI,CAAC6B,SAAL,GAAiB,KAAKA,SAAtB;AACA7B,MAAAA,IAAI,CAACsC,MAAL,GAAc,KAAKA,MAAnB;AACAtC,MAAAA,IAAI,CAACuC,MAAL,GAAc,KAAKA,MAAnB;AACAvC,MAAAA,IAAI,CAACwC,UAAL,GAAkB,KAAKA,UAAvB;AACA,aAAOxC,IAAP;AACD,KAjCsB;AAkCvBC,IAAAA,QAAQ,EAAE,UAASD,IAAT,EAAe;AACvB,WAAK6B,SAAL,GAAiB7B,IAAI,CAAC6B,SAAtB;AACA,WAAKS,MAAL,GAActC,IAAI,CAACsC,MAAnB;AACA,WAAKC,MAAL,GAAcvC,IAAI,CAACuC,MAAnB;AACA,WAAKC,UAAL,GAAkBxC,IAAI,CAACwC,UAAvB;AACD,KAvCsB,CA0CzB;AACA;AACA;AACA;;AA7CyB,GAAzB;;AA8CA,MAAI8D,WAAW,GAAG,UAAS1I,GAAT,EAAc;AAC9B,QAAIA,GAAG,GAAGA,GAAG,IAAI,EAAjB,CAD8B,CAG9B;;AACA,SAAK2I,UAAL,GAAkB,OAAO3I,GAAG,CAAC2I,UAAX,KAA0B,WAA1B,GAAwC3I,GAAG,CAAC2I,UAA5C,GAAyD,CAA3E,CAJ8B,CAM9B;;AACA,SAAKjE,MAAL,GAAc1E,GAAG,CAACoE,KAAlB;AACA,SAAKO,MAAL,GAAc3E,GAAG,CAACqE,KAAlB;AACA,SAAKJ,SAAL,GAAiBhH,IAAI,CAACW,KAAL,CAAWoC,GAAG,CAACmE,QAAJ,GAAe,KAAKwE,UAA/B,CAAjB;AACA,SAAK/D,UAAL,GAAkB,QAAlB;AAEA,SAAKgE,QAAL,GAAgBhM,MAAM,CAACoB,KAAP,CAAa,KAAK0G,MAAL,GAAY,KAAKC,MAAjB,GAAwB,KAAKV,SAA1C,CAAhB,CAZ8B,CAYwC;AACvE,GAbD;;AAcAyE,EAAAA,WAAW,CAAC5H,SAAZ,GAAwB;AACtBkE,IAAAA,OAAO,EAAE,UAASjD,CAAT,EAAYkD,WAAZ,EAAyB;AAChC,WAAKC,MAAL,GAAcnD,CAAd;AACA,UAAIuG,CAAC,GAAG,KAAKrE,SAAb;AACA,UAAIoE,EAAE,GAAG,IAAI5H,GAAJ,CAAQ,KAAKiE,MAAb,EAAqB,KAAKC,MAA1B,EAAkC,KAAKV,SAAvC,EAAkD,GAAlD,CAAT,CAHgC,CAKhC;AACA;AACA;;AACA,UAAG,KAAKS,MAAL,KAAgB,CAAhB,IAAqB,KAAKC,MAAL,KAAgB,CAAxC,EAA2C;AACzC,aAAI,IAAIrG,CAAC,GAAC,CAAV,EAAYA,CAAC,GAACgK,CAAd,EAAgBhK,CAAC,EAAjB,EAAqB;AACnB,cAAIiD,EAAE,GAAGjD,CAAC,GAAG,KAAKqK,UAAlB,CADmB,CACW;;AAC9B,cAAIlL,CAAC,GAAGsE,CAAC,CAACjD,CAAF,CAAIyC,EAAJ,CAAR;AACA,cAAIsH,EAAE,GAAG,CAAT;;AACA,eAAI,IAAIxJ,CAAC,GAAC,CAAV,EAAYA,CAAC,GAAC,KAAKsJ,UAAnB,EAA8BtJ,CAAC,EAA/B,EAAmC;AACjC,gBAAIyJ,EAAE,GAAG/G,CAAC,CAACjD,CAAF,CAAIyC,EAAE,GAAClC,CAAP,CAAT;;AACA,gBAAGyJ,EAAE,GAAGrL,CAAR,EAAW;AACTA,cAAAA,CAAC,GAAGqL,EAAJ;AACAD,cAAAA,EAAE,GAAGxJ,CAAL;AACD;AACF;;AACDgJ,UAAAA,EAAE,CAACvJ,CAAH,CAAKR,CAAL,IAAUb,CAAV;AACA,eAAKmL,QAAL,CAActK,CAAd,IAAmBiD,EAAE,GAAGsH,EAAxB;AACD;AACF,OAfD,MAeO;AACL,YAAI5K,CAAC,GAAC,CAAN,CADK,CACI;;AACT,aAAI,IAAImD,CAAC,GAAC,CAAV,EAAYA,CAAC,GAACW,CAAC,CAACrB,EAAhB,EAAmBU,CAAC,EAApB,EAAwB;AACtB,eAAI,IAAIC,CAAC,GAAC,CAAV,EAAYA,CAAC,GAACU,CAAC,CAACpB,EAAhB,EAAmBU,CAAC,EAApB,EAAwB;AACtB,iBAAI,IAAI/C,CAAC,GAAC,CAAV,EAAYA,CAAC,GAACgK,CAAd,EAAgBhK,CAAC,EAAjB,EAAqB;AACnB,kBAAIiD,EAAE,GAAGjD,CAAC,GAAG,KAAKqK,UAAlB;AACA,kBAAIlL,CAAC,GAAGsE,CAAC,CAACZ,GAAF,CAAMC,CAAN,EAASC,CAAT,EAAYE,EAAZ,CAAR;AACA,kBAAIsH,EAAE,GAAG,CAAT;;AACA,mBAAI,IAAIxJ,CAAC,GAAC,CAAV,EAAYA,CAAC,GAAC,KAAKsJ,UAAnB,EAA8BtJ,CAAC,EAA/B,EAAmC;AACjC,oBAAIyJ,EAAE,GAAG/G,CAAC,CAACZ,GAAF,CAAMC,CAAN,EAASC,CAAT,EAAYE,EAAE,GAAClC,CAAf,CAAT;;AACA,oBAAGyJ,EAAE,GAAGrL,CAAR,EAAW;AACTA,kBAAAA,CAAC,GAAGqL,EAAJ;AACAD,kBAAAA,EAAE,GAAGxJ,CAAL;AACD;AACF;;AACDgJ,cAAAA,EAAE,CAAC7G,GAAH,CAAOJ,CAAP,EAASC,CAAT,EAAW/C,CAAX,EAAab,CAAb;AACA,mBAAKmL,QAAL,CAAc3K,CAAd,IAAmBsD,EAAE,GAAGsH,EAAxB;AACA5K,cAAAA,CAAC;AACF;AACF;AACF;AAEF;;AACD,WAAK6H,OAAL,GAAeuC,EAAf;AACA,aAAO,KAAKvC,OAAZ;AACD,KAjDqB;AAkDtBC,IAAAA,QAAQ,EAAE,YAAW;AACnB,UAAIhE,CAAC,GAAG,KAAKmD,MAAb,CADmB,CACE;;AACrB,UAAImD,EAAE,GAAG,KAAKvC,OAAd;AACA,UAAIwC,CAAC,GAAG,KAAKrE,SAAb;AACAlC,MAAAA,CAAC,CAACd,EAAF,GAAOrE,MAAM,CAACoB,KAAP,CAAa+D,CAAC,CAACjD,CAAF,CAAIJ,MAAjB,CAAP,CAJmB,CAIc;AAEjC;;AACA,UAAG,KAAKgG,MAAL,KAAgB,CAAhB,IAAqB,KAAKC,MAAL,KAAgB,CAAxC,EAA2C;AACzC,aAAI,IAAIrG,CAAC,GAAC,CAAV,EAAYA,CAAC,GAACgK,CAAd,EAAgBhK,CAAC,EAAjB,EAAqB;AACnB,cAAI0H,UAAU,GAAGqC,EAAE,CAACpH,EAAH,CAAM3C,CAAN,CAAjB;AACAyD,UAAAA,CAAC,CAACd,EAAF,CAAK,KAAK2H,QAAL,CAActK,CAAd,CAAL,IAAyB0H,UAAzB;AACD;AACF,OALD,MAKO;AACL;AACA,YAAI/H,CAAC,GAAC,CAAN,CAFK,CAEI;;AACT,aAAI,IAAImD,CAAC,GAAC,CAAV,EAAYA,CAAC,GAACiH,EAAE,CAAC3H,EAAjB,EAAoBU,CAAC,EAArB,EAAyB;AACvB,eAAI,IAAIC,CAAC,GAAC,CAAV,EAAYA,CAAC,GAACgH,EAAE,CAAC1H,EAAjB,EAAoBU,CAAC,EAArB,EAAyB;AACvB,iBAAI,IAAI/C,CAAC,GAAC,CAAV,EAAYA,CAAC,GAACgK,CAAd,EAAgBhK,CAAC,EAAjB,EAAqB;AACnB,kBAAI0H,UAAU,GAAGqC,EAAE,CAAC3G,QAAH,CAAYN,CAAZ,EAAcC,CAAd,EAAgB/C,CAAhB,CAAjB;AACAyD,cAAAA,CAAC,CAACJ,QAAF,CAAWP,CAAX,EAAaC,CAAb,EAAe,KAAKuH,QAAL,CAAc3K,CAAd,CAAf,EAAgC+H,UAAhC;AACA/H,cAAAA,CAAC;AACF;AACF;AACF;AACF;AACF,KA3EqB;AA4EtBkI,IAAAA,iBAAiB,EAAE,YAAW;AAC5B,aAAO,EAAP;AACD,KA9EqB;AA+EtBhE,IAAAA,MAAM,EAAE,YAAW;AACjB,UAAIC,IAAI,GAAG,EAAX;AACAA,MAAAA,IAAI,CAAC6B,SAAL,GAAiB,KAAKA,SAAtB;AACA7B,MAAAA,IAAI,CAACsC,MAAL,GAAc,KAAKA,MAAnB;AACAtC,MAAAA,IAAI,CAACuC,MAAL,GAAc,KAAKA,MAAnB;AACAvC,MAAAA,IAAI,CAACwC,UAAL,GAAkB,KAAKA,UAAvB;AACAxC,MAAAA,IAAI,CAACuG,UAAL,GAAkB,KAAKA,UAAvB;AACA,aAAOvG,IAAP;AACD,KAvFqB;AAwFtBC,IAAAA,QAAQ,EAAE,UAASD,IAAT,EAAe;AACvB,WAAK6B,SAAL,GAAiB7B,IAAI,CAAC6B,SAAtB;AACA,WAAKS,MAAL,GAActC,IAAI,CAACsC,MAAnB;AACA,WAAKC,MAAL,GAAcvC,IAAI,CAACuC,MAAnB;AACA,WAAKC,UAAL,GAAkBxC,IAAI,CAACwC,UAAvB;AACA,WAAK+D,UAAL,GAAkBvG,IAAI,CAACuG,UAAvB;AACA,WAAKC,QAAL,GAAgBhM,MAAM,CAACoB,KAAP,CAAa,KAAK2K,UAAlB,CAAhB;AACD,KA/FqB,CAkGxB;;AAlGwB,GAAxB;;AAmGA,WAASI,IAAT,CAAc3H,CAAd,EAAiB;AACf,QAAIC,CAAC,GAAGpE,IAAI,CAACuK,GAAL,CAAS,IAAIpG,CAAb,CAAR;AACA,WAAO,CAACC,CAAC,GAAG,CAAL,KAAWA,CAAC,GAAG,CAAf,CAAP;AACD,GAvOe,CAwOhB;AACA;AACA;;;AACA,MAAI2H,SAAS,GAAG,UAAShJ,GAAT,EAAc;AAC5B,QAAIA,GAAG,GAAGA,GAAG,IAAI,EAAjB,CAD4B,CAG5B;;AACA,SAAK0E,MAAL,GAAc1E,GAAG,CAACoE,KAAlB;AACA,SAAKO,MAAL,GAAc3E,GAAG,CAACqE,KAAlB;AACA,SAAKJ,SAAL,GAAiBjE,GAAG,CAACmE,QAArB;AACA,SAAKS,UAAL,GAAkB,MAAlB;AACD,GARD;;AASAoE,EAAAA,SAAS,CAAClI,SAAV,GAAsB;AACpBkE,IAAAA,OAAO,EAAE,UAASjD,CAAT,EAAYkD,WAAZ,EAAyB;AAChC,WAAKC,MAAL,GAAcnD,CAAd;AACA,UAAIsG,EAAE,GAAGtG,CAAC,CAACF,YAAF,EAAT;AACA,UAAIyG,CAAC,GAAGvG,CAAC,CAACjD,CAAF,CAAIJ,MAAZ;;AACA,WAAI,IAAIJ,CAAC,GAAC,CAAV,EAAYA,CAAC,GAACgK,CAAd,EAAgBhK,CAAC,EAAjB,EAAqB;AACnB+J,QAAAA,EAAE,CAACvJ,CAAH,CAAKR,CAAL,IAAUyK,IAAI,CAAChH,CAAC,CAACjD,CAAF,CAAIR,CAAJ,CAAD,CAAd;AACD;;AACD,WAAKwH,OAAL,GAAeuC,EAAf;AACA,aAAO,KAAKvC,OAAZ;AACD,KAVmB;AAWpBC,IAAAA,QAAQ,EAAE,YAAW;AACnB,UAAIhE,CAAC,GAAG,KAAKmD,MAAb,CADmB,CACE;;AACrB,UAAImD,EAAE,GAAG,KAAKvC,OAAd;AACA,UAAIwC,CAAC,GAAGvG,CAAC,CAACjD,CAAF,CAAIJ,MAAZ;AACAqD,MAAAA,CAAC,CAACd,EAAF,GAAOrE,MAAM,CAACoB,KAAP,CAAasK,CAAb,CAAP,CAJmB,CAIK;;AACxB,WAAI,IAAIhK,CAAC,GAAC,CAAV,EAAYA,CAAC,GAACgK,CAAd,EAAgBhK,CAAC,EAAjB,EAAqB;AACnB,YAAImK,IAAI,GAAGJ,EAAE,CAACvJ,CAAH,CAAKR,CAAL,CAAX;AACAyD,QAAAA,CAAC,CAACd,EAAF,CAAK3C,CAAL,IAAU,CAAC,MAAMmK,IAAI,GAAGA,IAAd,IAAsBJ,EAAE,CAACpH,EAAH,CAAM3C,CAAN,CAAhC;AACD;AACF,KApBmB;AAqBpB6H,IAAAA,iBAAiB,EAAE,YAAW;AAC5B,aAAO,EAAP;AACD,KAvBmB;AAwBpBhE,IAAAA,MAAM,EAAE,YAAW;AACjB,UAAIC,IAAI,GAAG,EAAX;AACAA,MAAAA,IAAI,CAAC6B,SAAL,GAAiB,KAAKA,SAAtB;AACA7B,MAAAA,IAAI,CAACsC,MAAL,GAAc,KAAKA,MAAnB;AACAtC,MAAAA,IAAI,CAACuC,MAAL,GAAc,KAAKA,MAAnB;AACAvC,MAAAA,IAAI,CAACwC,UAAL,GAAkB,KAAKA,UAAvB;AACA,aAAOxC,IAAP;AACD,KA/BmB;AAgCpBC,IAAAA,QAAQ,EAAE,UAASD,IAAT,EAAe;AACvB,WAAK6B,SAAL,GAAiB7B,IAAI,CAAC6B,SAAtB;AACA,WAAKS,MAAL,GAActC,IAAI,CAACsC,MAAnB;AACA,WAAKC,MAAL,GAAcvC,IAAI,CAACuC,MAAnB;AACA,WAAKC,UAAL,GAAkBxC,IAAI,CAACwC,UAAvB;AACD;AArCmB,GAAtB;AAwCAhI,EAAAA,MAAM,CAACoM,SAAP,GAAmBA,SAAnB;AACApM,EAAAA,MAAM,CAAC8L,WAAP,GAAqBA,WAArB;AACA9L,EAAAA,MAAM,CAACwL,SAAP,GAAmBA,SAAnB;AACAxL,EAAAA,MAAM,CAAC4L,YAAP,GAAsBA,YAAtB;AAED,CAjSD,EAiSG9L,SAjSH;;AAmSA,CAAC,UAASE,MAAT,EAAiB;AAChB;;AACA,MAAI6D,GAAG,GAAG7D,MAAM,CAAC6D,GAAjB,CAFgB,CAEM;AAEtB;AACA;AACA;AACA;AACA;AACA;;AACA,MAAIwI,YAAY,GAAG,UAASjJ,GAAT,EAAc;AAC/B,QAAIA,GAAG,GAAGA,GAAG,IAAI,EAAjB,CAD+B,CAG/B;;AACA,SAAK0E,MAAL,GAAc1E,GAAG,CAACoE,KAAlB;AACA,SAAKO,MAAL,GAAc3E,GAAG,CAACqE,KAAlB;AACA,SAAKJ,SAAL,GAAiBjE,GAAG,CAACmE,QAArB;AACA,SAAKS,UAAL,GAAkB,SAAlB;AACA,SAAKsE,SAAL,GAAiB,OAAOlJ,GAAG,CAACkJ,SAAX,KAAyB,WAAzB,GAAuClJ,GAAG,CAACkJ,SAA3C,GAAuD,GAAxE;AACA,SAAKC,OAAL,GAAevM,MAAM,CAACoB,KAAP,CAAa,KAAK0G,MAAL,GAAY,KAAKC,MAAjB,GAAwB,KAAKV,SAA1C,CAAf;AACD,GAVD;;AAWAgF,EAAAA,YAAY,CAACnI,SAAb,GAAyB;AACvBkE,IAAAA,OAAO,EAAE,UAASjD,CAAT,EAAYkD,WAAZ,EAAyB;AAChC,WAAKC,MAAL,GAAcnD,CAAd;;AACA,UAAG,OAAOkD,WAAP,KAAsB,WAAzB,EAAsC;AAAEA,QAAAA,WAAW,GAAG,KAAd;AAAsB,OAF9B,CAE+B;;;AAC/D,UAAIoD,EAAE,GAAGtG,CAAC,CAACD,KAAF,EAAT;AACA,UAAIwG,CAAC,GAAGvG,CAAC,CAACjD,CAAF,CAAIJ,MAAZ;;AACA,UAAGuG,WAAH,EAAgB;AACd;AACA,aAAI,IAAI3G,CAAC,GAAC,CAAV,EAAYA,CAAC,GAACgK,CAAd,EAAgBhK,CAAC,EAAjB,EAAqB;AACnB,cAAGrB,IAAI,CAACC,MAAL,KAAc,KAAKgM,SAAtB,EAAiC;AAAEb,YAAAA,EAAE,CAACvJ,CAAH,CAAKR,CAAL,IAAQ,CAAR;AAAW,iBAAK6K,OAAL,CAAa7K,CAAb,IAAkB,IAAlB;AAAyB,WAAvE,CAAwE;AAAxE,eACK;AAAC,mBAAK6K,OAAL,CAAa7K,CAAb,IAAkB,KAAlB;AAAyB;AAChC;AACF,OAND,MAMO;AACL;AACA,aAAI,IAAIA,CAAC,GAAC,CAAV,EAAYA,CAAC,GAACgK,CAAd,EAAgBhK,CAAC,EAAjB,EAAqB;AAAE+J,UAAAA,EAAE,CAACvJ,CAAH,CAAKR,CAAL,KAAS,KAAK4K,SAAd;AAA0B;AAClD;;AACD,WAAKpD,OAAL,GAAeuC,EAAf;AACA,aAAO,KAAKvC,OAAZ,CAhBgC,CAgBX;AACtB,KAlBsB;AAmBvBC,IAAAA,QAAQ,EAAE,YAAW;AACnB,UAAIhE,CAAC,GAAG,KAAKmD,MAAb,CADmB,CACE;;AACrB,UAAIc,UAAU,GAAG,KAAKF,OAAtB;AACA,UAAIwC,CAAC,GAAGvG,CAAC,CAACjD,CAAF,CAAIJ,MAAZ;AACAqD,MAAAA,CAAC,CAACd,EAAF,GAAOrE,MAAM,CAACoB,KAAP,CAAasK,CAAb,CAAP,CAJmB,CAIK;;AACxB,WAAI,IAAIhK,CAAC,GAAC,CAAV,EAAYA,CAAC,GAACgK,CAAd,EAAgBhK,CAAC,EAAjB,EAAqB;AACnB,YAAG,CAAE,KAAK6K,OAAL,CAAa7K,CAAb,CAAL,EAAuB;AACrByD,UAAAA,CAAC,CAACd,EAAF,CAAK3C,CAAL,IAAU0H,UAAU,CAAC/E,EAAX,CAAc3C,CAAd,CAAV,CADqB,CACO;AAC7B;AACF;AACF,KA7BsB;AA8BvB6H,IAAAA,iBAAiB,EAAE,YAAW;AAC5B,aAAO,EAAP;AACD,KAhCsB;AAiCvBhE,IAAAA,MAAM,EAAE,YAAW;AACjB,UAAIC,IAAI,GAAG,EAAX;AACAA,MAAAA,IAAI,CAAC6B,SAAL,GAAiB,KAAKA,SAAtB;AACA7B,MAAAA,IAAI,CAACsC,MAAL,GAAc,KAAKA,MAAnB;AACAtC,MAAAA,IAAI,CAACuC,MAAL,GAAc,KAAKA,MAAnB;AACAvC,MAAAA,IAAI,CAACwC,UAAL,GAAkB,KAAKA,UAAvB;AACAxC,MAAAA,IAAI,CAAC8G,SAAL,GAAiB,KAAKA,SAAtB;AACA,aAAO9G,IAAP;AACD,KAzCsB;AA0CvBC,IAAAA,QAAQ,EAAE,UAASD,IAAT,EAAe;AACvB,WAAK6B,SAAL,GAAiB7B,IAAI,CAAC6B,SAAtB;AACA,WAAKS,MAAL,GAActC,IAAI,CAACsC,MAAnB;AACA,WAAKC,MAAL,GAAcvC,IAAI,CAACuC,MAAnB;AACA,WAAKC,UAAL,GAAkBxC,IAAI,CAACwC,UAAvB;AACA,WAAKsE,SAAL,GAAiB9G,IAAI,CAAC8G,SAAtB;AACD;AAhDsB,GAAzB;AAoDAtM,EAAAA,MAAM,CAACqM,YAAP,GAAsBA,YAAtB;AACD,CA1ED,EA0EGvM,SA1EH;;AA2EA,CAAC,UAASE,MAAT,EAAiB;AAChB;;AACA,MAAI6D,GAAG,GAAG7D,MAAM,CAAC6D,GAAjB,CAFgB,CAEM;AAEtB;AACA;AACA;;AACA,MAAI2I,+BAA+B,GAAG,UAASpJ,GAAT,EAAc;AAClD,QAAIA,GAAG,GAAGA,GAAG,IAAI,EAAjB,CADkD,CAGlD;;AACA,SAAKF,CAAL,GAASE,GAAG,CAACF,CAAb;AACA,SAAK7B,CAAL,GAAS+B,GAAG,CAAC/B,CAAb;AACA,SAAKoL,KAAL,GAAarJ,GAAG,CAACqJ,KAAjB;AACA,SAAKC,IAAL,GAAYtJ,GAAG,CAACsJ,IAAhB,CAPkD,CASlD;;AACA,SAAK5E,MAAL,GAAc1E,GAAG,CAACoE,KAAlB;AACA,SAAKO,MAAL,GAAc3E,GAAG,CAACqE,KAAlB;AACA,SAAKJ,SAAL,GAAiBjE,GAAG,CAACmE,QAArB;AACA,SAAKS,UAAL,GAAkB,KAAlB,CAbkD,CAelD;;AACA,QAAG,KAAK3G,CAAL,GAAO,CAAP,KAAa,CAAhB,EAAmB;AAAEsL,MAAAA,OAAO,CAAChM,GAAR,CAAY,uCAAZ;AAAuD;AAC7E,GAjBD;;AAkBA6L,EAAAA,+BAA+B,CAACtI,SAAhC,GAA4C;AAC1CkE,IAAAA,OAAO,EAAE,UAASjD,CAAT,EAAYkD,WAAZ,EAAyB;AAChC,WAAKC,MAAL,GAAcnD,CAAd;AAEA,UAAIoD,CAAC,GAAGpD,CAAC,CAACF,YAAF,EAAR;AACA,WAAK2H,QAAL,GAAgBzH,CAAC,CAACF,YAAF,EAAhB;AACA,UAAI4H,EAAE,GAAGxM,IAAI,CAACW,KAAL,CAAW,KAAKK,CAAL,GAAO,CAAlB,CAAT;;AACA,WAAI,IAAImD,CAAC,GAAC,CAAV,EAAYA,CAAC,GAACW,CAAC,CAACrB,EAAhB,EAAmBU,CAAC,EAApB,EAAwB;AACtB,aAAI,IAAIC,CAAC,GAAC,CAAV,EAAYA,CAAC,GAACU,CAAC,CAACpB,EAAhB,EAAmBU,CAAC,EAApB,EAAwB;AACtB,eAAI,IAAI/C,CAAC,GAAC,CAAV,EAAYA,CAAC,GAACyD,CAAC,CAACnB,KAAhB,EAAsBtC,CAAC,EAAvB,EAA2B;AAEzB,gBAAIuK,EAAE,GAAG9G,CAAC,CAACZ,GAAF,CAAMC,CAAN,EAAQC,CAAR,EAAU/C,CAAV,CAAT,CAFyB,CAIzB;;AACA,gBAAIoL,GAAG,GAAG,GAAV;;AACA,iBAAI,IAAIrK,CAAC,GAACpC,IAAI,CAAC0M,GAAL,CAAS,CAAT,EAAWrL,CAAC,GAACmL,EAAb,CAAV,EAA2BpK,CAAC,IAAEpC,IAAI,CAAC2M,GAAL,CAAStL,CAAC,GAACmL,EAAX,EAAc1H,CAAC,CAACnB,KAAF,GAAQ,CAAtB,CAA9B,EAAuDvB,CAAC,EAAxD,EAA4D;AAC1D,kBAAIwK,EAAE,GAAG9H,CAAC,CAACZ,GAAF,CAAMC,CAAN,EAAQC,CAAR,EAAUhC,CAAV,CAAT;AACAqK,cAAAA,GAAG,IAAIG,EAAE,GAACA,EAAV;AACD;;AACDH,YAAAA,GAAG,IAAI,KAAKL,KAAL,GAAa,KAAKpL,CAAzB;AACAyL,YAAAA,GAAG,IAAI,KAAK5J,CAAZ;AACA,iBAAK0J,QAAL,CAAchI,GAAd,CAAkBJ,CAAlB,EAAoBC,CAApB,EAAsB/C,CAAtB,EAAwBoL,GAAxB,EAZyB,CAYK;;AAC9BA,YAAAA,GAAG,GAAGzM,IAAI,CAAC6M,GAAL,CAASJ,GAAT,EAAc,KAAKJ,IAAnB,CAAN;AACAnE,YAAAA,CAAC,CAAC3D,GAAF,CAAMJ,CAAN,EAAQC,CAAR,EAAU/C,CAAV,EAAYuK,EAAE,GAACa,GAAf;AACD;AACF;AACF;;AAED,WAAK5D,OAAL,GAAeX,CAAf;AACA,aAAO,KAAKW,OAAZ,CA5BgC,CA4BX;AACtB,KA9ByC;AA+B1CC,IAAAA,QAAQ,EAAE,YAAW;AACnB;AACA,UAAIhE,CAAC,GAAG,KAAKmD,MAAb,CAFmB,CAEE;;AACrBnD,MAAAA,CAAC,CAACd,EAAF,GAAOrE,MAAM,CAACoB,KAAP,CAAa+D,CAAC,CAACjD,CAAF,CAAIJ,MAAjB,CAAP,CAHmB,CAGc;;AACjC,UAAIyG,CAAC,GAAG,KAAKW,OAAb,CAJmB,CAIG;;AAEtB,UAAI2D,EAAE,GAAGxM,IAAI,CAACW,KAAL,CAAW,KAAKK,CAAL,GAAO,CAAlB,CAAT;;AACA,WAAI,IAAImD,CAAC,GAAC,CAAV,EAAYA,CAAC,GAACW,CAAC,CAACrB,EAAhB,EAAmBU,CAAC,EAApB,EAAwB;AACtB,aAAI,IAAIC,CAAC,GAAC,CAAV,EAAYA,CAAC,GAACU,CAAC,CAACpB,EAAhB,EAAmBU,CAAC,EAApB,EAAwB;AACtB,eAAI,IAAI/C,CAAC,GAAC,CAAV,EAAYA,CAAC,GAACyD,CAAC,CAACnB,KAAhB,EAAsBtC,CAAC,EAAvB,EAA2B;AAEzB,gBAAI0H,UAAU,GAAG,KAAKF,OAAL,CAAapE,QAAb,CAAsBN,CAAtB,EAAwBC,CAAxB,EAA0B/C,CAA1B,CAAjB;AACA,gBAAIyL,CAAC,GAAG,KAAKP,QAAL,CAAcrI,GAAd,CAAkBC,CAAlB,EAAoBC,CAApB,EAAsB/C,CAAtB,CAAR;AACA,gBAAI0L,EAAE,GAAG/M,IAAI,CAAC6M,GAAL,CAASC,CAAT,EAAY,KAAKT,IAAjB,CAAT;AACA,gBAAIW,GAAG,GAAGD,EAAE,GAACA,EAAb,CALyB,CAOzB;;AACA,iBAAI,IAAI3K,CAAC,GAACpC,IAAI,CAAC0M,GAAL,CAAS,CAAT,EAAWrL,CAAC,GAACmL,EAAb,CAAV,EAA2BpK,CAAC,IAAEpC,IAAI,CAAC2M,GAAL,CAAStL,CAAC,GAACmL,EAAX,EAAc1H,CAAC,CAACnB,KAAF,GAAQ,CAAtB,CAA9B,EAAuDvB,CAAC,EAAxD,EAA4D;AAC1D,kBAAI6K,EAAE,GAAGnI,CAAC,CAACZ,GAAF,CAAMC,CAAN,EAAQC,CAAR,EAAUhC,CAAV,CAAT;AACA,kBAAI8K,CAAC,GAAG,CAACD,EAAD,GAAI,KAAKZ,IAAT,GAAcrM,IAAI,CAAC6M,GAAL,CAASC,CAAT,EAAW,KAAKT,IAAL,GAAU,CAArB,CAAd,GAAsC,KAAKD,KAA3C,GAAiD,KAAKpL,CAAtD,GAAwD,CAAxD,GAA0DiM,EAAlE;AACA,kBAAG7K,CAAC,KAAGf,CAAP,EAAU6L,CAAC,IAAGH,EAAJ;AACVG,cAAAA,CAAC,IAAIF,GAAL;AACAE,cAAAA,CAAC,IAAInE,UAAL;AACAjE,cAAAA,CAAC,CAACH,QAAF,CAAWR,CAAX,EAAaC,CAAb,EAAehC,CAAf,EAAiB8K,CAAjB;AACD;AAEF;AACF;AACF;AACF,KA5DyC;AA6D1ChE,IAAAA,iBAAiB,EAAE,YAAW;AAAE,aAAO,EAAP;AAAY,KA7DF;AA8D1ChE,IAAAA,MAAM,EAAE,YAAW;AACjB,UAAIC,IAAI,GAAG,EAAX;AACAA,MAAAA,IAAI,CAACtC,CAAL,GAAS,KAAKA,CAAd;AACAsC,MAAAA,IAAI,CAACnE,CAAL,GAAS,KAAKA,CAAd;AACAmE,MAAAA,IAAI,CAACiH,KAAL,GAAa,KAAKA,KAAlB,CAJiB,CAIQ;;AACzBjH,MAAAA,IAAI,CAACkH,IAAL,GAAY,KAAKA,IAAjB;AACAlH,MAAAA,IAAI,CAACsC,MAAL,GAAc,KAAKA,MAAnB;AACAtC,MAAAA,IAAI,CAACuC,MAAL,GAAc,KAAKA,MAAnB;AACAvC,MAAAA,IAAI,CAAC6B,SAAL,GAAiB,KAAKA,SAAtB;AACA7B,MAAAA,IAAI,CAACwC,UAAL,GAAkB,KAAKA,UAAvB;AACA,aAAOxC,IAAP;AACD,KAzEyC;AA0E1CC,IAAAA,QAAQ,EAAE,UAASD,IAAT,EAAe;AACvB,WAAKtC,CAAL,GAASsC,IAAI,CAACtC,CAAd;AACA,WAAK7B,CAAL,GAASmE,IAAI,CAACnE,CAAd;AACA,WAAKoL,KAAL,GAAajH,IAAI,CAACiH,KAAlB,CAHuB,CAGE;;AACzB,WAAKC,IAAL,GAAYlH,IAAI,CAACkH,IAAjB;AACA,WAAK5E,MAAL,GAActC,IAAI,CAACsC,MAAnB;AACA,WAAKC,MAAL,GAAcvC,IAAI,CAACuC,MAAnB;AACA,WAAKV,SAAL,GAAiB7B,IAAI,CAAC6B,SAAtB;AACA,WAAKW,UAAL,GAAkBxC,IAAI,CAACwC,UAAvB;AACD;AAnFyC,GAA5C;AAuFAhI,EAAAA,MAAM,CAACwM,+BAAP,GAAyCA,+BAAzC;AACD,CAjHD,EAiHG1M,SAjHH;;AAkHA,CAAC,UAASE,MAAT,EAAiB;AAChB;;AACA,MAAI6D,GAAG,GAAG7D,MAAM,CAAC6D,GAAjB,CAFgB,CAEM;;AACtB,MAAIJ,MAAM,GAAGzD,MAAM,CAACyD,MAApB,CAHgB,CAKhB;AACA;;AACA,MAAI+J,GAAG,GAAG,UAASC,OAAT,EAAkB;AAC1B,SAAKC,MAAL,GAAc,EAAd;AACD,GAFD;;AAIAF,EAAAA,GAAG,CAACtJ,SAAJ,GAAgB;AAEd;AACAyJ,IAAAA,UAAU,EAAE,UAASC,IAAT,EAAe;AAEzB;AACAnK,MAAAA,MAAM,CAACmK,IAAI,CAAC9L,MAAL,IAAe,CAAhB,EAAmB,kEAAnB,CAAN;AACA2B,MAAAA,MAAM,CAACmK,IAAI,CAAC,CAAD,CAAJ,CAAQC,IAAR,KAAiB,OAAlB,EAA2B,uEAA3B,CAAN,CAJyB,CAMzB;;AACA,UAAIC,OAAO,GAAG,YAAW;AACvB,YAAIC,QAAQ,GAAG,EAAf;;AACA,aAAI,IAAIrM,CAAC,GAAC,CAAV,EAAYA,CAAC,GAACkM,IAAI,CAAC9L,MAAnB,EAA0BJ,CAAC,EAA3B,EAA+B;AAC7B,cAAIsM,GAAG,GAAGJ,IAAI,CAAClM,CAAD,CAAd;;AAEA,cAAGsM,GAAG,CAACH,IAAJ,KAAW,SAAX,IAAwBG,GAAG,CAACH,IAAJ,KAAW,KAAtC,EAA6C;AAC3C;AACA;AACAE,YAAAA,QAAQ,CAAC/L,IAAT,CAAc;AAAC6L,cAAAA,IAAI,EAAC,IAAN;AAAYjE,cAAAA,WAAW,EAAEoE,GAAG,CAACC;AAA7B,aAAd;AACD;;AAED,cAAGD,GAAG,CAACH,IAAJ,KAAW,YAAd,EAA4B;AAC1B;AACA;AACAE,YAAAA,QAAQ,CAAC/L,IAAT,CAAc;AAAC6L,cAAAA,IAAI,EAAC,IAAN;AAAYjE,cAAAA,WAAW,EAAEoE,GAAG,CAACpE;AAA7B,aAAd;AACD;;AAED,cAAG,CAACoE,GAAG,CAACH,IAAJ,KAAW,IAAX,IAAmBG,GAAG,CAACH,IAAJ,KAAW,MAA/B,KACI,OAAOG,GAAG,CAAC9F,SAAX,KAA0B,WADjC,EAC6C;AAC3C8F,YAAAA,GAAG,CAAC9F,SAAJ,GAAgB,GAAhB;;AACA,gBAAG,OAAO8F,GAAG,CAACE,UAAX,KAA0B,WAA1B,IAAyCF,GAAG,CAACE,UAAJ,KAAmB,MAA/D,EAAuE;AACrEF,cAAAA,GAAG,CAAC9F,SAAJ,GAAgB,GAAhB,CADqE,CAChD;AACrB;AACA;AACD;AACF;;AAED6F,UAAAA,QAAQ,CAAC/L,IAAT,CAAcgM,GAAd;;AAEA,cAAG,OAAOA,GAAG,CAACE,UAAX,KAA0B,WAA7B,EAA0C;AACxC,gBAAGF,GAAG,CAACE,UAAJ,KAAiB,MAApB,EAA4B;AAAEH,cAAAA,QAAQ,CAAC/L,IAAT,CAAc;AAAC6L,gBAAAA,IAAI,EAAC;AAAN,eAAd;AAA+B,aAA7D,MACK,IAAIG,GAAG,CAACE,UAAJ,KAAiB,SAArB,EAAgC;AAAEH,cAAAA,QAAQ,CAAC/L,IAAT,CAAc;AAAC6L,gBAAAA,IAAI,EAAC;AAAN,eAAd;AAAkC,aAApE,MACA,IAAIG,GAAG,CAACE,UAAJ,KAAiB,MAArB,EAA6B;AAAEH,cAAAA,QAAQ,CAAC/L,IAAT,CAAc;AAAC6L,gBAAAA,IAAI,EAAC;AAAN,eAAd;AAA+B,aAA9D,MACA,IAAIG,GAAG,CAACE,UAAJ,KAAiB,QAArB,EAA+B;AAClC;AACA,kBAAIC,EAAE,GAAGH,GAAG,CAACjC,UAAJ,KAAmB,WAAnB,GAAiCiC,GAAG,CAACjC,UAArC,GAAkD,CAA3D;AACAgC,cAAAA,QAAQ,CAAC/L,IAAT,CAAc;AAAC6L,gBAAAA,IAAI,EAAC,QAAN;AAAgB9B,gBAAAA,UAAU,EAACoC;AAA3B,eAAd;AACD,aAJI,MAKA;AAAExB,cAAAA,OAAO,CAAChM,GAAR,CAAY,kCAAkCqN,GAAG,CAACE,UAAlD;AAAgE;AACxE;;AACD,cAAG,OAAOF,GAAG,CAAC1B,SAAX,KAAyB,WAAzB,IAAwC0B,GAAG,CAACH,IAAJ,KAAa,SAAxD,EAAmE;AACjEE,YAAAA,QAAQ,CAAC/L,IAAT,CAAc;AAAC6L,cAAAA,IAAI,EAAC,SAAN;AAAiBvB,cAAAA,SAAS,EAAE0B,GAAG,CAAC1B;AAAhC,aAAd;AACD;AAEF;;AACD,eAAOyB,QAAP;AACD,OA9CD;;AA+CAH,MAAAA,IAAI,GAAGE,OAAO,CAACF,IAAD,CAAd,CAtDyB,CAwDzB;;AACA,WAAKF,MAAL,GAAc,EAAd;;AACA,WAAI,IAAIhM,CAAC,GAAC,CAAV,EAAYA,CAAC,GAACkM,IAAI,CAAC9L,MAAnB,EAA0BJ,CAAC,EAA3B,EAA+B;AAC7B,YAAIsM,GAAG,GAAGJ,IAAI,CAAClM,CAAD,CAAd;;AACA,YAAGA,CAAC,GAAC,CAAL,EAAQ;AACN,cAAI0M,IAAI,GAAG,KAAKV,MAAL,CAAYhM,CAAC,GAAC,CAAd,CAAX;AACAsM,UAAAA,GAAG,CAACxG,KAAJ,GAAY4G,IAAI,CAACtG,MAAjB;AACAkG,UAAAA,GAAG,CAACvG,KAAJ,GAAY2G,IAAI,CAACrG,MAAjB;AACAiG,UAAAA,GAAG,CAACzG,QAAJ,GAAe6G,IAAI,CAAC/G,SAApB;AACD;;AAED,gBAAO2G,GAAG,CAACH,IAAX;AACE,eAAK,IAAL;AAAW,iBAAKH,MAAL,CAAY1L,IAAZ,CAAiB,IAAIhC,MAAM,CAAC2J,cAAX,CAA0BqE,GAA1B,CAAjB;AAAkD;;AAC7D,eAAK,KAAL;AAAY,iBAAKN,MAAL,CAAY1L,IAAZ,CAAiB,IAAIhC,MAAM,CAACwM,+BAAX,CAA2CwB,GAA3C,CAAjB;AAAmE;;AAC/E,eAAK,SAAL;AAAgB,iBAAKN,MAAL,CAAY1L,IAAZ,CAAiB,IAAIhC,MAAM,CAACqM,YAAX,CAAwB2B,GAAxB,CAAjB;AAAgD;;AAChE,eAAK,OAAL;AAAc,iBAAKN,MAAL,CAAY1L,IAAZ,CAAiB,IAAIhC,MAAM,CAACsK,UAAX,CAAsB0D,GAAtB,CAAjB;AAA8C;;AAC5D,eAAK,SAAL;AAAgB,iBAAKN,MAAL,CAAY1L,IAAZ,CAAiB,IAAIhC,MAAM,CAACuK,YAAX,CAAwByD,GAAxB,CAAjB;AAAgD;;AAChE,eAAK,YAAL;AAAmB,iBAAKN,MAAL,CAAY1L,IAAZ,CAAiB,IAAIhC,MAAM,CAAC+K,eAAX,CAA2BiD,GAA3B,CAAjB;AAAmD;;AACtE,eAAK,MAAL;AAAa,iBAAKN,MAAL,CAAY1L,IAAZ,CAAiB,IAAIhC,MAAM,CAACoH,SAAX,CAAqB4G,GAArB,CAAjB;AAA6C;;AAC1D,eAAK,MAAL;AAAa,iBAAKN,MAAL,CAAY1L,IAAZ,CAAiB,IAAIhC,MAAM,CAACiK,SAAX,CAAqB+D,GAArB,CAAjB;AAA6C;;AAC1D,eAAK,MAAL;AAAa,iBAAKN,MAAL,CAAY1L,IAAZ,CAAiB,IAAIhC,MAAM,CAACwL,SAAX,CAAqBwC,GAArB,CAAjB;AAA6C;;AAC1D,eAAK,SAAL;AAAgB,iBAAKN,MAAL,CAAY1L,IAAZ,CAAiB,IAAIhC,MAAM,CAAC4L,YAAX,CAAwBoC,GAAxB,CAAjB;AAAgD;;AAChE,eAAK,MAAL;AAAa,iBAAKN,MAAL,CAAY1L,IAAZ,CAAiB,IAAIhC,MAAM,CAACoM,SAAX,CAAqB4B,GAArB,CAAjB;AAA6C;;AAC1D,eAAK,QAAL;AAAe,iBAAKN,MAAL,CAAY1L,IAAZ,CAAiB,IAAIhC,MAAM,CAAC8L,WAAX,CAAuBkC,GAAvB,CAAjB;AAA+C;;AAC9D,eAAK,KAAL;AAAY,iBAAKN,MAAL,CAAY1L,IAAZ,CAAiB,IAAIhC,MAAM,CAACoL,QAAX,CAAoB4C,GAApB,CAAjB;AAA4C;;AACxD;AAASrB,YAAAA,OAAO,CAAChM,GAAR,CAAY,qCAAqCqN,GAAG,CAACH,IAArD;AAdX;AAgBD;AACF,KAvFa;AAyFd;AACA;AACA;AACAzF,IAAAA,OAAO,EAAE,UAASjD,CAAT,EAAYkD,WAAZ,EAAyB;AAChC,UAAG,OAAOA,WAAP,KAAwB,WAA3B,EAAwCA,WAAW,GAAG,KAAd;AACxC,UAAIgG,GAAG,GAAG,KAAKX,MAAL,CAAY,CAAZ,EAAetF,OAAf,CAAuBjD,CAAvB,EAA0BkD,WAA1B,CAAV;;AACA,WAAI,IAAI3G,CAAC,GAAC,CAAV,EAAYA,CAAC,GAAC,KAAKgM,MAAL,CAAY5L,MAA1B,EAAiCJ,CAAC,EAAlC,EAAsC;AACpC2M,QAAAA,GAAG,GAAG,KAAKX,MAAL,CAAYhM,CAAZ,EAAe0G,OAAf,CAAuBiG,GAAvB,EAA4BhG,WAA5B,CAAN;AACD;;AACD,aAAOgG,GAAP;AACD,KAnGa;AAqGdC,IAAAA,WAAW,EAAE,UAASnJ,CAAT,EAAYV,CAAZ,EAAe;AAC1B,WAAK2D,OAAL,CAAajD,CAAb,EAAgB,KAAhB;AACA,UAAIuG,CAAC,GAAG,KAAKgC,MAAL,CAAY5L,MAApB;AACA,UAAIkJ,IAAI,GAAG,KAAK0C,MAAL,CAAYhC,CAAC,GAAC,CAAd,EAAiBvC,QAAjB,CAA0B1E,CAA1B,CAAX;AACA,aAAOuG,IAAP;AACD,KA1Ga;AA4Gd;AACA7B,IAAAA,QAAQ,EAAE,UAAS1E,CAAT,EAAY;AACpB,UAAIiH,CAAC,GAAG,KAAKgC,MAAL,CAAY5L,MAApB;AACA,UAAIkJ,IAAI,GAAG,KAAK0C,MAAL,CAAYhC,CAAC,GAAC,CAAd,EAAiBvC,QAAjB,CAA0B1E,CAA1B,CAAX,CAFoB,CAEqB;;AACzC,WAAI,IAAI/C,CAAC,GAACgK,CAAC,GAAC,CAAZ,EAAchK,CAAC,IAAE,CAAjB,EAAmBA,CAAC,EAApB,EAAwB;AAAE;AACxB,aAAKgM,MAAL,CAAYhM,CAAZ,EAAeyH,QAAf;AACD;;AACD,aAAO6B,IAAP;AACD,KApHa;AAqHdzB,IAAAA,iBAAiB,EAAE,YAAW;AAC5B;AACA,UAAIC,QAAQ,GAAG,EAAf;;AACA,WAAI,IAAI9H,CAAC,GAAC,CAAV,EAAYA,CAAC,GAAC,KAAKgM,MAAL,CAAY5L,MAA1B,EAAiCJ,CAAC,EAAlC,EAAsC;AACpC,YAAI6M,aAAa,GAAG,KAAKb,MAAL,CAAYhM,CAAZ,EAAe6H,iBAAf,EAApB;;AACA,aAAI,IAAI9G,CAAC,GAAC,CAAV,EAAYA,CAAC,GAAC8L,aAAa,CAACzM,MAA5B,EAAmCW,CAAC,EAApC,EAAwC;AACtC+G,UAAAA,QAAQ,CAACxH,IAAT,CAAcuM,aAAa,CAAC9L,CAAD,CAA3B;AACD;AACF;;AACD,aAAO+G,QAAP;AACD,KA/Ha;AAgIdgF,IAAAA,aAAa,EAAE,YAAW;AACxB;AACA;AACA,UAAIrB,CAAC,GAAG,KAAKO,MAAL,CAAY,KAAKA,MAAL,CAAY5L,MAAZ,GAAmB,CAA/B,CAAR;AACA2B,MAAAA,MAAM,CAAC0J,CAAC,CAACnF,UAAF,KAAiB,SAAlB,EAA6B,kEAA7B,CAAN;AAEA,UAAIhF,CAAC,GAAGmK,CAAC,CAACjE,OAAF,CAAUhH,CAAlB;AACA,UAAIC,IAAI,GAAGa,CAAC,CAAC,CAAD,CAAZ;AACA,UAAIX,IAAI,GAAG,CAAX;;AACA,WAAI,IAAIX,CAAC,GAAC,CAAV,EAAYA,CAAC,GAACsB,CAAC,CAAClB,MAAhB,EAAuBJ,CAAC,EAAxB,EAA4B;AAC1B,YAAGsB,CAAC,CAACtB,CAAD,CAAD,GAAOS,IAAV,EAAgB;AAAEA,UAAAA,IAAI,GAAGa,CAAC,CAACtB,CAAD,CAAR;AAAaW,UAAAA,IAAI,GAAGX,CAAP;AAAU;AAC1C;;AACD,aAAOW,IAAP,CAZwB,CAYX;AACd,KA7Ia;AA8IdkD,IAAAA,MAAM,EAAE,YAAW;AACjB,UAAIC,IAAI,GAAG,EAAX;AACAA,MAAAA,IAAI,CAACkI,MAAL,GAAc,EAAd;;AACA,WAAI,IAAIhM,CAAC,GAAC,CAAV,EAAYA,CAAC,GAAC,KAAKgM,MAAL,CAAY5L,MAA1B,EAAiCJ,CAAC,EAAlC,EAAsC;AACpC8D,QAAAA,IAAI,CAACkI,MAAL,CAAY1L,IAAZ,CAAiB,KAAK0L,MAAL,CAAYhM,CAAZ,EAAe6D,MAAf,EAAjB;AACD;;AACD,aAAOC,IAAP;AACD,KArJa;AAsJdC,IAAAA,QAAQ,EAAE,UAASD,IAAT,EAAe;AACvB,WAAKkI,MAAL,GAAc,EAAd;;AACA,WAAI,IAAIhM,CAAC,GAAC,CAAV,EAAYA,CAAC,GAAC8D,IAAI,CAACkI,MAAL,CAAY5L,MAA1B,EAAiCJ,CAAC,EAAlC,EAAsC;AACpC,YAAI+M,EAAE,GAAGjJ,IAAI,CAACkI,MAAL,CAAYhM,CAAZ,CAAT;AACA,YAAIgN,CAAC,GAAGD,EAAE,CAACzG,UAAX;AACA,YAAI2G,CAAJ;;AACA,YAAGD,CAAC,KAAG,OAAP,EAAgB;AAAEC,UAAAA,CAAC,GAAG,IAAI3O,MAAM,CAACsK,UAAX,EAAJ;AAA8B;;AAChD,YAAGoE,CAAC,KAAG,MAAP,EAAe;AAAEC,UAAAA,CAAC,GAAG,IAAI3O,MAAM,CAACwL,SAAX,EAAJ;AAA6B;;AAC9C,YAAGkD,CAAC,KAAG,SAAP,EAAkB;AAAEC,UAAAA,CAAC,GAAG,IAAI3O,MAAM,CAAC4L,YAAX,EAAJ;AAAgC;;AACpD,YAAG8C,CAAC,KAAG,MAAP,EAAe;AAAEC,UAAAA,CAAC,GAAG,IAAI3O,MAAM,CAACoM,SAAX,EAAJ;AAA6B;;AAC9C,YAAGsC,CAAC,KAAG,SAAP,EAAkB;AAAEC,UAAAA,CAAC,GAAG,IAAI3O,MAAM,CAACqM,YAAX,EAAJ;AAAgC;;AACpD,YAAGqC,CAAC,KAAG,MAAP,EAAe;AAAEC,UAAAA,CAAC,GAAG,IAAI3O,MAAM,CAACoH,SAAX,EAAJ;AAA6B;;AAC9C,YAAGsH,CAAC,KAAG,MAAP,EAAe;AAAEC,UAAAA,CAAC,GAAG,IAAI3O,MAAM,CAACiK,SAAX,EAAJ;AAA6B;;AAC9C,YAAGyE,CAAC,KAAG,KAAP,EAAc;AAAEC,UAAAA,CAAC,GAAG,IAAI3O,MAAM,CAACwM,+BAAX,EAAJ;AAAmD;;AACnE,YAAGkC,CAAC,KAAG,SAAP,EAAkB;AAAEC,UAAAA,CAAC,GAAG,IAAI3O,MAAM,CAACuK,YAAX,EAAJ;AAAgC;;AACpD,YAAGmE,CAAC,KAAG,YAAP,EAAqB;AAAEC,UAAAA,CAAC,GAAG,IAAI3O,MAAM,CAAC+K,eAAX,EAAJ;AAAmC;;AAC1D,YAAG2D,CAAC,KAAG,IAAP,EAAa;AAAEC,UAAAA,CAAC,GAAG,IAAI3O,MAAM,CAAC2J,cAAX,EAAJ;AAAkC;;AACjD,YAAG+E,CAAC,KAAG,QAAP,EAAiB;AAAEC,UAAAA,CAAC,GAAG,IAAI3O,MAAM,CAAC8L,WAAX,EAAJ;AAA+B;;AAClD,YAAG4C,CAAC,KAAG,KAAP,EAAc;AAAEC,UAAAA,CAAC,GAAG,IAAI3O,MAAM,CAACoL,QAAX,EAAJ;AAA4B;;AAC5CuD,QAAAA,CAAC,CAAClJ,QAAF,CAAWgJ,EAAX;AACA,aAAKf,MAAL,CAAY1L,IAAZ,CAAiB2M,CAAjB;AACD;AACF;AA5Ka,GAAhB;AA+KA3O,EAAAA,MAAM,CAACwN,GAAP,GAAaA,GAAb;AACD,CA3LD,EA2LG1N,SA3LH;;AA4LA,CAAC,UAASE,MAAT,EAAiB;AAChB;;AACA,MAAI6D,GAAG,GAAG7D,MAAM,CAAC6D,GAAjB,CAFgB,CAEM;;AAEtB,MAAI+K,OAAO,GAAG,UAASC,GAAT,EAAcpB,OAAd,EAAuB;AAEnC,SAAKoB,GAAL,GAAWA,GAAX;AAEA,QAAIpB,OAAO,GAAGA,OAAO,IAAI,EAAzB;AACA,SAAKqB,aAAL,GAAqB,OAAOrB,OAAO,CAACqB,aAAf,KAAiC,WAAjC,GAA+CrB,OAAO,CAACqB,aAAvD,GAAuE,IAA5F;AACA,SAAKC,QAAL,GAAgB,OAAOtB,OAAO,CAACsB,QAAf,KAA4B,WAA5B,GAA0CtB,OAAO,CAACsB,QAAlD,GAA6D,GAA7E;AACA,SAAKC,QAAL,GAAgB,OAAOvB,OAAO,CAACuB,QAAf,KAA4B,WAA5B,GAA0CvB,OAAO,CAACuB,QAAlD,GAA6D,GAA7E;AACA,SAAKC,UAAL,GAAkB,OAAOxB,OAAO,CAACwB,UAAf,KAA8B,WAA9B,GAA4CxB,OAAO,CAACwB,UAApD,GAAiE,CAAnF;AACA,SAAKC,MAAL,GAAc,OAAOzB,OAAO,CAACyB,MAAf,KAA0B,WAA1B,GAAwCzB,OAAO,CAACyB,MAAhD,GAAyD,KAAvE,CATmC,CAS2C;;AAE9E,SAAKC,QAAL,GAAgB,OAAO1B,OAAO,CAAC0B,QAAf,KAA4B,WAA5B,GAA0C1B,OAAO,CAAC0B,QAAlD,GAA6D,GAA7E;AACA,SAAKC,EAAL,GAAU,OAAO3B,OAAO,CAAC2B,EAAf,KAAsB,WAAtB,GAAoC3B,OAAO,CAAC2B,EAA5C,GAAiD,IAA3D,CAZmC,CAY8B;;AACjE,SAAKC,GAAL,GAAW,OAAO5B,OAAO,CAAC4B,GAAf,KAAuB,WAAvB,GAAqC5B,OAAO,CAAC4B,GAA7C,GAAmD,IAA9D,CAbmC,CAaiC;;AAEpE,SAAKnM,CAAL,GAAS,CAAT,CAfmC,CAevB;;AACZ,SAAKoM,IAAL,GAAY,EAAZ,CAhBmC,CAgBnB;;AAChB,SAAKC,IAAL,GAAY,EAAZ,CAjBmC,CAiBnB;AACjB,GAlBD;;AAoBAX,EAAAA,OAAO,CAAC1K,SAAR,GAAoB;AAClBsL,IAAAA,KAAK,EAAE,UAAShL,CAAT,EAAYC,CAAZ,EAAe;AAEpB,UAAIgL,KAAK,GAAG,IAAIC,IAAJ,GAAWC,OAAX,EAAZ;AACA,WAAKd,GAAL,CAASzG,OAAT,CAAiB5D,CAAjB,EAAoB,IAApB,EAHoB,CAGO;;AAC3B,UAAIoL,GAAG,GAAG,IAAIF,IAAJ,GAAWC,OAAX,EAAV;AACA,UAAIE,QAAQ,GAAGD,GAAG,GAAGH,KAArB;AAEA,UAAIA,KAAK,GAAG,IAAIC,IAAJ,GAAWC,OAAX,EAAZ;AACA,UAAIG,SAAS,GAAG,KAAKjB,GAAL,CAAS1F,QAAT,CAAkB1E,CAAlB,CAAhB;AACA,UAAIsL,aAAa,GAAG,GAApB;AACA,UAAIC,aAAa,GAAG,GAApB;AACA,UAAIJ,GAAG,GAAG,IAAIF,IAAJ,GAAWC,OAAX,EAAV;AACA,UAAIM,QAAQ,GAAGL,GAAG,GAAGH,KAArB;AAEA,WAAKvM,CAAL;;AACA,UAAG,KAAKA,CAAL,GAAS,KAAK+L,UAAd,KAA6B,CAAhC,EAAmC;AAEjC,YAAIiB,MAAM,GAAG,KAAKrB,GAAL,CAAStF,iBAAT,EAAb,CAFiC,CAIjC;;AACA,YAAG,KAAK+F,IAAL,CAAUxN,MAAV,KAAqB,CAArB,KAA2B,KAAKoN,MAAL,KAAgB,KAAhB,IAAyB,KAAKC,QAAL,GAAgB,GAApE,CAAH,EAA6E;AAC3E;AACA;AACA;AACA;AACA,eAAI,IAAIzN,CAAC,GAAC,CAAV,EAAYA,CAAC,GAACwO,MAAM,CAACpO,MAArB,EAA4BJ,CAAC,EAA7B,EAAiC;AAC/B,iBAAK4N,IAAL,CAAUtN,IAAV,CAAehC,MAAM,CAACoB,KAAP,CAAa8O,MAAM,CAACxO,CAAD,CAAN,CAAU+H,MAAV,CAAiB3H,MAA9B,CAAf;;AACA,gBAAG,KAAKoN,MAAL,KAAgB,UAAnB,EAA+B;AAC7B,mBAAKK,IAAL,CAAUvN,IAAV,CAAehC,MAAM,CAACoB,KAAP,CAAa8O,MAAM,CAACxO,CAAD,CAAN,CAAU+H,MAAV,CAAiB3H,MAA9B,CAAf;AACD,aAFD,MAEO;AACL,mBAAKyN,IAAL,CAAUvN,IAAV,CAAe,EAAf,EADK,CACe;AACrB;AACF;AACF,SAlBgC,CAoBjC;;;AACA,aAAI,IAAIN,CAAC,GAAC,CAAV,EAAYA,CAAC,GAACwO,MAAM,CAACpO,MAArB,EAA4BJ,CAAC,EAA7B,EAAiC;AAC/B,cAAIyO,EAAE,GAAGD,MAAM,CAACxO,CAAD,CAAf,CAD+B,CACX;;AACpB,cAAIsB,CAAC,GAAGmN,EAAE,CAAC1G,MAAX;AACA,cAAI8D,CAAC,GAAG4C,EAAE,CAACzG,KAAX,CAH+B,CAK/B;;AACA,cAAI7B,YAAY,GAAG,OAAOsI,EAAE,CAACtI,YAAV,KAA2B,WAA3B,GAAyCsI,EAAE,CAACtI,YAA5C,GAA2D,GAA9E;AACA,cAAID,YAAY,GAAG,OAAOuI,EAAE,CAACvI,YAAV,KAA2B,WAA3B,GAAyCuI,EAAE,CAACvI,YAA5C,GAA2D,GAA9E;AACA,cAAIoH,QAAQ,GAAG,KAAKA,QAAL,GAAgBnH,YAA/B;AACA,cAAIkH,QAAQ,GAAG,KAAKA,QAAL,GAAgBnH,YAA/B;AAEA,cAAIwI,IAAI,GAAGpN,CAAC,CAAClB,MAAb;;AACA,eAAI,IAAIW,CAAC,GAAC,CAAV,EAAYA,CAAC,GAAC2N,IAAd,EAAmB3N,CAAC,EAApB,EAAwB;AACtBsN,YAAAA,aAAa,IAAIf,QAAQ,GAAChM,CAAC,CAACP,CAAD,CAAV,GAAcO,CAAC,CAACP,CAAD,CAAf,GAAmB,CAApC,CADsB,CACiB;;AACvCuN,YAAAA,aAAa,IAAIjB,QAAQ,GAAC1O,IAAI,CAACgQ,GAAL,CAASrN,CAAC,CAACP,CAAD,CAAV,CAA1B;AACA,gBAAI6N,MAAM,GAAGvB,QAAQ,IAAI/L,CAAC,CAACP,CAAD,CAAD,GAAO,CAAP,GAAW,CAAX,GAAe,CAAC,CAApB,CAArB;AACA,gBAAI8N,MAAM,GAAGvB,QAAQ,GAAIhM,CAAC,CAACP,CAAD,CAA1B;AAEA,gBAAI+N,GAAG,GAAG,CAACD,MAAM,GAAGD,MAAT,GAAkB/C,CAAC,CAAC9K,CAAD,CAApB,IAA2B,KAAKwM,UAA1C,CANsB,CAMgC;;AAEtD,gBAAIwB,KAAK,GAAG,KAAKnB,IAAL,CAAU5N,CAAV,CAAZ;AACA,gBAAIgP,KAAK,GAAG,KAAKnB,IAAL,CAAU7N,CAAV,CAAZ;;AACA,gBAAG,KAAKwN,MAAL,KAAgB,SAAnB,EAA8B;AAC5B;AACAuB,cAAAA,KAAK,CAAChO,CAAD,CAAL,GAAWgO,KAAK,CAAChO,CAAD,CAAL,GAAW+N,GAAG,GAAGA,GAA5B;AACA,kBAAI5K,EAAE,GAAG,CAAE,KAAKkJ,aAAP,GAAuBzO,IAAI,CAACK,IAAL,CAAU+P,KAAK,CAAChO,CAAD,CAAL,GAAW,KAAK4M,GAA1B,CAAvB,GAAwDmB,GAAjE;AACAxN,cAAAA,CAAC,CAACP,CAAD,CAAD,IAAQmD,EAAR;AACD,aALD,MAKO,IAAG,KAAKsJ,MAAL,KAAgB,YAAnB,EAAiC;AACtC;AACA;AACA;AACAuB,cAAAA,KAAK,CAAChO,CAAD,CAAL,GAAW,KAAK2M,EAAL,GAAUqB,KAAK,CAAChO,CAAD,CAAf,GAAqB,CAAC,IAAE,KAAK2M,EAAR,IAAcoB,GAAd,GAAoBA,GAApD;AACA,kBAAI5K,EAAE,GAAG,CAAE,KAAKkJ,aAAP,GAAuBzO,IAAI,CAACK,IAAL,CAAU+P,KAAK,CAAChO,CAAD,CAAL,GAAW,KAAK4M,GAA1B,CAAvB,GAAwDmB,GAAjE,CALsC,CAKgC;;AACtExN,cAAAA,CAAC,CAACP,CAAD,CAAD,IAAQmD,EAAR;AACD,aAPM,MAOA,IAAG,KAAKsJ,MAAL,KAAgB,UAAnB,EAA+B;AACpC;AACAuB,cAAAA,KAAK,CAAChO,CAAD,CAAL,GAAW,KAAK2M,EAAL,GAAUqB,KAAK,CAAChO,CAAD,CAAf,GAAqB,CAAC,IAAE,KAAK2M,EAAR,IAAcoB,GAAd,GAAoBA,GAApD;AACA,kBAAI5K,EAAE,GAAG,CAAEvF,IAAI,CAACK,IAAL,CAAU,CAACgQ,KAAK,CAACjO,CAAD,CAAL,GAAW,KAAK4M,GAAjB,KAAuBoB,KAAK,CAAChO,CAAD,CAAL,GAAW,KAAK4M,GAAvC,CAAV,CAAF,GAA2DmB,GAApE;AACAE,cAAAA,KAAK,CAACjO,CAAD,CAAL,GAAW,KAAK2M,EAAL,GAAUsB,KAAK,CAACjO,CAAD,CAAf,GAAqB,CAAC,IAAE,KAAK2M,EAAR,IAAcxJ,EAAd,GAAmBA,EAAnD,CAJoC,CAImB;;AACvD5C,cAAAA,CAAC,CAACP,CAAD,CAAD,IAAQmD,EAAR;AACD,aANM,MAMA,IAAG,KAAKsJ,MAAL,KAAgB,UAAnB,EAA+B;AACrC,kBAAItJ,EAAE,GAAG6K,KAAK,CAAChO,CAAD,CAAd;AACAgO,cAAAA,KAAK,CAAChO,CAAD,CAAL,GAAWgO,KAAK,CAAChO,CAAD,CAAL,GAAW,KAAK0M,QAAhB,GAA2B,KAAKL,aAAL,GAAqB0B,GAA3D;AACG5K,cAAAA,EAAE,GAAG,KAAKuJ,QAAL,GAAgBvJ,EAAhB,GAAqB,CAAC,MAAM,KAAKuJ,QAAZ,IAAwBsB,KAAK,CAAChO,CAAD,CAAvD;AACAO,cAAAA,CAAC,CAACP,CAAD,CAAD,IAAQmD,EAAR;AACH,aALM,MAKA;AACL;AACA,kBAAG,KAAKuJ,QAAL,GAAgB,GAAnB,EAAwB;AACtB;AACA,oBAAIvJ,EAAE,GAAG,KAAKuJ,QAAL,GAAgBsB,KAAK,CAAChO,CAAD,CAArB,GAA2B,KAAKqM,aAAL,GAAqB0B,GAAzD,CAFsB,CAEwC;;AAC9DC,gBAAAA,KAAK,CAAChO,CAAD,CAAL,GAAWmD,EAAX,CAHsB,CAGP;;AACf5C,gBAAAA,CAAC,CAACP,CAAD,CAAD,IAAQmD,EAAR,CAJsB,CAIV;AACb,eALD,MAKO;AACL;AACA5C,gBAAAA,CAAC,CAACP,CAAD,CAAD,IAAS,CAAE,KAAKqM,aAAP,GAAuB0B,GAAhC;AACD;AACF;;AACDjD,YAAAA,CAAC,CAAC9K,CAAD,CAAD,GAAO,GAAP,CA7CsB,CA6CV;AACb;AACF;AACF,OAhGmB,CAkGpB;AACA;AACA;AACA;;;AACA,aAAO;AAACoN,QAAAA,QAAQ,EAAEA,QAAX;AAAqBI,QAAAA,QAAQ,EAAEA,QAA/B;AACCF,QAAAA,aAAa,EAAEA,aADhB;AAC+BC,QAAAA,aAAa,EAAEA,aAD9C;AAECF,QAAAA,SAAS,EAAEA,SAFZ;AAEuBa,QAAAA,YAAY,EAAEb,SAFrC;AAGC9E,QAAAA,IAAI,EAAE8E,SAAS,GAAGE,aAAZ,GAA4BD;AAHnC,OAAP;AAID;AA3GiB,GAApB;AA8GA/P,EAAAA,MAAM,CAAC4O,OAAP,GAAiBA,OAAjB;AACA5O,EAAAA,MAAM,CAAC4Q,UAAP,GAAoBhC,OAApB,CAvIgB,CAuIa;AAC9B,CAxID,EAwIG9O,SAxIH;;AA0IA,CAAC,UAASE,MAAT,EAAiB;AAChB,eADgB,CAGhB;;AACA,MAAIY,KAAK,GAAGZ,MAAM,CAACY,KAAnB;AACA,MAAIG,KAAK,GAAGf,MAAM,CAACe,KAAnB;AACA,MAAIyM,GAAG,GAAGxN,MAAM,CAACwN,GAAjB;AACA,MAAIoB,OAAO,GAAG5O,MAAM,CAAC4O,OAArB;AACA,MAAI3M,MAAM,GAAGjC,MAAM,CAACiC,MAApB;AACA,MAAIO,QAAQ,GAAGxC,MAAM,CAACwC,QAAtB;AACA,MAAIK,cAAc,GAAG7C,MAAM,CAAC6C,cAA5B;AACA,MAAIM,MAAM,GAAGnD,MAAM,CAACmD,MAApB;AACA,MAAIpB,SAAS,GAAG/B,MAAM,CAAC+B,SAAvB;AAEA;;;;;;;;;AAQA,MAAI8O,QAAQ,GAAG,UAAS7J,IAAT,EAAe8J,MAAf,EAAuB1N,GAAvB,EAA4B;AACzC,QAAIA,GAAG,GAAGA,GAAG,IAAI,EAAjB;;AACA,QAAG,OAAO4D,IAAP,KAAgB,WAAnB,EAAgC;AAAEA,MAAAA,IAAI,GAAG,EAAP;AAAY;;AAC9C,QAAG,OAAO8J,MAAP,KAAkB,WAArB,EAAkC;AAAEA,MAAAA,MAAM,GAAG,EAAT;AAAc,KAHT,CAKzC;;;AACA,SAAK9J,IAAL,GAAYA,IAAZ,CANyC,CAMvB;;AAClB,SAAK8J,MAAL,GAAcA,MAAd,CAPyC,CASzC;;AACA,SAAKC,WAAL,GAAmB5N,MAAM,CAACC,GAAD,EAAM,aAAN,EAAqB,GAArB,CAAzB;AACA,SAAK4N,SAAL,GAAiB7N,MAAM,CAACC,GAAD,EAAM,WAAN,EAAmB,EAAnB,CAAvB;AACA,SAAK6N,cAAL,GAAsB9N,MAAM,CAACC,GAAD,EAAM,gBAAN,EAAwB,EAAxB,CAA5B,CAZyC,CAYgB;AACzD;AACA;;AACA,SAAK8N,UAAL,GAAkB/N,MAAM,CAACC,GAAD,EAAM,YAAN,EAAoB,EAApB,CAAxB,CAfyC,CAgBzC;;AACA,SAAK+N,aAAL,GAAqBhO,MAAM,CAACC,GAAD,EAAM,eAAN,EAAuB,EAAvB,CAA3B,CAjByC,CAmBzC;;AACA,SAAKgO,cAAL,GAAsBjO,MAAM,CAACC,GAAD,EAAM,gBAAN,EAAwB,EAAxB,CAA5B;AACA,SAAKiO,cAAL,GAAsBlO,MAAM,CAACC,GAAD,EAAM,gBAAN,EAAwB,GAAxB,CAA5B;AACA,SAAKkO,YAAL,GAAoBnO,MAAM,CAACC,GAAD,EAAM,cAAN,EAAsB,CAAC,CAAvB,CAA1B;AACA,SAAKmO,YAAL,GAAoBpO,MAAM,CAACC,GAAD,EAAM,cAAN,EAAsB,CAAtB,CAA1B;AACA,SAAKoO,iBAAL,GAAyBrO,MAAM,CAACC,GAAD,EAAM,mBAAN,EAA2B,CAAC,CAA5B,CAA/B;AACA,SAAKqO,iBAAL,GAAyBtO,MAAM,CAACC,GAAD,EAAM,mBAAN,EAA2B,CAA3B,CAA/B;AACA,SAAKsO,YAAL,GAAoBvO,MAAM,CAACC,GAAD,EAAM,cAAN,EAAsB,GAAtB,CAA1B;AACA,SAAKuO,YAAL,GAAoBxO,MAAM,CAACC,GAAD,EAAM,cAAN,EAAsB,GAAtB,CAA1B;AACA,SAAKwO,WAAL,GAAmBzO,MAAM,CAACC,GAAD,EAAM,aAAN,EAAqB,CAArB,CAAzB;AACA,SAAKyO,WAAL,GAAmB1O,MAAM,CAACC,GAAD,EAAM,aAAN,EAAqB,EAArB,CAAzB,CA7ByC,CA+BzC;;AACA,SAAK0O,KAAL,GAAa,EAAb,CAhCyC,CAgCxB;;AACjB,SAAKC,UAAL,GAAkB,EAAlB,CAjCyC,CAiCnB;;AACtB,SAAKC,oBAAL,GAA4B,EAA5B,CAlCyC,CAkCT;;AAChC,SAAKC,aAAL,GAAqBlQ,SAAS,CAAC+O,MAAD,CAA9B;AACA,SAAKoB,IAAL,GAAY,CAAZ,CApCyC,CAoC1B;;AACf,SAAKC,MAAL,GAAc,CAAd,CArCyC,CAqCxB;AAEjB;;AACA,SAAKC,oBAAL,GAA4B,IAA5B;AACA,SAAKC,qBAAL,GAA6B,IAA7B,CAzCyC,CA2CzC;;AACA,QAAG,KAAKrL,IAAL,CAAUlF,MAAV,GAAmB,CAAtB,EAAyB;AACvB,WAAKwQ,WAAL;AACA,WAAKC,gBAAL;AACD;AACF,GAhDD;;AAkDA1B,EAAAA,QAAQ,CAAC3M,SAAT,GAAqB;AAEnB;AACAoO,IAAAA,WAAW,EAAE,YAAW;AACtB,UAAI5G,CAAC,GAAG,KAAK1E,IAAL,CAAUlF,MAAlB;AACA,UAAI0Q,SAAS,GAAGnS,IAAI,CAACW,KAAL,CAAW,KAAK+P,WAAL,GAAmBrF,CAA9B,CAAhB;AACA,WAAKoG,KAAL,GAAa,EAAb,CAHsB,CAGL;;AACjB,WAAI,IAAIpQ,CAAC,GAAC,CAAV,EAAYA,CAAC,GAAC,KAAKsP,SAAnB,EAA6BtP,CAAC,EAA9B,EAAkC;AAChC,YAAIsB,CAAC,GAAGR,QAAQ,CAACkJ,CAAD,CAAhB;AACA,aAAKoG,KAAL,CAAW9P,IAAX,CAAgB;AAACyQ,UAAAA,QAAQ,EAAEzP,CAAC,CAAC0P,KAAF,CAAQ,CAAR,EAAWF,SAAX,CAAX;AAAkCG,UAAAA,OAAO,EAAE3P,CAAC,CAAC0P,KAAF,CAAQF,SAAR,EAAmB9G,CAAnB;AAA3C,SAAhB;AACD;AACF,KAXkB;AAanB;AACAkH,IAAAA,eAAe,EAAE,YAAW;AAC1B,UAAIC,WAAW,GAAG,KAAK7L,IAAL,CAAU,CAAV,EAAa9E,CAAb,CAAeJ,MAAjC;AACA,UAAImM,WAAW,GAAG,KAAKgE,aAAL,CAAmBnQ,MAArC,CAF0B,CAI1B;;AACA,UAAIgR,UAAU,GAAG,EAAjB;AACAA,MAAAA,UAAU,CAAC9Q,IAAX,CAAgB;AAAC6L,QAAAA,IAAI,EAAC,OAAN;AAAe/F,QAAAA,MAAM,EAAC,CAAtB;AAAyBC,QAAAA,MAAM,EAAC,CAAhC;AAAmCV,QAAAA,SAAS,EAAEwL;AAA9C,OAAhB;AACA,UAAIE,EAAE,GAAGlQ,cAAc,CAAC,CAAC,CAAD,EAAG,CAAH,EAAK,CAAL,EAAO,CAAP,CAAD,EAAY,CAAC,GAAD,EAAM,GAAN,EAAW,GAAX,EAAgB,GAAhB,CAAZ,CAAvB,CAP0B,CAOgC;;AAC1D,WAAI,IAAID,CAAC,GAAC,CAAV,EAAYA,CAAC,GAACmQ,EAAd,EAAiBnQ,CAAC,EAAlB,EAAsB;AACpB,YAAIoQ,EAAE,GAAGjS,KAAK,CAAC,KAAK6Q,WAAN,EAAmB,KAAKC,WAAxB,CAAd;AACA,YAAIxD,GAAG,GAAG,CAAC,MAAD,EAAQ,QAAR,EAAiB,MAAjB,EAAyBtN,KAAK,CAAC,CAAD,EAAG,CAAH,CAA9B,CAAV;;AACA,YAAGH,KAAK,CAAC,CAAD,EAAG,CAAH,CAAL,GAAW,GAAd,EAAmB;AACjB,cAAIqS,EAAE,GAAG5S,IAAI,CAACC,MAAL,EAAT;AACAwS,UAAAA,UAAU,CAAC9Q,IAAX,CAAgB;AAAC6L,YAAAA,IAAI,EAAC,IAAN;AAAYjE,YAAAA,WAAW,EAAEoJ,EAAzB;AAA6B9E,YAAAA,UAAU,EAAEG,GAAzC;AAA8C/B,YAAAA,SAAS,EAAE2G;AAAzD,WAAhB;AACD,SAHD,MAGO;AACLH,UAAAA,UAAU,CAAC9Q,IAAX,CAAgB;AAAC6L,YAAAA,IAAI,EAAC,IAAN;AAAYjE,YAAAA,WAAW,EAAEoJ,EAAzB;AAA6B9E,YAAAA,UAAU,EAAEG;AAAzC,WAAhB;AACD;AACF;;AACDyE,MAAAA,UAAU,CAAC9Q,IAAX,CAAgB;AAAC6L,QAAAA,IAAI,EAAC,SAAN;AAAiBI,QAAAA,WAAW,EAAEA;AAA9B,OAAhB;AACA,UAAIY,GAAG,GAAG,IAAIrB,GAAJ,EAAV;AACAqB,MAAAA,GAAG,CAAClB,UAAJ,CAAemF,UAAf,EApB0B,CAsB1B;;AACA,UAAII,EAAE,GAAGnS,KAAK,CAAC,KAAKqQ,cAAN,EAAsB,KAAKC,cAA3B,CAAd,CAvB0B,CAuBgC;;AAC1D,UAAI8B,EAAE,GAAG9S,IAAI,CAAC6M,GAAL,CAAS,EAAT,EAAatM,KAAK,CAAC,KAAK0Q,YAAN,EAAoB,KAAKC,YAAzB,CAAlB,CAAT,CAxB0B,CAwB0C;;AACpE,UAAI6B,EAAE,GAAG/S,IAAI,CAAC6M,GAAL,CAAS,EAAT,EAAatM,KAAK,CAAC,KAAK4Q,iBAAN,EAAyB,KAAKC,iBAA9B,CAAlB,CAAT,CAzB0B,CAyBoD;;AAC9E,UAAI4B,GAAG,GAAGzS,KAAK,CAAC,KAAK8Q,YAAN,EAAoB,KAAKC,YAAzB,CAAf,CA1B0B,CA0B6B;;AACvD,UAAI2B,EAAE,GAAG1S,KAAK,CAAC,CAAD,EAAG,CAAH,CAAd,CA3B0B,CA2BL;;AACrB,UAAI2S,WAAJ;;AACA,UAAGD,EAAE,GAAC,IAAN,EAAY;AACVC,QAAAA,WAAW,GAAG;AAACrE,UAAAA,MAAM,EAAC,UAAR;AAAoBD,UAAAA,UAAU,EAACiE,EAA/B;AAAmClE,UAAAA,QAAQ,EAACmE;AAA5C,SAAd;AACD,OAFD,MAEO,IAAGG,EAAE,GAAC,IAAN,EAAY;AACjBC,QAAAA,WAAW,GAAG;AAACrE,UAAAA,MAAM,EAAC,SAAR;AAAmBJ,UAAAA,aAAa,EAAEsE,EAAlC;AAAsCnE,UAAAA,UAAU,EAACiE,EAAjD;AAAqDlE,UAAAA,QAAQ,EAACmE;AAA9D,SAAd;AACD,OAFM,MAEA;AACLI,QAAAA,WAAW,GAAG;AAACrE,UAAAA,MAAM,EAAC,KAAR;AAAeJ,UAAAA,aAAa,EAAEsE,EAA9B;AAAkCjE,UAAAA,QAAQ,EAAEkE,GAA5C;AAAiDpE,UAAAA,UAAU,EAACiE,EAA5D;AAAgElE,UAAAA,QAAQ,EAACmE;AAAzE,SAAd;AACD;;AAED,UAAIK,OAAO,GAAG,IAAI5E,OAAJ,CAAYC,GAAZ,EAAiB0E,WAAjB,CAAd;AAEA,UAAIE,IAAI,GAAG,EAAX;AACAA,MAAAA,IAAI,CAACC,GAAL,GAAW,EAAX;AACAD,MAAAA,IAAI,CAACE,IAAL,GAAY,CAAZ,CAzC0B,CAyCX;;AACfF,MAAAA,IAAI,CAACX,UAAL,GAAkBA,UAAlB;AACAW,MAAAA,IAAI,CAACF,WAAL,GAAmBA,WAAnB;AACAE,MAAAA,IAAI,CAAC5E,GAAL,GAAWA,GAAX;AACA4E,MAAAA,IAAI,CAACD,OAAL,GAAeA,OAAf;AACA,aAAOC,IAAP;AACD,KA7DkB;AA+DnB;AACAlB,IAAAA,gBAAgB,EAAE,YAAW;AAC3B,WAAKR,UAAL,GAAkB,EAAlB,CAD2B,CACL;;AACtB,WAAI,IAAIrQ,CAAC,GAAC,CAAV,EAAYA,CAAC,GAAC,KAAKuP,cAAnB,EAAkCvP,CAAC,EAAnC,EAAuC;AACrC,YAAI+R,IAAI,GAAG,KAAKb,eAAL,EAAX;AACA,aAAKb,UAAL,CAAgB/P,IAAhB,CAAqByR,IAArB;AACD;AACF,KAtEkB;AAwEnBG,IAAAA,IAAI,EAAE,YAAW;AAEf;AACA,WAAK1B,IAAL,GAHe,CAKf;;AACA,UAAI2B,IAAI,GAAG,KAAK/B,KAAL,CAAW,KAAKK,MAAhB,CAAX,CANe,CAMqB;;AACpC,UAAI2B,MAAM,GAAGD,IAAI,CAACpB,QAAL,CAAc1R,KAAK,CAAC,CAAD,EAAI8S,IAAI,CAACpB,QAAL,CAAc3Q,MAAlB,CAAnB,CAAb;;AACA,WAAI,IAAIoB,CAAC,GAAC,CAAV,EAAYA,CAAC,GAAC,KAAK6O,UAAL,CAAgBjQ,MAA9B,EAAqCoB,CAAC,EAAtC,EAA0C;AACxC,YAAIsB,CAAC,GAAG,KAAKwC,IAAL,CAAU8M,MAAV,CAAR;AACA,YAAIC,CAAC,GAAG,KAAKjD,MAAL,CAAYgD,MAAZ,CAAR;AACA,aAAK/B,UAAL,CAAgB7O,CAAhB,EAAmBsQ,OAAnB,CAA2BhE,KAA3B,CAAiChL,CAAjC,EAAoCuP,CAApC;AACD,OAZc,CAcf;;;AACA,UAAIC,QAAQ,GAAG,KAAK9C,UAAL,GAAkB2C,IAAI,CAACpB,QAAL,CAAc3Q,MAA/C;;AACA,UAAG,KAAKoQ,IAAL,IAAa8B,QAAhB,EAA0B;AACxB;AACA;AACA,YAAIC,OAAO,GAAG,KAAKC,aAAL,EAAd;;AACA,aAAI,IAAIhR,CAAC,GAAC,CAAV,EAAYA,CAAC,GAAC,KAAK6O,UAAL,CAAgBjQ,MAA9B,EAAqCoB,CAAC,EAAtC,EAA0C;AACxC,cAAIzC,CAAC,GAAG,KAAKsR,UAAL,CAAgB7O,CAAhB,CAAR;AACAzC,UAAAA,CAAC,CAACiT,GAAF,CAAM1R,IAAN,CAAWiS,OAAO,CAAC/Q,CAAD,CAAlB;AACAzC,UAAAA,CAAC,CAACkT,IAAF,IAAUM,OAAO,CAAC/Q,CAAD,CAAjB;AACD;;AACD,aAAKgP,IAAL,GAAY,CAAZ,CATwB,CAST;;AACf,aAAKC,MAAL,GAVwB,CAUT;;AAEf,YAAG,KAAKC,oBAAL,KAA8B,IAAjC,EAAuC;AACrC,eAAKA,oBAAL;AACD;;AAED,YAAG,KAAKD,MAAL,IAAe,KAAKL,KAAL,CAAWhQ,MAA7B,EAAqC;AACnC;AACA;AACA,eAAI,IAAIoB,CAAC,GAAC,CAAV,EAAYA,CAAC,GAAC,KAAK6O,UAAL,CAAgBjQ,MAA9B,EAAqCoB,CAAC,EAAtC,EAA0C;AACxC,iBAAK8O,oBAAL,CAA0BhQ,IAA1B,CAA+B,KAAK+P,UAAL,CAAgB7O,CAAhB,CAA/B;AACD,WALkC,CAMnC;;;AACA,eAAK8O,oBAAL,CAA0BmC,IAA1B,CAA+B,UAAStT,CAAT,EAAYC,CAAZ,EAAe;AAC5C,mBAAQD,CAAC,CAAC8S,IAAF,GAAS9S,CAAC,CAAC6S,GAAF,CAAM5R,MAAhB,GACChB,CAAC,CAAC6S,IAAF,GAAS7S,CAAC,CAAC4S,GAAF,CAAM5R,MADhB,GAEA,CAAC,CAFD,GAEK,CAFZ;AAGD,WAJD,EAPmC,CAYnC;AACA;AACA;;AACA,cAAG,KAAKkQ,oBAAL,CAA0BlQ,MAA1B,GAAmC,IAAI,KAAKqP,aAA/C,EAA8D;AAC5D,iBAAKa,oBAAL,GAA4B,KAAKA,oBAAL,CAA0BU,KAA1B,CAAgC,CAAhC,EAAmC,IAAI,KAAKvB,aAA5C,CAA5B;AACD;;AACD,cAAG,KAAKkB,qBAAL,KAA+B,IAAlC,EAAwC;AACtC,iBAAKA,qBAAL;AACD;;AACD,eAAKE,gBAAL,GArBmC,CAqBV;;AACzB,eAAKJ,MAAL,GAAc,CAAd,CAtBmC,CAsBlB;AAClB,SAvBD,MAuBO;AACL;AACA,eAAI,IAAIjP,CAAC,GAAC,CAAV,EAAYA,CAAC,GAAC,KAAK6O,UAAL,CAAgBjQ,MAA9B,EAAqCoB,CAAC,EAAtC,EAA0C;AACxC,gBAAIzC,CAAC,GAAG,KAAKsR,UAAL,CAAgB7O,CAAhB,CAAR;AACA,gBAAI2L,GAAG,GAAG,IAAIrB,GAAJ,EAAV;AACAqB,YAAAA,GAAG,CAAClB,UAAJ,CAAelN,CAAC,CAACqS,UAAjB;AACA,gBAAIU,OAAO,GAAG,IAAI5E,OAAJ,CAAYC,GAAZ,EAAiBpO,CAAC,CAAC8S,WAAnB,CAAd;AACA9S,YAAAA,CAAC,CAACoO,GAAF,GAAQA,GAAR;AACApO,YAAAA,CAAC,CAAC+S,OAAF,GAAYA,OAAZ;AACD;AACF;AACF;AACF,KA3IkB;AA6InBU,IAAAA,aAAa,EAAE,YAAW;AACxB;AACA;AACA,UAAIE,IAAI,GAAG,EAAX;AACA,UAAIP,IAAI,GAAG,KAAK/B,KAAL,CAAW,KAAKK,MAAhB,CAAX,CAJwB,CAIY;;AACpC,WAAI,IAAIjP,CAAC,GAAC,CAAV,EAAYA,CAAC,GAAC,KAAK6O,UAAL,CAAgBjQ,MAA9B,EAAqCoB,CAAC,EAAtC,EAA0C;AACxC,YAAI2L,GAAG,GAAG,KAAKkD,UAAL,CAAgB7O,CAAhB,EAAmB2L,GAA7B;AACA,YAAItO,CAAC,GAAG,GAAR;;AACA,aAAI,IAAIqC,CAAC,GAAC,CAAV,EAAYA,CAAC,GAACiR,IAAI,CAAClB,OAAL,CAAa7Q,MAA3B,EAAkCc,CAAC,EAAnC,EAAuC;AACrC,cAAI4B,CAAC,GAAG,KAAKwC,IAAL,CAAU6M,IAAI,CAAClB,OAAL,CAAa/P,CAAb,CAAV,CAAR;AACA,cAAImR,CAAC,GAAG,KAAKjD,MAAL,CAAY+C,IAAI,CAAClB,OAAL,CAAa/P,CAAb,CAAZ,CAAR;AACAiM,UAAAA,GAAG,CAACzG,OAAJ,CAAY5D,CAAZ;AACA,cAAI6P,IAAI,GAAGxF,GAAG,CAACL,aAAJ,EAAX;AACAjO,UAAAA,CAAC,IAAK8T,IAAI,KAAKN,CAAT,GAAa,GAAb,GAAmB,GAAzB,CALqC,CAKN;AAChC;;AACDxT,QAAAA,CAAC,IAAIsT,IAAI,CAAClB,OAAL,CAAa7Q,MAAlB,CAVwC,CAUd;;AAC1BsS,QAAAA,IAAI,CAACpS,IAAL,CAAUzB,CAAV;AACD;;AACD,aAAO6T,IAAP;AACD,KAhKkB;AAkKnB;AACA;AACA;AACAE,IAAAA,YAAY,EAAE,UAAStN,IAAT,EAAe;AAC3B;AACA;AAEA,UAAIuN,eAAe,GAAG,EAAtB;AACA,UAAIC,EAAE,GAAG,CAAT;;AACA,UAAG,KAAKxC,oBAAL,CAA0BlQ,MAA1B,KAAqC,CAAxC,EAA2C;AACzC;AACA;AACA0S,QAAAA,EAAE,GAAG,KAAKzC,UAAL,CAAgBjQ,MAArB;AACAyS,QAAAA,eAAe,GAAG,KAAKxC,UAAvB;AACD,OALD,MAKO;AACL;AACAyC,QAAAA,EAAE,GAAGnU,IAAI,CAAC2M,GAAL,CAAS,KAAKmE,aAAd,EAA6B,KAAKa,oBAAL,CAA0BlQ,MAAvD,CAAL;AACAyS,QAAAA,eAAe,GAAG,KAAKvC,oBAAvB;AACD,OAf0B,CAiB3B;;;AACA,UAAIyC,IAAJ,EAAUpT,CAAV;;AACA,WAAI,IAAIoB,CAAC,GAAC,CAAV,EAAYA,CAAC,GAAC+R,EAAd,EAAiB/R,CAAC,EAAlB,EAAsB;AACpB,YAAIoM,GAAG,GAAG0F,eAAe,CAAC9R,CAAD,CAAf,CAAmBoM,GAA7B;AACA,YAAIrK,CAAC,GAAGqK,GAAG,CAACzG,OAAJ,CAAYpB,IAAZ,CAAR;;AACA,YAAGvE,CAAC,KAAG,CAAP,EAAU;AACRgS,UAAAA,IAAI,GAAGjQ,CAAP;AACAnD,UAAAA,CAAC,GAAGmD,CAAC,CAACtC,CAAF,CAAIJ,MAAR;AACD,SAHD,MAGO;AACL;AACA,eAAI,IAAI4C,CAAC,GAAC,CAAV,EAAYA,CAAC,GAACrD,CAAd,EAAgBqD,CAAC,EAAjB,EAAqB;AACnB+P,YAAAA,IAAI,CAACvS,CAAL,CAAOwC,CAAP,KAAaF,CAAC,CAACtC,CAAF,CAAIwC,CAAJ,CAAb;AACD;AACF;AACF,OA/B0B,CAgC3B;;;AACA,WAAI,IAAIA,CAAC,GAAC,CAAV,EAAYA,CAAC,GAACrD,CAAd,EAAgBqD,CAAC,EAAjB,EAAqB;AACnB+P,QAAAA,IAAI,CAACvS,CAAL,CAAOwC,CAAP,KAAa8P,EAAb;AACD;;AACD,aAAOC,IAAP;AACD,KA1MkB;AA4MnBC,IAAAA,OAAO,EAAE,UAAS1N,IAAT,EAAe;AACtB,UAAIyN,IAAI,GAAG,KAAKH,YAAL,CAAkBtN,IAAlB,CAAX;;AACA,UAAGyN,IAAI,CAACvS,CAAL,CAAOJ,MAAP,KAAkB,CAArB,EAAwB;AACtB,YAAI6S,KAAK,GAAG1S,MAAM,CAACwS,IAAI,CAACvS,CAAN,CAAlB;AACA,YAAI0S,eAAe,GAAGD,KAAK,CAACtS,IAA5B;AACD,OAHD,MAGO;AACL,YAAIuS,eAAe,GAAG,CAAC,CAAvB,CADK,CACqB;AAC3B;;AACD,aAAOA,eAAP;AAED,KAtNkB;AAwNnBrP,IAAAA,MAAM,EAAE,YAAW;AACjB;AACA,UAAIiP,EAAE,GAAGnU,IAAI,CAAC2M,GAAL,CAAS,KAAKmE,aAAd,EAA6B,KAAKa,oBAAL,CAA0BlQ,MAAvD,CAAT;AACA,UAAI0D,IAAI,GAAG,EAAX;AACAA,MAAAA,IAAI,CAACqP,IAAL,GAAY,EAAZ;;AACA,WAAI,IAAInT,CAAC,GAAC,CAAV,EAAYA,CAAC,GAAC8S,EAAd,EAAiB9S,CAAC,EAAlB,EAAsB;AACpB8D,QAAAA,IAAI,CAACqP,IAAL,CAAU7S,IAAV,CAAe,KAAKgQ,oBAAL,CAA0BtQ,CAA1B,EAA6BmN,GAA7B,CAAiCtJ,MAAjC,EAAf;AACD;;AACD,aAAOC,IAAP;AACD,KAjOkB;AAmOnBC,IAAAA,QAAQ,EAAE,UAASD,IAAT,EAAe;AACvB,WAAK2L,aAAL,GAAqB3L,IAAI,CAACqP,IAAL,CAAU/S,MAA/B;AACA,WAAKkQ,oBAAL,GAA4B,EAA5B;;AACA,WAAI,IAAItQ,CAAC,GAAC,CAAV,EAAYA,CAAC,GAAC,KAAKyP,aAAnB,EAAiCzP,CAAC,EAAlC,EAAsC;AACpC,YAAImN,GAAG,GAAG,IAAIrB,GAAJ,EAAV;AACAqB,QAAAA,GAAG,CAACpJ,QAAJ,CAAaD,IAAI,CAACqP,IAAL,CAAUnT,CAAV,CAAb;AACA,YAAIoT,eAAe,GAAG,EAAtB;AACAA,QAAAA,eAAe,CAACjG,GAAhB,GAAsBA,GAAtB;AACA,aAAKmD,oBAAL,CAA0BhQ,IAA1B,CAA+B8S,eAA/B;AACD;AACF,KA7OkB;AA+OnB;AACA;AACAC,IAAAA,YAAY,EAAE,UAASvR,CAAT,EAAY;AAAE,WAAK4O,oBAAL,GAA4B5O,CAA5B;AAAgC,KAjPzC;AAkPnB;AACAwR,IAAAA,aAAa,EAAE,UAASxR,CAAT,EAAY;AAAE,WAAK6O,qBAAL,GAA6B7O,CAA7B;AAAiC;AAnP3C,GAArB;AAuPAxD,EAAAA,MAAM,CAAC6Q,QAAP,GAAkBA,QAAlB;AACD,CAhUD,EAgUG/Q,SAhUH;;AAiUA,CAAC,UAASmV,GAAT,EAAc;AACb;;AACA,MAAI,OAAOC,MAAP,KAAkB,WAAlB,IAAiC,OAAOA,MAAM,CAACC,OAAd,KAA0B,WAA/D,EAA4E;AAC1EC,IAAAA,MAAM,CAACC,MAAP,GAAgBJ,GAAhB,CAD0E,CACrD;AACtB,GAFD,MAEO;AACLC,IAAAA,MAAM,CAACC,OAAP,GAAiBF,GAAjB,CADK,CACiB;AACvB;AACF,CAPD,EAOGnV,SAPH","file":"convnet.map","sourceRoot":"..","sourcesContent":["var convnetjs = convnetjs || { REVISION: 'ALPHA' };\n(function(global) {\n  \"use strict\";\n\n  // Random number utilities\n  var return_v = false;\n  var v_val = 0.0;\n  var gaussRandom = function() {\n    if(return_v) { \n      return_v = false;\n      return v_val; \n    }\n    var u = 2*Math.random()-1;\n    var v = 2*Math.random()-1;\n    var r = u*u + v*v;\n    if(r == 0 || r > 1) return gaussRandom();\n    var c = Math.sqrt(-2*Math.log(r)/r);\n    v_val = v*c; // cache this\n    return_v = true;\n    return u*c;\n  }\n  var randf = function(a, b) { return Math.random()*(b-a)+a; }\n  var randi = function(a, b) { return Math.floor(Math.random()*(b-a)+a); }\n  var randn = function(mu, std){ return mu+gaussRandom()*std; }\n\n  // Array utilities\n  var zeros = function(n) {\n    if(typeof(n)==='undefined' || isNaN(n)) { return []; }\n    if(typeof ArrayBuffer === 'undefined') {\n      // lacking browser support\n      var arr = new Array(n);\n      for(var i=0;i<n;i++) { arr[i]= 0; }\n      return arr;\n    } else {\n      return new Float64Array(n);\n    }\n  }\n\n  var arrContains = function(arr, elt) {\n    for(var i=0,n=arr.length;i<n;i++) {\n      if(arr[i]===elt) return true;\n    }\n    return false;\n  }\n\n  var arrUnique = function(arr) {\n    var b = [];\n    for(var i=0,n=arr.length;i<n;i++) {\n      if(!arrContains(b, arr[i])) {\n        b.push(arr[i]);\n      }\n    }\n    return b;\n  }\n\n  // return max and min of a given non-empty array.\n  var maxmin = function(w) {\n    if(w.length === 0) { return {}; } // ... ;s\n    var maxv = w[0];\n    var minv = w[0];\n    var maxi = 0;\n    var mini = 0;\n    var n = w.length;\n    for(var i=1;i<n;i++) {\n      if(w[i] > maxv) { maxv = w[i]; maxi = i; } \n      if(w[i] < minv) { minv = w[i]; mini = i; } \n    }\n    return {maxi: maxi, maxv: maxv, mini: mini, minv: minv, dv:maxv-minv};\n  }\n\n  // create random permutation of numbers, in range [0...n-1]\n  var randperm = function(n) {\n    var i = n,\n        j = 0,\n        temp;\n    var array = [];\n    for(var q=0;q<n;q++)array[q]=q;\n    while (i--) {\n        j = Math.floor(Math.random() * (i+1));\n        temp = array[i];\n        array[i] = array[j];\n        array[j] = temp;\n    }\n    return array;\n  }\n\n  // sample from list lst according to probabilities in list probs\n  // the two lists are of same size, and probs adds up to 1\n  var weightedSample = function(lst, probs) {\n    var p = randf(0, 1.0);\n    var cumprob = 0.0;\n    for(var k=0,n=lst.length;k<n;k++) {\n      cumprob += probs[k];\n      if(p < cumprob) { return lst[k]; }\n    }\n  }\n\n  // syntactic sugar function for getting default parameter values\n  var getopt = function(opt, field_name, default_value) {\n    if(typeof field_name === 'string') {\n      // case of single string\n      return (typeof opt[field_name] !== 'undefined') ? opt[field_name] : default_value;\n    } else {\n      // assume we are given a list of string instead\n      var ret = default_value;\n      for(var i=0;i<field_name.length;i++) {\n        var f = field_name[i];\n        if (typeof opt[f] !== 'undefined') {\n          ret = opt[f]; // overwrite return value\n        }\n      }\n      return ret;\n    }\n  }\n\n  function assert(condition, message) {\n    if (!condition) {\n      message = message || \"Assertion failed\";\n      if (typeof Error !== \"undefined\") {\n        throw new Error(message);\n      }\n      throw message; // Fallback\n    }\n  }\n\n  global.randf = randf;\n  global.randi = randi;\n  global.randn = randn;\n  global.zeros = zeros;\n  global.maxmin = maxmin;\n  global.randperm = randperm;\n  global.weightedSample = weightedSample;\n  global.arrUnique = arrUnique;\n  global.arrContains = arrContains;\n  global.getopt = getopt;\n  global.assert = assert;\n  \n})(convnetjs);\n(function(global) {\n  \"use strict\";\n\n  // Vol is the basic building block of all data in a net.\n  // it is essentially just a 3D volume of numbers, with a\n  // width (sx), height (sy), and depth (depth).\n  // it is used to hold data for all filters, all volumes,\n  // all weights, and also stores all gradients w.r.t. \n  // the data. c is optionally a value to initialize the volume\n  // with. If c is missing, fills the Vol with random numbers.\n  var Vol = function(sx, sy, depth, c) {\n    // this is how you check if a variable is an array. Oh, Javascript :)\n    if(Object.prototype.toString.call(sx) === '[object Array]') {\n      // we were given a list in sx, assume 1D volume and fill it up\n      this.sx = 1;\n      this.sy = 1;\n      this.depth = sx.length;\n      // we have to do the following copy because we want to use\n      // fast typed arrays, not an ordinary javascript array\n      this.w = global.zeros(this.depth);\n      this.dw = global.zeros(this.depth);\n      for(var i=0;i<this.depth;i++) {\n        this.w[i] = sx[i];\n      }\n    } else {\n      // we were given dimensions of the vol\n      this.sx = sx;\n      this.sy = sy;\n      this.depth = depth;\n      var n = sx*sy*depth;\n      this.w = global.zeros(n);\n      this.dw = global.zeros(n);\n      if(typeof c === 'undefined') {\n        // weight normalization is done to equalize the output\n        // variance of every neuron, otherwise neurons with a lot\n        // of incoming connections have outputs of larger variance\n        var scale = Math.sqrt(1.0/(sx*sy*depth));\n        for(var i=0;i<n;i++) { \n          this.w[i] = global.randn(0.0, scale);\n        }\n      } else {\n        for(var i=0;i<n;i++) { \n          this.w[i] = c;\n        }\n      }\n    }\n  }\n\n  Vol.prototype = {\n    get: function(x, y, d) { \n      var ix=((this.sx * y)+x)*this.depth+d;\n      return this.w[ix];\n    },\n    set: function(x, y, d, v) { \n      var ix=((this.sx * y)+x)*this.depth+d;\n      this.w[ix] = v; \n    },\n    add: function(x, y, d, v) { \n      var ix=((this.sx * y)+x)*this.depth+d;\n      this.w[ix] += v; \n    },\n    get_grad: function(x, y, d) { \n      var ix = ((this.sx * y)+x)*this.depth+d;\n      return this.dw[ix]; \n    },\n    set_grad: function(x, y, d, v) { \n      var ix = ((this.sx * y)+x)*this.depth+d;\n      this.dw[ix] = v; \n    },\n    add_grad: function(x, y, d, v) { \n      var ix = ((this.sx * y)+x)*this.depth+d;\n      this.dw[ix] += v; \n    },\n    cloneAndZero: function() { return new Vol(this.sx, this.sy, this.depth, 0.0)},\n    clone: function() {\n      var V = new Vol(this.sx, this.sy, this.depth, 0.0);\n      var n = this.w.length;\n      for(var i=0;i<n;i++) { V.w[i] = this.w[i]; }\n      return V;\n    },\n    addFrom: function(V) { for(var k=0;k<this.w.length;k++) { this.w[k] += V.w[k]; }},\n    addFromScaled: function(V, a) { for(var k=0;k<this.w.length;k++) { this.w[k] += a*V.w[k]; }},\n    setConst: function(a) { for(var k=0;k<this.w.length;k++) { this.w[k] = a; }},\n\n    toJSON: function() {\n      // todo: we may want to only save d most significant digits to save space\n      var json = {}\n      json.sx = this.sx; \n      json.sy = this.sy;\n      json.depth = this.depth;\n      json.w = this.w;\n      return json;\n      // we wont back up gradients to save space\n    },\n    fromJSON: function(json) {\n      this.sx = json.sx;\n      this.sy = json.sy;\n      this.depth = json.depth;\n\n      var n = this.sx*this.sy*this.depth;\n      this.w = global.zeros(n);\n      this.dw = global.zeros(n);\n      // copy over the elements.\n      for(var i=0;i<n;i++) {\n        this.w[i] = json.w[i];\n      }\n    }\n  }\n\n  global.Vol = Vol;\n})(convnetjs);\n(function(global) {\n  \"use strict\";\n  var Vol = global.Vol; // convenience\n\n  // Volume utilities\n  // intended for use with data augmentation\n  // crop is the size of output\n  // dx,dy are offset wrt incoming volume, of the shift\n  // fliplr is boolean on whether we also want to flip left<->right\n  var augment = function(V, crop, dx, dy, fliplr) {\n    // note assumes square outputs of size crop x crop\n    if(typeof(fliplr)==='undefined') var fliplr = false;\n    if(typeof(dx)==='undefined') var dx = global.randi(0, V.sx - crop);\n    if(typeof(dy)==='undefined') var dy = global.randi(0, V.sy - crop);\n    \n    // randomly sample a crop in the input volume\n    var W;\n    if(crop !== V.sx || dx!==0 || dy!==0) {\n      W = new Vol(crop, crop, V.depth, 0.0);\n      for(var x=0;x<crop;x++) {\n        for(var y=0;y<crop;y++) {\n          if(x+dx<0 || x+dx>=V.sx || y+dy<0 || y+dy>=V.sy) continue; // oob\n          for(var d=0;d<V.depth;d++) {\n           W.set(x,y,d,V.get(x+dx,y+dy,d)); // copy data over\n          }\n        }\n      }\n    } else {\n      W = V;\n    }\n\n    if(fliplr) {\n      // flip volume horziontally\n      var W2 = W.cloneAndZero();\n      for(var x=0;x<W.sx;x++) {\n        for(var y=0;y<W.sy;y++) {\n          for(var d=0;d<W.depth;d++) {\n           W2.set(x,y,d,W.get(W.sx - x - 1,y,d)); // copy data over\n          }\n        }\n      }\n      W = W2; //swap\n    }\n    return W;\n  }\n\n  // img is a DOM element that contains a loaded image\n  // returns a Vol of size (W, H, 4). 4 is for RGBA\n  var img_to_vol = function(img, convert_grayscale) {\n\n    if(typeof(convert_grayscale)==='undefined') var convert_grayscale = false;\n\n    var canvas = document.createElement('canvas');\n    canvas.width = img.width;\n    canvas.height = img.height;\n    var ctx = canvas.getContext(\"2d\");\n\n    // due to a Firefox bug\n    try {\n      ctx.drawImage(img, 0, 0);\n    } catch (e) {\n      if (e.name === \"NS_ERROR_NOT_AVAILABLE\") {\n        // sometimes happens, lets just abort\n        return false;\n      } else {\n        throw e;\n      }\n    }\n\n    try {\n      var img_data = ctx.getImageData(0, 0, canvas.width, canvas.height);\n    } catch (e) {\n      if(e.name === 'IndexSizeError') {\n        return false; // not sure what causes this sometimes but okay abort\n      } else {\n        throw e;\n      }\n    }\n\n    // prepare the input: get pixels and normalize them\n    var p = img_data.data;\n    var W = img.width;\n    var H = img.height;\n    var pv = []\n    for(var i=0;i<p.length;i++) {\n      pv.push(p[i]/255.0-0.5); // normalize image pixels to [-0.5, 0.5]\n    }\n    var x = new Vol(W, H, 4, 0.0); //input volume (image)\n    x.w = pv;\n\n    if(convert_grayscale) {\n      // flatten into depth=1 array\n      var x1 = new Vol(W, H, 1, 0.0);\n      for(var i=0;i<W;i++) {\n        for(var j=0;j<H;j++) {\n          x1.set(i,j,0,x.get(i,j,0));\n        }\n      }\n      x = x1;\n    }\n\n    return x;\n  }\n  \n  global.augment = augment;\n  global.img_to_vol = img_to_vol;\n\n})(convnetjs);\n(function(global) {\n  \"use strict\";\n  var Vol = global.Vol; // convenience\n\n  // This file contains all layers that do dot products with input,\n  // but usually in a different connectivity pattern and weight sharing\n  // schemes: \n  // - FullyConn is fully connected dot products \n  // - ConvLayer does convolutions (so weight sharing spatially)\n  // putting them together in one file because they are very similar\n  var ConvLayer = function(opt) {\n    var opt = opt || {};\n\n    // required\n    this.out_depth = opt.filters;\n    this.sx = opt.sx; // filter size. Should be odd if possible, it's cleaner.\n    this.in_depth = opt.in_depth;\n    this.in_sx = opt.in_sx;\n    this.in_sy = opt.in_sy;\n    \n    // optional\n    this.sy = typeof opt.sy !== 'undefined' ? opt.sy : this.sx;\n    this.stride = typeof opt.stride !== 'undefined' ? opt.stride : 1; // stride at which we apply filters to input volume\n    this.pad = typeof opt.pad !== 'undefined' ? opt.pad : 0; // amount of 0 padding to add around borders of input volume\n    this.l1_decay_mul = typeof opt.l1_decay_mul !== 'undefined' ? opt.l1_decay_mul : 0.0;\n    this.l2_decay_mul = typeof opt.l2_decay_mul !== 'undefined' ? opt.l2_decay_mul : 1.0;\n\n    // computed\n    // note we are doing floor, so if the strided convolution of the filter doesnt fit into the input\n    // volume exactly, the output volume will be trimmed and not contain the (incomplete) computed\n    // final application.\n    this.out_sx = Math.floor((this.in_sx + this.pad * 2 - this.sx) / this.stride + 1);\n    this.out_sy = Math.floor((this.in_sy + this.pad * 2 - this.sy) / this.stride + 1);\n    this.layer_type = 'conv';\n\n    // initializations\n    var bias = typeof opt.bias_pref !== 'undefined' ? opt.bias_pref : 0.0;\n    this.filters = [];\n    for(var i=0;i<this.out_depth;i++) { this.filters.push(new Vol(this.sx, this.sy, this.in_depth)); }\n    this.biases = new Vol(1, 1, this.out_depth, bias);\n  }\n  ConvLayer.prototype = {\n    forward: function(V, is_training) {\n      // optimized code by @mdda that achieves 2x speedup over previous version\n\n      this.in_act = V;\n      var A = new Vol(this.out_sx |0, this.out_sy |0, this.out_depth |0, 0.0);\n      \n      var V_sx = V.sx |0;\n      var V_sy = V.sy |0;\n      var xy_stride = this.stride |0;\n\n      for(var d=0;d<this.out_depth;d++) {\n        var f = this.filters[d];\n        var x = -this.pad |0;\n        var y = -this.pad |0;\n        for(var ay=0; ay<this.out_sy; y+=xy_stride,ay++) {  // xy_stride\n          x = -this.pad |0;\n          for(var ax=0; ax<this.out_sx; x+=xy_stride,ax++) {  // xy_stride\n\n            // convolve centered at this particular location\n            var a = 0.0;\n            for(var fy=0;fy<f.sy;fy++) {\n              var oy = y+fy; // coordinates in the original input array coordinates\n              for(var fx=0;fx<f.sx;fx++) {\n                var ox = x+fx;\n                if(oy>=0 && oy<V_sy && ox>=0 && ox<V_sx) {\n                  for(var fd=0;fd<f.depth;fd++) {\n                    // avoid function call overhead (x2) for efficiency, compromise modularity :(\n                    a += f.w[((f.sx * fy)+fx)*f.depth+fd] * V.w[((V_sx * oy)+ox)*V.depth+fd];\n                  }\n                }\n              }\n            }\n            a += this.biases.w[d];\n            A.set(ax, ay, d, a);\n          }\n        }\n      }\n      this.out_act = A;\n      return this.out_act;\n    },\n    backward: function() {\n\n      var V = this.in_act;\n      V.dw = global.zeros(V.w.length); // zero out gradient wrt bottom data, we're about to fill it\n\n      var V_sx = V.sx |0;\n      var V_sy = V.sy |0;\n      var xy_stride = this.stride |0;\n\n      for(var d=0;d<this.out_depth;d++) {\n        var f = this.filters[d];\n        var x = -this.pad |0;\n        var y = -this.pad |0;\n        for(var ay=0; ay<this.out_sy; y+=xy_stride,ay++) {  // xy_stride\n          x = -this.pad |0;\n          for(var ax=0; ax<this.out_sx; x+=xy_stride,ax++) {  // xy_stride\n\n            // convolve centered at this particular location\n            var chain_grad = this.out_act.get_grad(ax,ay,d); // gradient from above, from chain rule\n            for(var fy=0;fy<f.sy;fy++) {\n              var oy = y+fy; // coordinates in the original input array coordinates\n              for(var fx=0;fx<f.sx;fx++) {\n                var ox = x+fx;\n                if(oy>=0 && oy<V_sy && ox>=0 && ox<V_sx) {\n                  for(var fd=0;fd<f.depth;fd++) {\n                    // avoid function call overhead (x2) for efficiency, compromise modularity :(\n                    var ix1 = ((V_sx * oy)+ox)*V.depth+fd;\n                    var ix2 = ((f.sx * fy)+fx)*f.depth+fd;\n                    f.dw[ix2] += V.w[ix1]*chain_grad;\n                    V.dw[ix1] += f.w[ix2]*chain_grad;\n                  }\n                }\n              }\n            }\n            this.biases.dw[d] += chain_grad;\n          }\n        }\n      }\n    },\n    getParamsAndGrads: function() {\n      var response = [];\n      for(var i=0;i<this.out_depth;i++) {\n        response.push({params: this.filters[i].w, grads: this.filters[i].dw, l2_decay_mul: this.l2_decay_mul, l1_decay_mul: this.l1_decay_mul});\n      }\n      response.push({params: this.biases.w, grads: this.biases.dw, l1_decay_mul: 0.0, l2_decay_mul: 0.0});\n      return response;\n    },\n    toJSON: function() {\n      var json = {};\n      json.sx = this.sx; // filter size in x, y dims\n      json.sy = this.sy;\n      json.stride = this.stride;\n      json.in_depth = this.in_depth;\n      json.out_depth = this.out_depth;\n      json.out_sx = this.out_sx;\n      json.out_sy = this.out_sy;\n      json.layer_type = this.layer_type;\n      json.l1_decay_mul = this.l1_decay_mul;\n      json.l2_decay_mul = this.l2_decay_mul;\n      json.pad = this.pad;\n      json.filters = [];\n      for(var i=0;i<this.filters.length;i++) {\n        json.filters.push(this.filters[i].toJSON());\n      }\n      json.biases = this.biases.toJSON();\n      return json;\n    },\n    fromJSON: function(json) {\n      this.out_depth = json.out_depth;\n      this.out_sx = json.out_sx;\n      this.out_sy = json.out_sy;\n      this.layer_type = json.layer_type;\n      this.sx = json.sx; // filter size in x, y dims\n      this.sy = json.sy;\n      this.stride = json.stride;\n      this.in_depth = json.in_depth; // depth of input volume\n      this.filters = [];\n      this.l1_decay_mul = typeof json.l1_decay_mul !== 'undefined' ? json.l1_decay_mul : 1.0;\n      this.l2_decay_mul = typeof json.l2_decay_mul !== 'undefined' ? json.l2_decay_mul : 1.0;\n      this.pad = typeof json.pad !== 'undefined' ? json.pad : 0;\n      for(var i=0;i<json.filters.length;i++) {\n        var v = new Vol(0,0,0,0);\n        v.fromJSON(json.filters[i]);\n        this.filters.push(v);\n      }\n      this.biases = new Vol(0,0,0,0);\n      this.biases.fromJSON(json.biases);\n    }\n  }\n\n  var FullyConnLayer = function(opt) {\n    var opt = opt || {};\n\n    // required\n    // ok fine we will allow 'filters' as the word as well\n    this.out_depth = typeof opt.num_neurons !== 'undefined' ? opt.num_neurons : opt.filters;\n\n    // optional \n    this.l1_decay_mul = typeof opt.l1_decay_mul !== 'undefined' ? opt.l1_decay_mul : 0.0;\n    this.l2_decay_mul = typeof opt.l2_decay_mul !== 'undefined' ? opt.l2_decay_mul : 1.0;\n\n    // computed\n    this.num_inputs = opt.in_sx * opt.in_sy * opt.in_depth;\n    this.out_sx = 1;\n    this.out_sy = 1;\n    this.layer_type = 'fc';\n\n    // initializations\n    var bias = typeof opt.bias_pref !== 'undefined' ? opt.bias_pref : 0.0;\n    this.filters = [];\n    for(var i=0;i<this.out_depth ;i++) { this.filters.push(new Vol(1, 1, this.num_inputs)); }\n    this.biases = new Vol(1, 1, this.out_depth, bias);\n  }\n\n  FullyConnLayer.prototype = {\n    forward: function(V, is_training) {\n      this.in_act = V;\n      var A = new Vol(1, 1, this.out_depth, 0.0);\n      var Vw = V.w;\n      for(var i=0;i<this.out_depth;i++) {\n        var a = 0.0;\n        var wi = this.filters[i].w;\n        for(var d=0;d<this.num_inputs;d++) {\n          a += Vw[d] * wi[d]; // for efficiency use Vols directly for now\n        }\n        a += this.biases.w[i];\n        A.w[i] = a;\n      }\n      this.out_act = A;\n      return this.out_act;\n    },\n    backward: function() {\n      var V = this.in_act;\n      V.dw = global.zeros(V.w.length); // zero out the gradient in input Vol\n      \n      // compute gradient wrt weights and data\n      for(var i=0;i<this.out_depth;i++) {\n        var tfi = this.filters[i];\n        var chain_grad = this.out_act.dw[i];\n        for(var d=0;d<this.num_inputs;d++) {\n          V.dw[d] += tfi.w[d]*chain_grad; // grad wrt input data\n          tfi.dw[d] += V.w[d]*chain_grad; // grad wrt params\n        }\n        this.biases.dw[i] += chain_grad;\n      }\n    },\n    getParamsAndGrads: function() {\n      var response = [];\n      for(var i=0;i<this.out_depth;i++) {\n        response.push({params: this.filters[i].w, grads: this.filters[i].dw, l1_decay_mul: this.l1_decay_mul, l2_decay_mul: this.l2_decay_mul});\n      }\n      response.push({params: this.biases.w, grads: this.biases.dw, l1_decay_mul: 0.0, l2_decay_mul: 0.0});\n      return response;\n    },\n    toJSON: function() {\n      var json = {};\n      json.out_depth = this.out_depth;\n      json.out_sx = this.out_sx;\n      json.out_sy = this.out_sy;\n      json.layer_type = this.layer_type;\n      json.num_inputs = this.num_inputs;\n      json.l1_decay_mul = this.l1_decay_mul;\n      json.l2_decay_mul = this.l2_decay_mul;\n      json.filters = [];\n      for(var i=0;i<this.filters.length;i++) {\n        json.filters.push(this.filters[i].toJSON());\n      }\n      json.biases = this.biases.toJSON();\n      return json;\n    },\n    fromJSON: function(json) {\n      this.out_depth = json.out_depth;\n      this.out_sx = json.out_sx;\n      this.out_sy = json.out_sy;\n      this.layer_type = json.layer_type;\n      this.num_inputs = json.num_inputs;\n      this.l1_decay_mul = typeof json.l1_decay_mul !== 'undefined' ? json.l1_decay_mul : 1.0;\n      this.l2_decay_mul = typeof json.l2_decay_mul !== 'undefined' ? json.l2_decay_mul : 1.0;\n      this.filters = [];\n      for(var i=0;i<json.filters.length;i++) {\n        var v = new Vol(0,0,0,0);\n        v.fromJSON(json.filters[i]);\n        this.filters.push(v);\n      }\n      this.biases = new Vol(0,0,0,0);\n      this.biases.fromJSON(json.biases);\n    }\n  }\n\n  global.ConvLayer = ConvLayer;\n  global.FullyConnLayer = FullyConnLayer;\n  \n})(convnetjs);\n(function(global) {\n  \"use strict\";\n  var Vol = global.Vol; // convenience\n  \n  var PoolLayer = function(opt) {\n\n    var opt = opt || {};\n\n    // required\n    this.sx = opt.sx; // filter size\n    this.in_depth = opt.in_depth;\n    this.in_sx = opt.in_sx;\n    this.in_sy = opt.in_sy;\n\n    // optional\n    this.sy = typeof opt.sy !== 'undefined' ? opt.sy : this.sx;\n    this.stride = typeof opt.stride !== 'undefined' ? opt.stride : 2;\n    this.pad = typeof opt.pad !== 'undefined' ? opt.pad : 0; // amount of 0 padding to add around borders of input volume\n\n    // computed\n    this.out_depth = this.in_depth;\n    this.out_sx = Math.floor((this.in_sx + this.pad * 2 - this.sx) / this.stride + 1);\n    this.out_sy = Math.floor((this.in_sy + this.pad * 2 - this.sy) / this.stride + 1);\n    this.layer_type = 'pool';\n    // store switches for x,y coordinates for where the max comes from, for each output neuron\n    this.switchx = global.zeros(this.out_sx*this.out_sy*this.out_depth);\n    this.switchy = global.zeros(this.out_sx*this.out_sy*this.out_depth);\n  }\n\n  PoolLayer.prototype = {\n    forward: function(V, is_training) {\n      this.in_act = V;\n\n      var A = new Vol(this.out_sx, this.out_sy, this.out_depth, 0.0);\n      \n      var n=0; // a counter for switches\n      for(var d=0;d<this.out_depth;d++) {\n        var x = -this.pad;\n        var y = -this.pad;\n        for(var ax=0; ax<this.out_sx; x+=this.stride,ax++) {\n          y = -this.pad;\n          for(var ay=0; ay<this.out_sy; y+=this.stride,ay++) {\n\n            // convolve centered at this particular location\n            var a = -99999; // hopefully small enough ;\\\n            var winx=-1,winy=-1;\n            for(var fx=0;fx<this.sx;fx++) {\n              for(var fy=0;fy<this.sy;fy++) {\n                var oy = y+fy;\n                var ox = x+fx;\n                if(oy>=0 && oy<V.sy && ox>=0 && ox<V.sx) {\n                  var v = V.get(ox, oy, d);\n                  // perform max pooling and store pointers to where\n                  // the max came from. This will speed up backprop \n                  // and can help make nice visualizations in future\n                  if(v > a) { a = v; winx=ox; winy=oy;}\n                }\n              }\n            }\n            this.switchx[n] = winx;\n            this.switchy[n] = winy;\n            n++;\n            A.set(ax, ay, d, a);\n          }\n        }\n      }\n      this.out_act = A;\n      return this.out_act;\n    },\n    backward: function() { \n      // pooling layers have no parameters, so simply compute \n      // gradient wrt data here\n      var V = this.in_act;\n      V.dw = global.zeros(V.w.length); // zero out gradient wrt data\n      var A = this.out_act; // computed in forward pass \n\n      var n = 0;\n      for(var d=0;d<this.out_depth;d++) {\n        var x = -this.pad;\n        var y = -this.pad;\n        for(var ax=0; ax<this.out_sx; x+=this.stride,ax++) {\n          y = -this.pad;\n          for(var ay=0; ay<this.out_sy; y+=this.stride,ay++) {\n\n            var chain_grad = this.out_act.get_grad(ax,ay,d);\n            V.add_grad(this.switchx[n], this.switchy[n], d, chain_grad);\n            n++;\n\n          }\n        }\n      }\n    },\n    getParamsAndGrads: function() {\n      return [];\n    },\n    toJSON: function() {\n      var json = {};\n      json.sx = this.sx;\n      json.sy = this.sy;\n      json.stride = this.stride;\n      json.in_depth = this.in_depth;\n      json.out_depth = this.out_depth;\n      json.out_sx = this.out_sx;\n      json.out_sy = this.out_sy;\n      json.layer_type = this.layer_type;\n      json.pad = this.pad;\n      return json;\n    },\n    fromJSON: function(json) {\n      this.out_depth = json.out_depth;\n      this.out_sx = json.out_sx;\n      this.out_sy = json.out_sy;\n      this.layer_type = json.layer_type;\n      this.sx = json.sx;\n      this.sy = json.sy;\n      this.stride = json.stride;\n      this.in_depth = json.in_depth;\n      this.pad = typeof json.pad !== 'undefined' ? json.pad : 0; // backwards compatibility\n      this.switchx = global.zeros(this.out_sx*this.out_sy*this.out_depth); // need to re-init these appropriately\n      this.switchy = global.zeros(this.out_sx*this.out_sy*this.out_depth);\n    }\n  }\n\n  global.PoolLayer = PoolLayer;\n\n})(convnetjs);\n\n(function(global) {\n  \"use strict\";\n  var Vol = global.Vol; // convenience\n  var getopt = global.getopt;\n\n  var InputLayer = function(opt) {\n    var opt = opt || {};\n\n    // required: depth\n    this.out_depth = getopt(opt, ['out_depth', 'depth'], 0);\n\n    // optional: default these dimensions to 1\n    this.out_sx = getopt(opt, ['out_sx', 'sx', 'width'], 1);\n    this.out_sy = getopt(opt, ['out_sy', 'sy', 'height'], 1);\n    \n    // computed\n    this.layer_type = 'input';\n  }\n  InputLayer.prototype = {\n    forward: function(V, is_training) {\n      this.in_act = V;\n      this.out_act = V;\n      return this.out_act; // simply identity function for now\n    },\n    backward: function() { },\n    getParamsAndGrads: function() {\n      return [];\n    },\n    toJSON: function() {\n      var json = {};\n      json.out_depth = this.out_depth;\n      json.out_sx = this.out_sx;\n      json.out_sy = this.out_sy;\n      json.layer_type = this.layer_type;\n      return json;\n    },\n    fromJSON: function(json) {\n      this.out_depth = json.out_depth;\n      this.out_sx = json.out_sx;\n      this.out_sy = json.out_sy;\n      this.layer_type = json.layer_type; \n    }\n  }\n\n  global.InputLayer = InputLayer;\n})(convnetjs);\n(function(global) {\n  \"use strict\";\n  var Vol = global.Vol; // convenience\n  \n  // Layers that implement a loss. Currently these are the layers that \n  // can initiate a backward() pass. In future we probably want a more \n  // flexible system that can accomodate multiple losses to do multi-task\n  // learning, and stuff like that. But for now, one of the layers in this\n  // file must be the final layer in a Net.\n\n  // This is a classifier, with N discrete classes from 0 to N-1\n  // it gets a stream of N incoming numbers and computes the softmax\n  // function (exponentiate and normalize to sum to 1 as probabilities should)\n  var SoftmaxLayer = function(opt) {\n    var opt = opt || {};\n\n    // computed\n    this.num_inputs = opt.in_sx * opt.in_sy * opt.in_depth;\n    this.out_depth = this.num_inputs;\n    this.out_sx = 1;\n    this.out_sy = 1;\n    this.layer_type = 'softmax';\n  }\n\n  SoftmaxLayer.prototype = {\n    forward: function(V, is_training) {\n      this.in_act = V;\n\n      var A = new Vol(1, 1, this.out_depth, 0.0);\n\n      // compute max activation\n      var as = V.w;\n      var amax = V.w[0];\n      for(var i=1;i<this.out_depth;i++) {\n        if(as[i] > amax) amax = as[i];\n      }\n\n      // compute exponentials (carefully to not blow up)\n      var es = global.zeros(this.out_depth);\n      var esum = 0.0;\n      for(var i=0;i<this.out_depth;i++) {\n        var e = Math.exp(as[i] - amax);\n        esum += e;\n        es[i] = e;\n      }\n\n      // normalize and output to sum to one\n      for(var i=0;i<this.out_depth;i++) {\n        es[i] /= esum;\n        A.w[i] = es[i];\n      }\n\n      this.es = es; // save these for backprop\n      this.out_act = A;\n      return this.out_act;\n    },\n    backward: function(y) {\n\n      // compute and accumulate gradient wrt weights and bias of this layer\n      var x = this.in_act;\n      x.dw = global.zeros(x.w.length); // zero out the gradient of input Vol\n\n      for(var i=0;i<this.out_depth;i++) {\n        var indicator = i === y ? 1.0 : 0.0;\n        var mul = -(indicator - this.es[i]);\n        x.dw[i] = mul;\n      }\n\n      // loss is the class negative log likelihood\n      return -Math.log(this.es[y]);\n    },\n    getParamsAndGrads: function() { \n      return [];\n    },\n    toJSON: function() {\n      var json = {};\n      json.out_depth = this.out_depth;\n      json.out_sx = this.out_sx;\n      json.out_sy = this.out_sy;\n      json.layer_type = this.layer_type;\n      json.num_inputs = this.num_inputs;\n      return json;\n    },\n    fromJSON: function(json) {\n      this.out_depth = json.out_depth;\n      this.out_sx = json.out_sx;\n      this.out_sy = json.out_sy;\n      this.layer_type = json.layer_type;\n      this.num_inputs = json.num_inputs;\n    }\n  }\n\n  // implements an L2 regression cost layer,\n  // so penalizes \\sum_i(||x_i - y_i||^2), where x is its input\n  // and y is the user-provided array of \"correct\" values.\n  var RegressionLayer = function(opt) {\n    var opt = opt || {};\n\n    // computed\n    this.num_inputs = opt.in_sx * opt.in_sy * opt.in_depth;\n    this.out_depth = this.num_inputs;\n    this.out_sx = 1;\n    this.out_sy = 1;\n    this.layer_type = 'regression';\n  }\n\n  RegressionLayer.prototype = {\n    forward: function(V, is_training) {\n      this.in_act = V;\n      this.out_act = V;\n      return V; // identity function\n    },\n    // y is a list here of size num_inputs\n    // or it can be a number if only one value is regressed\n    // or it can be a struct {dim: i, val: x} where we only want to \n    // regress on dimension i and asking it to have value x\n    backward: function(y) { \n\n      // compute and accumulate gradient wrt weights and bias of this layer\n      var x = this.in_act;\n      x.dw = global.zeros(x.w.length); // zero out the gradient of input Vol\n      var loss = 0.0;\n      if(y instanceof Array || y instanceof Float64Array) {\n        for(var i=0;i<this.out_depth;i++) {\n          var dy = x.w[i] - y[i];\n          x.dw[i] = dy;\n          loss += 0.5*dy*dy;\n        }\n      } else if(typeof y === 'number') {\n        // lets hope that only one number is being regressed\n        var dy = x.w[0] - y;\n        x.dw[0] = dy;\n        loss += 0.5*dy*dy;\n      } else {\n        // assume it is a struct with entries .dim and .val\n        // and we pass gradient only along dimension dim to be equal to val\n        var i = y.dim;\n        var yi = y.val;\n        var dy = x.w[i] - yi;\n        x.dw[i] = dy;\n        loss += 0.5*dy*dy;\n      }\n      return loss;\n    },\n    getParamsAndGrads: function() { \n      return [];\n    },\n    toJSON: function() {\n      var json = {};\n      json.out_depth = this.out_depth;\n      json.out_sx = this.out_sx;\n      json.out_sy = this.out_sy;\n      json.layer_type = this.layer_type;\n      json.num_inputs = this.num_inputs;\n      return json;\n    },\n    fromJSON: function(json) {\n      this.out_depth = json.out_depth;\n      this.out_sx = json.out_sx;\n      this.out_sy = json.out_sy;\n      this.layer_type = json.layer_type;\n      this.num_inputs = json.num_inputs;\n    }\n  }\n\n  var SVMLayer = function(opt) {\n    var opt = opt || {};\n\n    // computed\n    this.num_inputs = opt.in_sx * opt.in_sy * opt.in_depth;\n    this.out_depth = this.num_inputs;\n    this.out_sx = 1;\n    this.out_sy = 1;\n    this.layer_type = 'svm';\n  }\n\n  SVMLayer.prototype = {\n    forward: function(V, is_training) {\n      this.in_act = V;\n      this.out_act = V; // nothing to do, output raw scores\n      return V;\n    },\n    backward: function(y) {\n\n      // compute and accumulate gradient wrt weights and bias of this layer\n      var x = this.in_act;\n      x.dw = global.zeros(x.w.length); // zero out the gradient of input Vol\n\n      // we're using structured loss here, which means that the score\n      // of the ground truth should be higher than the score of any other \n      // class, by a margin\n      var yscore = x.w[y]; // score of ground truth\n      var margin = 1.0;\n      var loss = 0.0;\n      for(var i=0;i<this.out_depth;i++) {\n        if(y === i) { continue; }\n        var ydiff = -yscore + x.w[i] + margin;\n        if(ydiff > 0) {\n          // violating dimension, apply loss\n          x.dw[i] += 1;\n          x.dw[y] -= 1;\n          loss += ydiff;\n        }\n      }\n\n      return loss;\n    },\n    getParamsAndGrads: function() { \n      return [];\n    },\n    toJSON: function() {\n      var json = {};\n      json.out_depth = this.out_depth;\n      json.out_sx = this.out_sx;\n      json.out_sy = this.out_sy;\n      json.layer_type = this.layer_type;\n      json.num_inputs = this.num_inputs;\n      return json;\n    },\n    fromJSON: function(json) {\n      this.out_depth = json.out_depth;\n      this.out_sx = json.out_sx;\n      this.out_sy = json.out_sy;\n      this.layer_type = json.layer_type;\n      this.num_inputs = json.num_inputs;\n    }\n  }\n  \n  global.RegressionLayer = RegressionLayer;\n  global.SoftmaxLayer = SoftmaxLayer;\n  global.SVMLayer = SVMLayer;\n\n})(convnetjs);\n\n(function(global) {\n  \"use strict\";\n  var Vol = global.Vol; // convenience\n  \n  // Implements ReLU nonlinearity elementwise\n  // x -> max(0, x)\n  // the output is in [0, inf)\n  var ReluLayer = function(opt) {\n    var opt = opt || {};\n\n    // computed\n    this.out_sx = opt.in_sx;\n    this.out_sy = opt.in_sy;\n    this.out_depth = opt.in_depth;\n    this.layer_type = 'relu';\n  }\n  ReluLayer.prototype = {\n    forward: function(V, is_training) {\n      this.in_act = V;\n      var V2 = V.clone();\n      var N = V.w.length;\n      var V2w = V2.w;\n      for(var i=0;i<N;i++) { \n        if(V2w[i] < 0) V2w[i] = 0; // threshold at 0\n      }\n      this.out_act = V2;\n      return this.out_act;\n    },\n    backward: function() {\n      var V = this.in_act; // we need to set dw of this\n      var V2 = this.out_act;\n      var N = V.w.length;\n      V.dw = global.zeros(N); // zero out gradient wrt data\n      for(var i=0;i<N;i++) {\n        if(V2.w[i] <= 0) V.dw[i] = 0; // threshold\n        else V.dw[i] = V2.dw[i];\n      }\n    },\n    getParamsAndGrads: function() {\n      return [];\n    },\n    toJSON: function() {\n      var json = {};\n      json.out_depth = this.out_depth;\n      json.out_sx = this.out_sx;\n      json.out_sy = this.out_sy;\n      json.layer_type = this.layer_type;\n      return json;\n    },\n    fromJSON: function(json) {\n      this.out_depth = json.out_depth;\n      this.out_sx = json.out_sx;\n      this.out_sy = json.out_sy;\n      this.layer_type = json.layer_type; \n    }\n  }\n\n  // Implements Sigmoid nnonlinearity elementwise\n  // x -> 1/(1+e^(-x))\n  // so the output is between 0 and 1.\n  var SigmoidLayer = function(opt) {\n    var opt = opt || {};\n\n    // computed\n    this.out_sx = opt.in_sx;\n    this.out_sy = opt.in_sy;\n    this.out_depth = opt.in_depth;\n    this.layer_type = 'sigmoid';\n  }\n  SigmoidLayer.prototype = {\n    forward: function(V, is_training) {\n      this.in_act = V;\n      var V2 = V.cloneAndZero();\n      var N = V.w.length;\n      var V2w = V2.w;\n      var Vw = V.w;\n      for(var i=0;i<N;i++) { \n        V2w[i] = 1.0/(1.0+Math.exp(-Vw[i]));\n      }\n      this.out_act = V2;\n      return this.out_act;\n    },\n    backward: function() {\n      var V = this.in_act; // we need to set dw of this\n      var V2 = this.out_act;\n      var N = V.w.length;\n      V.dw = global.zeros(N); // zero out gradient wrt data\n      for(var i=0;i<N;i++) {\n        var v2wi = V2.w[i];\n        V.dw[i] =  v2wi * (1.0 - v2wi) * V2.dw[i];\n      }\n    },\n    getParamsAndGrads: function() {\n      return [];\n    },\n    toJSON: function() {\n      var json = {};\n      json.out_depth = this.out_depth;\n      json.out_sx = this.out_sx;\n      json.out_sy = this.out_sy;\n      json.layer_type = this.layer_type;\n      return json;\n    },\n    fromJSON: function(json) {\n      this.out_depth = json.out_depth;\n      this.out_sx = json.out_sx;\n      this.out_sy = json.out_sy;\n      this.layer_type = json.layer_type; \n    }\n  }\n\n  // Implements Maxout nnonlinearity that computes\n  // x -> max(x)\n  // where x is a vector of size group_size. Ideally of course,\n  // the input size should be exactly divisible by group_size\n  var MaxoutLayer = function(opt) {\n    var opt = opt || {};\n\n    // required\n    this.group_size = typeof opt.group_size !== 'undefined' ? opt.group_size : 2;\n\n    // computed\n    this.out_sx = opt.in_sx;\n    this.out_sy = opt.in_sy;\n    this.out_depth = Math.floor(opt.in_depth / this.group_size);\n    this.layer_type = 'maxout';\n\n    this.switches = global.zeros(this.out_sx*this.out_sy*this.out_depth); // useful for backprop\n  }\n  MaxoutLayer.prototype = {\n    forward: function(V, is_training) {\n      this.in_act = V;\n      var N = this.out_depth; \n      var V2 = new Vol(this.out_sx, this.out_sy, this.out_depth, 0.0);\n\n      // optimization branch. If we're operating on 1D arrays we dont have\n      // to worry about keeping track of x,y,d coordinates inside\n      // input volumes. In convnets we do :(\n      if(this.out_sx === 1 && this.out_sy === 1) {\n        for(var i=0;i<N;i++) {\n          var ix = i * this.group_size; // base index offset\n          var a = V.w[ix];\n          var ai = 0;\n          for(var j=1;j<this.group_size;j++) {\n            var a2 = V.w[ix+j];\n            if(a2 > a) {\n              a = a2;\n              ai = j;\n            }\n          }\n          V2.w[i] = a;\n          this.switches[i] = ix + ai;\n        }\n      } else {\n        var n=0; // counter for switches\n        for(var x=0;x<V.sx;x++) {\n          for(var y=0;y<V.sy;y++) {\n            for(var i=0;i<N;i++) {\n              var ix = i * this.group_size;\n              var a = V.get(x, y, ix);\n              var ai = 0;\n              for(var j=1;j<this.group_size;j++) {\n                var a2 = V.get(x, y, ix+j);\n                if(a2 > a) {\n                  a = a2;\n                  ai = j;\n                }\n              }\n              V2.set(x,y,i,a);\n              this.switches[n] = ix + ai;\n              n++;\n            }\n          }\n        }\n\n      }\n      this.out_act = V2;\n      return this.out_act;\n    },\n    backward: function() {\n      var V = this.in_act; // we need to set dw of this\n      var V2 = this.out_act;\n      var N = this.out_depth;\n      V.dw = global.zeros(V.w.length); // zero out gradient wrt data\n\n      // pass the gradient through the appropriate switch\n      if(this.out_sx === 1 && this.out_sy === 1) {\n        for(var i=0;i<N;i++) {\n          var chain_grad = V2.dw[i];\n          V.dw[this.switches[i]] = chain_grad;\n        }\n      } else {\n        // bleh okay, lets do this the hard way\n        var n=0; // counter for switches\n        for(var x=0;x<V2.sx;x++) {\n          for(var y=0;y<V2.sy;y++) {\n            for(var i=0;i<N;i++) {\n              var chain_grad = V2.get_grad(x,y,i);\n              V.set_grad(x,y,this.switches[n],chain_grad);\n              n++;\n            }\n          }\n        }\n      }\n    },\n    getParamsAndGrads: function() {\n      return [];\n    },\n    toJSON: function() {\n      var json = {};\n      json.out_depth = this.out_depth;\n      json.out_sx = this.out_sx;\n      json.out_sy = this.out_sy;\n      json.layer_type = this.layer_type;\n      json.group_size = this.group_size;\n      return json;\n    },\n    fromJSON: function(json) {\n      this.out_depth = json.out_depth;\n      this.out_sx = json.out_sx;\n      this.out_sy = json.out_sy;\n      this.layer_type = json.layer_type; \n      this.group_size = json.group_size;\n      this.switches = global.zeros(this.group_size);\n    }\n  }\n\n  // a helper function, since tanh is not yet part of ECMAScript. Will be in v6.\n  function tanh(x) {\n    var y = Math.exp(2 * x);\n    return (y - 1) / (y + 1);\n  }\n  // Implements Tanh nnonlinearity elementwise\n  // x -> tanh(x) \n  // so the output is between -1 and 1.\n  var TanhLayer = function(opt) {\n    var opt = opt || {};\n\n    // computed\n    this.out_sx = opt.in_sx;\n    this.out_sy = opt.in_sy;\n    this.out_depth = opt.in_depth;\n    this.layer_type = 'tanh';\n  }\n  TanhLayer.prototype = {\n    forward: function(V, is_training) {\n      this.in_act = V;\n      var V2 = V.cloneAndZero();\n      var N = V.w.length;\n      for(var i=0;i<N;i++) { \n        V2.w[i] = tanh(V.w[i]);\n      }\n      this.out_act = V2;\n      return this.out_act;\n    },\n    backward: function() {\n      var V = this.in_act; // we need to set dw of this\n      var V2 = this.out_act;\n      var N = V.w.length;\n      V.dw = global.zeros(N); // zero out gradient wrt data\n      for(var i=0;i<N;i++) {\n        var v2wi = V2.w[i];\n        V.dw[i] = (1.0 - v2wi * v2wi) * V2.dw[i];\n      }\n    },\n    getParamsAndGrads: function() {\n      return [];\n    },\n    toJSON: function() {\n      var json = {};\n      json.out_depth = this.out_depth;\n      json.out_sx = this.out_sx;\n      json.out_sy = this.out_sy;\n      json.layer_type = this.layer_type;\n      return json;\n    },\n    fromJSON: function(json) {\n      this.out_depth = json.out_depth;\n      this.out_sx = json.out_sx;\n      this.out_sy = json.out_sy;\n      this.layer_type = json.layer_type; \n    }\n  }\n  \n  global.TanhLayer = TanhLayer;\n  global.MaxoutLayer = MaxoutLayer;\n  global.ReluLayer = ReluLayer;\n  global.SigmoidLayer = SigmoidLayer;\n\n})(convnetjs);\n\n(function(global) {\n  \"use strict\";\n  var Vol = global.Vol; // convenience\n\n  // An inefficient dropout layer\n  // Note this is not most efficient implementation since the layer before\n  // computed all these activations and now we're just going to drop them :(\n  // same goes for backward pass. Also, if we wanted to be efficient at test time\n  // we could equivalently be clever and upscale during train and copy pointers during test\n  // todo: make more efficient.\n  var DropoutLayer = function(opt) {\n    var opt = opt || {};\n\n    // computed\n    this.out_sx = opt.in_sx;\n    this.out_sy = opt.in_sy;\n    this.out_depth = opt.in_depth;\n    this.layer_type = 'dropout';\n    this.drop_prob = typeof opt.drop_prob !== 'undefined' ? opt.drop_prob : 0.5;\n    this.dropped = global.zeros(this.out_sx*this.out_sy*this.out_depth);\n  }\n  DropoutLayer.prototype = {\n    forward: function(V, is_training) {\n      this.in_act = V;\n      if(typeof(is_training)==='undefined') { is_training = false; } // default is prediction mode\n      var V2 = V.clone();\n      var N = V.w.length;\n      if(is_training) {\n        // do dropout\n        for(var i=0;i<N;i++) {\n          if(Math.random()<this.drop_prob) { V2.w[i]=0; this.dropped[i] = true; } // drop!\n          else {this.dropped[i] = false;}\n        }\n      } else {\n        // scale the activations during prediction\n        for(var i=0;i<N;i++) { V2.w[i]*=this.drop_prob; }\n      }\n      this.out_act = V2;\n      return this.out_act; // dummy identity function for now\n    },\n    backward: function() {\n      var V = this.in_act; // we need to set dw of this\n      var chain_grad = this.out_act;\n      var N = V.w.length;\n      V.dw = global.zeros(N); // zero out gradient wrt data\n      for(var i=0;i<N;i++) {\n        if(!(this.dropped[i])) { \n          V.dw[i] = chain_grad.dw[i]; // copy over the gradient\n        }\n      }\n    },\n    getParamsAndGrads: function() {\n      return [];\n    },\n    toJSON: function() {\n      var json = {};\n      json.out_depth = this.out_depth;\n      json.out_sx = this.out_sx;\n      json.out_sy = this.out_sy;\n      json.layer_type = this.layer_type;\n      json.drop_prob = this.drop_prob;\n      return json;\n    },\n    fromJSON: function(json) {\n      this.out_depth = json.out_depth;\n      this.out_sx = json.out_sx;\n      this.out_sy = json.out_sy;\n      this.layer_type = json.layer_type; \n      this.drop_prob = json.drop_prob;\n    }\n  }\n  \n\n  global.DropoutLayer = DropoutLayer;\n})(convnetjs);\n(function(global) {\n  \"use strict\";\n  var Vol = global.Vol; // convenience\n  \n  // a bit experimental layer for now. I think it works but I'm not 100%\n  // the gradient check is a bit funky. I'll look into this a bit later.\n  // Local Response Normalization in window, along depths of volumes\n  var LocalResponseNormalizationLayer = function(opt) {\n    var opt = opt || {};\n\n    // required\n    this.k = opt.k;\n    this.n = opt.n;\n    this.alpha = opt.alpha;\n    this.beta = opt.beta;\n\n    // computed\n    this.out_sx = opt.in_sx;\n    this.out_sy = opt.in_sy;\n    this.out_depth = opt.in_depth;\n    this.layer_type = 'lrn';\n\n    // checks\n    if(this.n%2 === 0) { console.log('WARNING n should be odd for LRN layer'); }\n  }\n  LocalResponseNormalizationLayer.prototype = {\n    forward: function(V, is_training) {\n      this.in_act = V;\n\n      var A = V.cloneAndZero();\n      this.S_cache_ = V.cloneAndZero();\n      var n2 = Math.floor(this.n/2);\n      for(var x=0;x<V.sx;x++) {\n        for(var y=0;y<V.sy;y++) {\n          for(var i=0;i<V.depth;i++) {\n\n            var ai = V.get(x,y,i);\n\n            // normalize in a window of size n\n            var den = 0.0;\n            for(var j=Math.max(0,i-n2);j<=Math.min(i+n2,V.depth-1);j++) {\n              var aa = V.get(x,y,j);\n              den += aa*aa;\n            }\n            den *= this.alpha / this.n;\n            den += this.k;\n            this.S_cache_.set(x,y,i,den); // will be useful for backprop\n            den = Math.pow(den, this.beta);\n            A.set(x,y,i,ai/den);\n          }\n        }\n      }\n\n      this.out_act = A;\n      return this.out_act; // dummy identity function for now\n    },\n    backward: function() { \n      // evaluate gradient wrt data\n      var V = this.in_act; // we need to set dw of this\n      V.dw = global.zeros(V.w.length); // zero out gradient wrt data\n      var A = this.out_act; // computed in forward pass \n\n      var n2 = Math.floor(this.n/2);\n      for(var x=0;x<V.sx;x++) {\n        for(var y=0;y<V.sy;y++) {\n          for(var i=0;i<V.depth;i++) {\n\n            var chain_grad = this.out_act.get_grad(x,y,i);\n            var S = this.S_cache_.get(x,y,i);\n            var SB = Math.pow(S, this.beta);\n            var SB2 = SB*SB;\n\n            // normalize in a window of size n\n            for(var j=Math.max(0,i-n2);j<=Math.min(i+n2,V.depth-1);j++) {              \n              var aj = V.get(x,y,j); \n              var g = -aj*this.beta*Math.pow(S,this.beta-1)*this.alpha/this.n*2*aj;\n              if(j===i) g+= SB;\n              g /= SB2;\n              g *= chain_grad;\n              V.add_grad(x,y,j,g);\n            }\n\n          }\n        }\n      }\n    },\n    getParamsAndGrads: function() { return []; },\n    toJSON: function() {\n      var json = {};\n      json.k = this.k;\n      json.n = this.n;\n      json.alpha = this.alpha; // normalize by size\n      json.beta = this.beta;\n      json.out_sx = this.out_sx; \n      json.out_sy = this.out_sy;\n      json.out_depth = this.out_depth;\n      json.layer_type = this.layer_type;\n      return json;\n    },\n    fromJSON: function(json) {\n      this.k = json.k;\n      this.n = json.n;\n      this.alpha = json.alpha; // normalize by size\n      this.beta = json.beta;\n      this.out_sx = json.out_sx; \n      this.out_sy = json.out_sy;\n      this.out_depth = json.out_depth;\n      this.layer_type = json.layer_type;\n    }\n  }\n  \n\n  global.LocalResponseNormalizationLayer = LocalResponseNormalizationLayer;\n})(convnetjs);\n(function(global) {\n  \"use strict\";\n  var Vol = global.Vol; // convenience\n  var assert = global.assert;\n\n  // Net manages a set of layers\n  // For now constraints: Simple linear order of layers, first layer input last layer a cost layer\n  var Net = function(options) {\n    this.layers = [];\n  }\n\n  Net.prototype = {\n    \n    // takes a list of layer definitions and creates the network layer objects\n    makeLayers: function(defs) {\n\n      // few checks\n      assert(defs.length >= 2, 'Error! At least one input layer and one loss layer are required.');\n      assert(defs[0].type === 'input', 'Error! First layer must be the input layer, to declare size of inputs');\n\n      // desugar layer_defs for adding activation, dropout layers etc\n      var desugar = function() {\n        var new_defs = [];\n        for(var i=0;i<defs.length;i++) {\n          var def = defs[i];\n          \n          if(def.type==='softmax' || def.type==='svm') {\n            // add an fc layer here, there is no reason the user should\n            // have to worry about this and we almost always want to\n            new_defs.push({type:'fc', num_neurons: def.num_classes});\n          }\n\n          if(def.type==='regression') {\n            // add an fc layer here, there is no reason the user should\n            // have to worry about this and we almost always want to\n            new_defs.push({type:'fc', num_neurons: def.num_neurons});\n          }\n\n          if((def.type==='fc' || def.type==='conv') \n              && typeof(def.bias_pref) === 'undefined'){\n            def.bias_pref = 0.0;\n            if(typeof def.activation !== 'undefined' && def.activation === 'relu') {\n              def.bias_pref = 0.1; // relus like a bit of positive bias to get gradients early\n              // otherwise it's technically possible that a relu unit will never turn on (by chance)\n              // and will never get any gradient and never contribute any computation. Dead relu.\n            }\n          }\n\n          new_defs.push(def);\n\n          if(typeof def.activation !== 'undefined') {\n            if(def.activation==='relu') { new_defs.push({type:'relu'}); }\n            else if (def.activation==='sigmoid') { new_defs.push({type:'sigmoid'}); }\n            else if (def.activation==='tanh') { new_defs.push({type:'tanh'}); }\n            else if (def.activation==='maxout') {\n              // create maxout activation, and pass along group size, if provided\n              var gs = def.group_size !== 'undefined' ? def.group_size : 2;\n              new_defs.push({type:'maxout', group_size:gs});\n            }\n            else { console.log('ERROR unsupported activation ' + def.activation); }\n          }\n          if(typeof def.drop_prob !== 'undefined' && def.type !== 'dropout') {\n            new_defs.push({type:'dropout', drop_prob: def.drop_prob});\n          }\n\n        }\n        return new_defs;\n      }\n      defs = desugar(defs);\n\n      // create the layers\n      this.layers = [];\n      for(var i=0;i<defs.length;i++) {\n        var def = defs[i];\n        if(i>0) {\n          var prev = this.layers[i-1];\n          def.in_sx = prev.out_sx;\n          def.in_sy = prev.out_sy;\n          def.in_depth = prev.out_depth;\n        }\n\n        switch(def.type) {\n          case 'fc': this.layers.push(new global.FullyConnLayer(def)); break;\n          case 'lrn': this.layers.push(new global.LocalResponseNormalizationLayer(def)); break;\n          case 'dropout': this.layers.push(new global.DropoutLayer(def)); break;\n          case 'input': this.layers.push(new global.InputLayer(def)); break;\n          case 'softmax': this.layers.push(new global.SoftmaxLayer(def)); break;\n          case 'regression': this.layers.push(new global.RegressionLayer(def)); break;\n          case 'conv': this.layers.push(new global.ConvLayer(def)); break;\n          case 'pool': this.layers.push(new global.PoolLayer(def)); break;\n          case 'relu': this.layers.push(new global.ReluLayer(def)); break;\n          case 'sigmoid': this.layers.push(new global.SigmoidLayer(def)); break;\n          case 'tanh': this.layers.push(new global.TanhLayer(def)); break;\n          case 'maxout': this.layers.push(new global.MaxoutLayer(def)); break;\n          case 'svm': this.layers.push(new global.SVMLayer(def)); break;\n          default: console.log('ERROR: UNRECOGNIZED LAYER TYPE: ' + def.type);\n        }\n      }\n    },\n\n    // forward prop the network. \n    // The trainer class passes is_training = true, but when this function is\n    // called from outside (not from the trainer), it defaults to prediction mode\n    forward: function(V, is_training) {\n      if(typeof(is_training) === 'undefined') is_training = false;\n      var act = this.layers[0].forward(V, is_training);\n      for(var i=1;i<this.layers.length;i++) {\n        act = this.layers[i].forward(act, is_training);\n      }\n      return act;\n    },\n\n    getCostLoss: function(V, y) {\n      this.forward(V, false);\n      var N = this.layers.length;\n      var loss = this.layers[N-1].backward(y);\n      return loss;\n    },\n    \n    // backprop: compute gradients wrt all parameters\n    backward: function(y) {\n      var N = this.layers.length;\n      var loss = this.layers[N-1].backward(y); // last layer assumed to be loss layer\n      for(var i=N-2;i>=0;i--) { // first layer assumed input\n        this.layers[i].backward();\n      }\n      return loss;\n    },\n    getParamsAndGrads: function() {\n      // accumulate parameters and gradients for the entire network\n      var response = [];\n      for(var i=0;i<this.layers.length;i++) {\n        var layer_reponse = this.layers[i].getParamsAndGrads();\n        for(var j=0;j<layer_reponse.length;j++) {\n          response.push(layer_reponse[j]);\n        }\n      }\n      return response;\n    },\n    getPrediction: function() {\n      // this is a convenience function for returning the argmax\n      // prediction, assuming the last layer of the net is a softmax\n      var S = this.layers[this.layers.length-1];\n      assert(S.layer_type === 'softmax', 'getPrediction function assumes softmax as last layer of the net!');\n\n      var p = S.out_act.w;\n      var maxv = p[0];\n      var maxi = 0;\n      for(var i=1;i<p.length;i++) {\n        if(p[i] > maxv) { maxv = p[i]; maxi = i;}\n      }\n      return maxi; // return index of the class with highest class probability\n    },\n    toJSON: function() {\n      var json = {};\n      json.layers = [];\n      for(var i=0;i<this.layers.length;i++) {\n        json.layers.push(this.layers[i].toJSON());\n      }\n      return json;\n    },\n    fromJSON: function(json) {\n      this.layers = [];\n      for(var i=0;i<json.layers.length;i++) {\n        var Lj = json.layers[i]\n        var t = Lj.layer_type;\n        var L;\n        if(t==='input') { L = new global.InputLayer(); }\n        if(t==='relu') { L = new global.ReluLayer(); }\n        if(t==='sigmoid') { L = new global.SigmoidLayer(); }\n        if(t==='tanh') { L = new global.TanhLayer(); }\n        if(t==='dropout') { L = new global.DropoutLayer(); }\n        if(t==='conv') { L = new global.ConvLayer(); }\n        if(t==='pool') { L = new global.PoolLayer(); }\n        if(t==='lrn') { L = new global.LocalResponseNormalizationLayer(); }\n        if(t==='softmax') { L = new global.SoftmaxLayer(); }\n        if(t==='regression') { L = new global.RegressionLayer(); }\n        if(t==='fc') { L = new global.FullyConnLayer(); }\n        if(t==='maxout') { L = new global.MaxoutLayer(); }\n        if(t==='svm') { L = new global.SVMLayer(); }\n        L.fromJSON(Lj);\n        this.layers.push(L);\n      }\n    }\n  }\n  \n  global.Net = Net;\n})(convnetjs);\n(function(global) {\n  \"use strict\";\n  var Vol = global.Vol; // convenience\n\n  var Trainer = function(net, options) {\n\n    this.net = net;\n\n    var options = options || {};\n    this.learning_rate = typeof options.learning_rate !== 'undefined' ? options.learning_rate : 0.01;\n    this.l1_decay = typeof options.l1_decay !== 'undefined' ? options.l1_decay : 0.0;\n    this.l2_decay = typeof options.l2_decay !== 'undefined' ? options.l2_decay : 0.0;\n    this.batch_size = typeof options.batch_size !== 'undefined' ? options.batch_size : 1;\n    this.method = typeof options.method !== 'undefined' ? options.method : 'sgd'; // sgd/adagrad/adadelta/windowgrad/netsterov\n\n    this.momentum = typeof options.momentum !== 'undefined' ? options.momentum : 0.9;\n    this.ro = typeof options.ro !== 'undefined' ? options.ro : 0.95; // used in adadelta\n    this.eps = typeof options.eps !== 'undefined' ? options.eps : 1e-6; // used in adadelta\n\n    this.k = 0; // iteration counter\n    this.gsum = []; // last iteration gradients (used for momentum calculations)\n    this.xsum = []; // used in adadelta\n  }\n\n  Trainer.prototype = {\n    train: function(x, y) {\n\n      var start = new Date().getTime();\n      this.net.forward(x, true); // also set the flag that lets the net know we're just training\n      var end = new Date().getTime();\n      var fwd_time = end - start;\n\n      var start = new Date().getTime();\n      var cost_loss = this.net.backward(y);\n      var l2_decay_loss = 0.0;\n      var l1_decay_loss = 0.0;\n      var end = new Date().getTime();\n      var bwd_time = end - start;\n      \n      this.k++;\n      if(this.k % this.batch_size === 0) {\n\n        var pglist = this.net.getParamsAndGrads();\n\n        // initialize lists for accumulators. Will only be done once on first iteration\n        if(this.gsum.length === 0 && (this.method !== 'sgd' || this.momentum > 0.0)) {\n          // only vanilla sgd doesnt need either lists\n          // momentum needs gsum\n          // adagrad needs gsum\n          // adadelta needs gsum and xsum\n          for(var i=0;i<pglist.length;i++) {\n            this.gsum.push(global.zeros(pglist[i].params.length));\n            if(this.method === 'adadelta') {\n              this.xsum.push(global.zeros(pglist[i].params.length));\n            } else {\n              this.xsum.push([]); // conserve memory\n            }\n          }\n        }\n\n        // perform an update for all sets of weights\n        for(var i=0;i<pglist.length;i++) {\n          var pg = pglist[i]; // param, gradient, other options in future (custom learning rate etc)\n          var p = pg.params;\n          var g = pg.grads;\n\n          // learning rate for some parameters.\n          var l2_decay_mul = typeof pg.l2_decay_mul !== 'undefined' ? pg.l2_decay_mul : 1.0;\n          var l1_decay_mul = typeof pg.l1_decay_mul !== 'undefined' ? pg.l1_decay_mul : 1.0;\n          var l2_decay = this.l2_decay * l2_decay_mul;\n          var l1_decay = this.l1_decay * l1_decay_mul;\n\n          var plen = p.length;\n          for(var j=0;j<plen;j++) {\n            l2_decay_loss += l2_decay*p[j]*p[j]/2; // accumulate weight decay loss\n            l1_decay_loss += l1_decay*Math.abs(p[j]);\n            var l1grad = l1_decay * (p[j] > 0 ? 1 : -1);\n            var l2grad = l2_decay * (p[j]);\n\n            var gij = (l2grad + l1grad + g[j]) / this.batch_size; // raw batch gradient\n\n            var gsumi = this.gsum[i];\n            var xsumi = this.xsum[i];\n            if(this.method === 'adagrad') {\n              // adagrad update\n              gsumi[j] = gsumi[j] + gij * gij;\n              var dx = - this.learning_rate / Math.sqrt(gsumi[j] + this.eps) * gij;\n              p[j] += dx;\n            } else if(this.method === 'windowgrad') {\n              // this is adagrad but with a moving window weighted average\n              // so the gradient is not accumulated over the entire history of the run. \n              // it's also referred to as Idea #1 in Zeiler paper on Adadelta. Seems reasonable to me!\n              gsumi[j] = this.ro * gsumi[j] + (1-this.ro) * gij * gij;\n              var dx = - this.learning_rate / Math.sqrt(gsumi[j] + this.eps) * gij; // eps added for better conditioning\n              p[j] += dx;\n            } else if(this.method === 'adadelta') {\n              // assume adadelta if not sgd or adagrad\n              gsumi[j] = this.ro * gsumi[j] + (1-this.ro) * gij * gij;\n              var dx = - Math.sqrt((xsumi[j] + this.eps)/(gsumi[j] + this.eps)) * gij;\n              xsumi[j] = this.ro * xsumi[j] + (1-this.ro) * dx * dx; // yes, xsum lags behind gsum by 1.\n              p[j] += dx;\n            } else if(this.method === 'nesterov') {\n            \tvar dx = gsumi[j];\n            \tgsumi[j] = gsumi[j] * this.momentum + this.learning_rate * gij;\n                dx = this.momentum * dx - (1.0 + this.momentum) * gsumi[j];\n                p[j] += dx;\n            } else {\n              // assume SGD\n              if(this.momentum > 0.0) {\n                // momentum update\n                var dx = this.momentum * gsumi[j] - this.learning_rate * gij; // step\n                gsumi[j] = dx; // back this up for next iteration of momentum\n                p[j] += dx; // apply corrected gradient\n              } else {\n                // vanilla sgd\n                p[j] +=  - this.learning_rate * gij;\n              }\n            }\n            g[j] = 0.0; // zero out gradient so that we can begin accumulating anew\n          }\n        }\n      }\n\n      // appending softmax_loss for backwards compatibility, but from now on we will always use cost_loss\n      // in future, TODO: have to completely redo the way loss is done around the network as currently \n      // loss is a bit of a hack. Ideally, user should specify arbitrary number of loss functions on any layer\n      // and it should all be computed correctly and automatically. \n      return {fwd_time: fwd_time, bwd_time: bwd_time, \n              l2_decay_loss: l2_decay_loss, l1_decay_loss: l1_decay_loss,\n              cost_loss: cost_loss, softmax_loss: cost_loss, \n              loss: cost_loss + l1_decay_loss + l2_decay_loss}\n    }\n  }\n  \n  global.Trainer = Trainer;\n  global.SGDTrainer = Trainer; // backwards compatibility\n})(convnetjs);\n\n(function(global) {\n  \"use strict\";\n\n  // used utilities, make explicit local references\n  var randf = global.randf;\n  var randi = global.randi;\n  var Net = global.Net;\n  var Trainer = global.Trainer;\n  var maxmin = global.maxmin;\n  var randperm = global.randperm;\n  var weightedSample = global.weightedSample;\n  var getopt = global.getopt;\n  var arrUnique = global.arrUnique;\n\n  /*\n  A MagicNet takes data: a list of convnetjs.Vol(), and labels\n  which for now are assumed to be class indeces 0..K. MagicNet then:\n  - creates data folds for cross-validation\n  - samples candidate networks\n  - evaluates candidate networks on all data folds\n  - produces predictions by model-averaging the best networks\n  */\n  var MagicNet = function(data, labels, opt) {\n    var opt = opt || {};\n    if(typeof data === 'undefined') { data = []; }\n    if(typeof labels === 'undefined') { labels = []; }\n\n    // required inputs\n    this.data = data; // store these pointers to data\n    this.labels = labels;\n\n    // optional inputs\n    this.train_ratio = getopt(opt, 'train_ratio', 0.7);\n    this.num_folds = getopt(opt, 'num_folds', 10);\n    this.num_candidates = getopt(opt, 'num_candidates', 50); // we evaluate several in parallel\n    // how many epochs of data to train every network? for every fold?\n    // higher values mean higher accuracy in final results, but more expensive\n    this.num_epochs = getopt(opt, 'num_epochs', 50); \n    // number of best models to average during prediction. Usually higher = better\n    this.ensemble_size = getopt(opt, 'ensemble_size', 10);\n\n    // candidate parameters\n    this.batch_size_min = getopt(opt, 'batch_size_min', 10);\n    this.batch_size_max = getopt(opt, 'batch_size_max', 300);\n    this.l2_decay_min = getopt(opt, 'l2_decay_min', -4);\n    this.l2_decay_max = getopt(opt, 'l2_decay_max', 2);\n    this.learning_rate_min = getopt(opt, 'learning_rate_min', -4);\n    this.learning_rate_max = getopt(opt, 'learning_rate_max', 0);\n    this.momentum_min = getopt(opt, 'momentum_min', 0.9);\n    this.momentum_max = getopt(opt, 'momentum_max', 0.9);\n    this.neurons_min = getopt(opt, 'neurons_min', 5);\n    this.neurons_max = getopt(opt, 'neurons_max', 30);\n\n    // computed\n    this.folds = []; // data fold indices, gets filled by sampleFolds()\n    this.candidates = []; // candidate networks that are being currently evaluated\n    this.evaluated_candidates = []; // history of all candidates that were fully evaluated on all folds\n    this.unique_labels = arrUnique(labels);\n    this.iter = 0; // iteration counter, goes from 0 -> num_epochs * num_training_data\n    this.foldix = 0; // index of active fold\n\n    // callbacks\n    this.finish_fold_callback = null;\n    this.finish_batch_callback = null;\n\n    // initializations\n    if(this.data.length > 0) {\n      this.sampleFolds();\n      this.sampleCandidates();\n    }\n  };\n\n  MagicNet.prototype = {\n\n    // sets this.folds to a sampling of this.num_folds folds\n    sampleFolds: function() {\n      var N = this.data.length;\n      var num_train = Math.floor(this.train_ratio * N);\n      this.folds = []; // flush folds, if any\n      for(var i=0;i<this.num_folds;i++) {\n        var p = randperm(N);\n        this.folds.push({train_ix: p.slice(0, num_train), test_ix: p.slice(num_train, N)});\n      }\n    },\n\n    // returns a random candidate network\n    sampleCandidate: function() {\n      var input_depth = this.data[0].w.length;\n      var num_classes = this.unique_labels.length;\n\n      // sample network topology and hyperparameters\n      var layer_defs = [];\n      layer_defs.push({type:'input', out_sx:1, out_sy:1, out_depth: input_depth});\n      var nl = weightedSample([0,1,2,3], [0.2, 0.3, 0.3, 0.2]); // prefer nets with 1,2 hidden layers\n      for(var q=0;q<nl;q++) {\n        var ni = randi(this.neurons_min, this.neurons_max);\n        var act = ['tanh','maxout','relu'][randi(0,3)];\n        if(randf(0,1)<0.5) {\n          var dp = Math.random();\n          layer_defs.push({type:'fc', num_neurons: ni, activation: act, drop_prob: dp});\n        } else {\n          layer_defs.push({type:'fc', num_neurons: ni, activation: act});\n        }\n      }\n      layer_defs.push({type:'softmax', num_classes: num_classes});\n      var net = new Net();\n      net.makeLayers(layer_defs);\n\n      // sample training hyperparameters\n      var bs = randi(this.batch_size_min, this.batch_size_max); // batch size\n      var l2 = Math.pow(10, randf(this.l2_decay_min, this.l2_decay_max)); // l2 weight decay\n      var lr = Math.pow(10, randf(this.learning_rate_min, this.learning_rate_max)); // learning rate\n      var mom = randf(this.momentum_min, this.momentum_max); // momentum. Lets just use 0.9, works okay usually ;p\n      var tp = randf(0,1); // trainer type\n      var trainer_def;\n      if(tp<0.33) {\n        trainer_def = {method:'adadelta', batch_size:bs, l2_decay:l2};\n      } else if(tp<0.66) {\n        trainer_def = {method:'adagrad', learning_rate: lr, batch_size:bs, l2_decay:l2};\n      } else {\n        trainer_def = {method:'sgd', learning_rate: lr, momentum: mom, batch_size:bs, l2_decay:l2};\n      }\n      \n      var trainer = new Trainer(net, trainer_def);\n\n      var cand = {};\n      cand.acc = [];\n      cand.accv = 0; // this will maintained as sum(acc) for convenience\n      cand.layer_defs = layer_defs;\n      cand.trainer_def = trainer_def;\n      cand.net = net;\n      cand.trainer = trainer;\n      return cand;\n    },\n\n    // sets this.candidates with this.num_candidates candidate nets\n    sampleCandidates: function() {\n      this.candidates = []; // flush, if any\n      for(var i=0;i<this.num_candidates;i++) {\n        var cand = this.sampleCandidate();\n        this.candidates.push(cand);\n      }\n    },\n\n    step: function() {\n      \n      // run an example through current candidate\n      this.iter++;\n\n      // step all candidates on a random data point\n      var fold = this.folds[this.foldix]; // active fold\n      var dataix = fold.train_ix[randi(0, fold.train_ix.length)];\n      for(var k=0;k<this.candidates.length;k++) {\n        var x = this.data[dataix];\n        var l = this.labels[dataix];\n        this.candidates[k].trainer.train(x, l);\n      }\n\n      // process consequences: sample new folds, or candidates\n      var lastiter = this.num_epochs * fold.train_ix.length;\n      if(this.iter >= lastiter) {\n        // finished evaluation of this fold. Get final validation\n        // accuracies, record them, and go on to next fold.\n        var val_acc = this.evalValErrors();\n        for(var k=0;k<this.candidates.length;k++) {\n          var c = this.candidates[k];\n          c.acc.push(val_acc[k]);\n          c.accv += val_acc[k];\n        }\n        this.iter = 0; // reset step number\n        this.foldix++; // increment fold\n\n        if(this.finish_fold_callback !== null) {\n          this.finish_fold_callback();\n        }\n\n        if(this.foldix >= this.folds.length) {\n          // we finished all folds as well! Record these candidates\n          // and sample new ones to evaluate.\n          for(var k=0;k<this.candidates.length;k++) {\n            this.evaluated_candidates.push(this.candidates[k]);\n          }\n          // sort evaluated candidates according to accuracy achieved\n          this.evaluated_candidates.sort(function(a, b) { \n            return (a.accv / a.acc.length) \n                 > (b.accv / b.acc.length) \n                 ? -1 : 1;\n          });\n          // and clip only to the top few ones (lets place limit at 3*ensemble_size)\n          // otherwise there are concerns with keeping these all in memory \n          // if MagicNet is being evaluated for a very long time\n          if(this.evaluated_candidates.length > 3 * this.ensemble_size) {\n            this.evaluated_candidates = this.evaluated_candidates.slice(0, 3 * this.ensemble_size);\n          }\n          if(this.finish_batch_callback !== null) {\n            this.finish_batch_callback();\n          }\n          this.sampleCandidates(); // begin with new candidates\n          this.foldix = 0; // reset this\n        } else {\n          // we will go on to another fold. reset all candidates nets\n          for(var k=0;k<this.candidates.length;k++) {\n            var c = this.candidates[k];\n            var net = new Net();\n            net.makeLayers(c.layer_defs);\n            var trainer = new Trainer(net, c.trainer_def);\n            c.net = net;\n            c.trainer = trainer;\n          }\n        }\n      }\n    },\n\n    evalValErrors: function() {\n      // evaluate candidates on validation data and return performance of current networks\n      // as simple list\n      var vals = [];\n      var fold = this.folds[this.foldix]; // active fold\n      for(var k=0;k<this.candidates.length;k++) {\n        var net = this.candidates[k].net;\n        var v = 0.0;\n        for(var q=0;q<fold.test_ix.length;q++) {\n          var x = this.data[fold.test_ix[q]];\n          var l = this.labels[fold.test_ix[q]];\n          net.forward(x);\n          var yhat = net.getPrediction();\n          v += (yhat === l ? 1.0 : 0.0); // 0 1 loss\n        }\n        v /= fold.test_ix.length; // normalize\n        vals.push(v);\n      }\n      return vals;\n    },\n\n    // returns prediction scores for given test data point, as Vol\n    // uses an averaged prediction from the best ensemble_size models\n    // x is a Vol.\n    predict_soft: function(data) {\n      // forward prop the best networks\n      // and accumulate probabilities at last layer into a an output Vol\n\n      var eval_candidates = [];\n      var nv = 0;\n      if(this.evaluated_candidates.length === 0) {\n        // not sure what to do here, first batch of nets hasnt evaluated yet\n        // lets just predict with current candidates.\n        nv = this.candidates.length;\n        eval_candidates = this.candidates;\n      } else {\n        // forward prop the best networks from evaluated_candidates\n        nv = Math.min(this.ensemble_size, this.evaluated_candidates.length);\n        eval_candidates = this.evaluated_candidates\n      }\n\n      // forward nets of all candidates and average the predictions\n      var xout, n;\n      for(var j=0;j<nv;j++) {\n        var net = eval_candidates[j].net;\n        var x = net.forward(data);\n        if(j===0) { \n          xout = x; \n          n = x.w.length; \n        } else {\n          // add it on\n          for(var d=0;d<n;d++) {\n            xout.w[d] += x.w[d];\n          }\n        }\n      }\n      // produce average\n      for(var d=0;d<n;d++) {\n        xout.w[d] /= nv;\n      }\n      return xout;\n    },\n\n    predict: function(data) {\n      var xout = this.predict_soft(data);\n      if(xout.w.length !== 0) {\n        var stats = maxmin(xout.w);\n        var predicted_label = stats.maxi; \n      } else {\n        var predicted_label = -1; // error out\n      }\n      return predicted_label;\n\n    },\n\n    toJSON: function() {\n      // dump the top ensemble_size networks as a list\n      var nv = Math.min(this.ensemble_size, this.evaluated_candidates.length);\n      var json = {};\n      json.nets = [];\n      for(var i=0;i<nv;i++) {\n        json.nets.push(this.evaluated_candidates[i].net.toJSON());\n      }\n      return json;\n    },\n\n    fromJSON: function(json) {\n      this.ensemble_size = json.nets.length;\n      this.evaluated_candidates = [];\n      for(var i=0;i<this.ensemble_size;i++) {\n        var net = new Net();\n        net.fromJSON(json.nets[i]);\n        var dummy_candidate = {};\n        dummy_candidate.net = net;\n        this.evaluated_candidates.push(dummy_candidate);\n      }\n    },\n\n    // callback functions\n    // called when a fold is finished, while evaluating a batch\n    onFinishFold: function(f) { this.finish_fold_callback = f; },\n    // called when a batch of candidates has finished evaluating\n    onFinishBatch: function(f) { this.finish_batch_callback = f; }\n    \n  };\n\n  global.MagicNet = MagicNet;\n})(convnetjs);\n(function(lib) {\n  \"use strict\";\n  if (typeof module === \"undefined\" || typeof module.exports === \"undefined\") {\n    window.jsfeat = lib; // in ordinary browser attach library to window\n  } else {\n    module.exports = lib; // in nodejs\n  }\n})(convnetjs);\n"]}